{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfae479-9399-492d-acaa-d9751615ee86",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 언어 모델 finetuning\n",
    "\n",
    "\n",
    "HuggingFace Trainer와 wandb를 합쳐 언어 모델이 글자를 생성하는 방법에 대해 알아봅시다.  \n",
    "본 노트북에서는 자원의 제약때문에 작은 언어 모델(`TinyStories-33M`)을 사용할 것입니다.  \n",
    "하지만 여기서 배운 내용은 당연히 큰 모델들에도 적용 가능합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f0e67f",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import transformers\n",
    "transformers.set_seed(42)\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c25e3-5f18-4457-84e1-ed2c0d262222",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "wandb.login(anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2286ae41-213d-480d-a4ba-8c4e2e1c4771",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"roneneldan/TinyStories-33M\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd80268-c4a1-4e1a-aed3-cd5c3ab4d48f",
   "metadata": {},
   "source": [
    "### 데이터 준비하기\n",
    "\n",
    "우선 던전과 드래곤 캐릭터의 이야기를 담은 데이터셋을 Huggingface로부터 불러옵시다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9288a8e-b19b-4bd2-a72c-7dda03632282",
   "metadata": {},
   "source": [
    "> 경고가 나타날수도 있긴 하지만 괜찮습니다 :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7535b8b-d220-44e8-a56c-97e250c36596",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "ds = load_dataset('MohamedRashad/characters_backstories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13caeb7f-8a07-4ca2-a770-5b627238c2ac",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# 예시 하나를 살펴 보죠\n",
    "ds[\"train\"][400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae9106-8015-43da-a6d9-1124dee4bdde",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# 이 데이터셋은 validation셋이 없으므로, train셋에서 20%를 validation셋으로 분리합니다.\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1602d-504b-43de-87ad-fcb35b9e61f7",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "# 모델 체크포인트로부터 토크나이저를 생성합니다\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=False)\n",
    "\n",
    "# 배치 내에서 동일한 시퀀스 길이를 갖기 위해 패딩을 사용합니다\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 텍스트와 타겟을 연결하여 토큰화하는 함수를 정의합니다\n",
    "def tokenize_function(example):\n",
    "    merged = example[\"text\"] + \" \" + example[\"target\"]\n",
    "    batch = tokenizer(merged, padding='max_length', truncation=True, max_length=128)\n",
    "    batch[\"labels\"] = batch[\"input_ids\"].copy()\n",
    "    return batch\n",
    "\n",
    "# 이 함수를 데이터셋에 적용하여 텍스트와 타겟 칼럼을 제거합니다\n",
    "tokenized_datasets = ds.map(tokenize_function, remove_columns=[\"text\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42417b8-ffa8-4d96-92ea-d8d949d87d5e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# 제대로 준비되었는지 확인해 봅시다\n",
    "print(tokenizer.decode(tokenized_datasets[\"train\"][900]['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d6b17-a63d-41f1-92cf-416064b52156",
   "metadata": {},
   "source": [
    "### 학습\n",
    "HF의 Transformer와 wandb 기능을 이용하여 사전학습된 모델을 우리 데이터셋에 finetuning 해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f131eb-979e-40f6-9e28-19756beaa8e4",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# 사전학습된 체크포인트로부터 인과적(autoregressive) 언어 모델을 훈련시킬 것입니다\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345ab23-8d12-4d4c-a39d-bb2202bff218",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# 새로운 wandb run 시작\n",
    "run = wandb.init(project='dlai_lm_tuning', job_type=\"training\", anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ee155-3c30-4ef2-9c4d-fd8ee222c50c",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "# 학습에 필요한 argument를 정의합니다\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-characters-backstories\",\n",
    "    report_to=\"wandb\", # wandb에서 실험을 관리하기 위해서는 한 줄만 추가하면 됩니다\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    no_cuda=True, # cpu 사용을 강제합니다\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62105f-a478-436f-88a2-5c1d78b9d20a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# HF의 Trainer를 사용합니다\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01958a56-c22a-4a27-bc71-41c59fc97f05",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# 학습을 시작합니다\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911e43f-f4ce-4855-9f68-662438af8d24",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_error() # 토크나이저 경고를 압축합니다\n",
    "\n",
    "prefix = \"Generate Backstory based on following information Character Name: \"\n",
    "\n",
    "prompts = [\n",
    "    \"Frogger Character Race: Aarakocra Character Class: Ranger Output: \",\n",
    "    \"Smarty Character Race: Aasimar Character Class: Cleric Output: \",\n",
    "    \"Volcano Character Race: Android Character Class: Paladin Output: \",\n",
    "]\n",
    "\n",
    "table = wandb.Table(columns=[\"prompt\", \"generation\"])\n",
    "\n",
    "for prompt in prompts:\n",
    "    input_ids = tokenizer.encode(prefix + prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(input_ids, do_sample=True, max_new_tokens=50, top_p=0.3)\n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    table.add_data(prefix + prompt, output_text)\n",
    "    \n",
    "wandb.log({'tiny_generations': table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7caafaf-dfb7-413d-a329-8520aea5f73a",
   "metadata": {},
   "source": [
    "**주의**: LLM의 생성 결과는 항상 동일하지 않을수도 있습니다. 생성된 글자와 이야기는 영상에서와 다를 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083c6a3-fdb8-44ab-a028-c0a222a2fdef",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e429a9-5255-4a76-a27b-945c2afd17e4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3bfcc-2885-4eb8-8a18-a236c69e1a98",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
