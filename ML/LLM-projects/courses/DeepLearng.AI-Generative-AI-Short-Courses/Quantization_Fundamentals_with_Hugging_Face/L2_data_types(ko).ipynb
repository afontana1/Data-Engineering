{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the `requirements.txt` for this course from the workspace of this lab. `File --> Open...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8teiBZ6dP5g"
   },
   "source": [
    "# Lesson 2: Data Types and Sizes\n",
    "\n",
    "본 강의에서는 머신러닝 모델이 가중치를 저장할 때 사용하는 일반적인 데이터 타입에 대해 공부합니다.  \n",
    "자세한 내용을 확인하시려면 강의를 직접 수강해보시길 권장드립니다.\n",
    "\n",
    "\n",
    "```Python\n",
    "!pip install torch==2.1.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "height": 30,
    "id": "x_9J8WavkQGl"
   },
   "source": [
    "만약 PyTorch가 설치되어 있지 않다면 `!pip install torch`를 실행하여 다운로드 받을 수 있습니다. (바로 위의 셀 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30,
    "id": "nFC9wgzxBZvz"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hW7psx41rn0h"
   },
   "source": [
    "### Integers (정수 자료형)\n",
    "\n",
    "`torch.iinfo`를 통해 각 자료형의 최솟값 및 최댓값을 확인할 수 있습니다.  \n",
    "`int8` 앞에 붙는 u는 'unsigned'를 의미합니다.\n",
    "\n",
    "unsigned는 음수를 고려하지 않고 0부터 값의 범위를 갖는 것과 달리, signed는 음수를 고려하여 $2^{n-1}$개의 값을 양수, 음수로 나눠 갖습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Information of `8-bit unsigned integer`\n",
    "torch.iinfo(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Information of `8-bit (signed) integer`\n",
    "torch.iinfo(torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "### Information of `64-bit (signed) integer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "### Information of `32-bit (signed) integer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "### Information of `16-bit (signed) integer`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating Points (실수 자료형) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# by default, python stores float data in fp64\n",
    "value = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "format(value, '.60f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64비트 자료형으로 생성한 텐서는 처음 초기화한 `value`와 완전히 동일한 값을 갖는다는 것을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# 64-bit floating point\n",
    "tensor_fp64 = torch.tensor(value, dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(f\"fp64 tensor: {format(tensor_fp64.item(), '.60f')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 표현할 수 있는 값의 범위가 다른 자료형들로 변경해보면 소수점이 일부 잘리는 것이 확인됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "tensor_fp32 = torch.tensor(value, dtype = torch.float32)\n",
    "tensor_fp16 = torch.tensor(value, dtype = torch.float16)\n",
    "tensor_bf16 = torch.tensor(value, dtype = torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "print(f\"fp64 tensor: {format(tensor_fp64.item(), '.60f')}\")\n",
    "print(f\"fp32 tensor: {format(tensor_fp32.item(), '.60f')}\")\n",
    "print(f\"fp16 tensor: {format(tensor_fp16.item(), '.60f')}\")\n",
    "print(f\"bf16 tensor: {format(tensor_bf16.item(), '.60f')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서와 마찬가지로 `torch.finfo`를 이용하여 자료형의 범위, resolution을 확인할 수 있습니다.\n",
    "\n",
    "bfloat 자료형의 resolution은 float32 대비 훨씬 큰 값인데, 이것은 float32 자료형이 그만큼 값을 세밀하게 표현할 수 있다는 걸 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1699482682456,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 47,
    "id": "hUukczHrBodt",
    "outputId": "4e75bdf1-25b6-4e0c-9c08-18208e943b10"
   },
   "outputs": [],
   "source": [
    "# Information of `16-bit brain floating point`\n",
    "torch.finfo(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Information of `32-bit floating point`\n",
    "torch.finfo(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "### Information of `16-bit floating point`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "### Information of `64-bit floating point`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DbtWVVc_jiW"
   },
   "source": [
    "### Downcasting\n",
    "\n",
    "큰 자료형으로 표현된 값을 작은 자료형의 값으로 변경하는 걸 뜻합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47,
    "id": "JHDsqfauBID9"
   },
   "outputs": [],
   "source": [
    "# random pytorch tensor: float32, size=1000\n",
    "tensor_fp32 = torch.rand(1000, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** 여기서는 값을 랜덤하게 초기화하기 때문에 강의에서 보이는 값과 다를 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# first 5 elements of the random tensor\n",
    "tensor_fp32[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fp32 자료형을 bf16으로 변경하게 되면 일부 값이 잘립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47,
    "id": "xXLANbSx_nx4"
   },
   "outputs": [],
   "source": [
    "# downcast the tensor to bfloat16 using the \"to\" method\n",
    "tensor_fp32_to_bf16 = tensor_fp32.to(dtype = torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tensor_fp32_to_bf16[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fp32 자료형으로 행렬곱을 했을 때와 bf16 자료형으로 행렬곱을 했을 때를 비교합니다.\n",
    "\n",
    "엄청 큰 값은 아니지만 분명히 정확도에서의 손실이 존재한다는 것을 알 수 있습니다.\n",
    "\n",
    "이것이 엄청나게 많은 양의 연산이 이뤄지는 인공지능 모델 전체에는 큰 영향을 줄 수밖에 없겠죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# tensor_fp32 x tensor_fp32\n",
    "m_float32 = torch.dot(tensor_fp32, tensor_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "m_float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# tensor_fp32_to_bf16 x tensor_fp32_to_bf16\n",
    "m_bfloat16 = torch.dot(tensor_fp32_to_bf16, tensor_fp32_to_bf16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "m_bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "- 다음 강의에서 quantization의 아주 간단한 방식으로 downcasting을 사용할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNKuOYgD21Zty8Z1Smilnjc",
   "collapsed_sections": [
    "x_9J8WavkQGl",
    "sulufN1wkK_L",
    "hqPUM0f8oGgf",
    "TgmPMm-ZvdXX",
    "MJuh8aqo9LO-",
    "3bOevU0Ez4KB",
    "LgtYIhSf0Uu0",
    "9DH7-tDDvK5N",
    "TuZhoPK6weuR",
    "WAOeSNraxZeF",
    "UGXo-IljxmNG",
    "_N3G-dX32awT",
    "hW7psx41rn0h",
    "OmcNPw6zlRp7",
    "3_zvORGrnTR8",
    "jh9IuiovrnoF",
    "isDcbkXxxiTf",
    "wM-xkASw1odi",
    "3DbtWVVc_jiW",
    "ViImpV5rAvyp",
    "RdcyknnjBD99",
    "-eYj4UUXCAlJ",
    "MCLe1N4GCSQT",
    "GIY7IrOv_3cD",
    "8HlFKDBKGNG8"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
