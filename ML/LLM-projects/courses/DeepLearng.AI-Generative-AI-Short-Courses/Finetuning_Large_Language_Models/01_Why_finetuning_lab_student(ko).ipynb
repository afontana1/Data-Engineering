{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMGxBP-yQoCl"
   },
   "source": [
    "# finetuned vs. non-finetuned 모델 비교하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전학습된 모델을 바로 사용하는 것도 분명히 좋은 성능을 발휘하고 유용할 때가 많습니다.  \n",
    "하지만 현실에서는 모델을 특정 태스크나 분야에 적합하도록 만들고 이를 사용하는 것이 오히려 좋습니다.  \n",
    "좋다는 것은 성능적으로 뛰어나고 보안상으로는 안전하다는 뜻입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특히 LLM의 경우 사실이 아닌 정보를 사실처럼 반환하는 hallucination 문제가 심각한데,  \n",
    "이를 완화하기 위한 방법으로 fine-tuning을 들 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물론 전체 모델을 fine-tuning하는 것은 상당한 비용과 자원을 필요로 하는 작업이지만,  \n",
    "사전학습 모델과의 성능을 비교해보면 그만한 자원을 투자할만한 가치가 있음을 깨닫게 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "height": 30,
    "id": "PKnPPEyPR3MO"
   },
   "outputs": [],
   "source": [
    "from llama import BasicModelRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Finetuned 모델로 먼저 테스트 해봅니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "의외로 우리가 지금까지 봤던 LLM과 달리 굉장히 낮은 수준의 답변이 반환되는 것을 알 수 있습니다.  \n",
    "(엉뚱하거나 부적절한 답변을 내놓죠)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "non_finetuned = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "non_finetuned_output = non_finetuned(\"Tell me how to train my dog to sit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"What do you think of Mars?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"taylor swift's best friend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
    "Customer: I didn't get my item\n",
    "Agent: I'm sorry to hear that. Which item was it?\n",
    "Customer: the blanket\n",
    "Agent:\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finetuned 모델과 비교해 봅니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 채팅 형식에 특화된 모델로 결과를 확인합니다.  \n",
    "위와 달리 질문에 적합한 답변을 상세히 반환하는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "finetuned_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "finetuned_output = finetuned_model(\"Tell me how to train my dog to sit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델로 하여금 주어진 문장이 instruction임을 알게 하는 토큰을 사용하는 것이 도움이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"What do you think of Mars?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"taylor swift's best friend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
    "Customer: I didn't get my item\n",
    "Agent: I'm sorry to hear that. Which item was it?\n",
    "Customer: the blanket\n",
    "Agent:\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT와도 비교해 봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT 역시 답변을 잘 만들어 내는 것을 알 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "chatgpt = BasicModelRunner(\"chat-gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(chatgpt(\"Tell me how to train my dog to sit\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
