## [Finetuning Large Language Models](https://www.deeplearning.ai/short-courses/)
This repository contains lecture materials of 'Evaluating and Debugging Generative AI', free course of DeepLearning.AI 🤖  

I found that it is not allowed to download ipynb file directly from the lecture environment(sometimes),  
so I wrote all codes and comments by myself ✍🏻

This course provides us with OpenAI's API, but it is not applicable in other environment or local.  
Thus, <mark>**if you prefer to test your experiemnts on your local environment, you are forced to use your own API.**</mark>  
(And OpenAI will charge you for using API 🥲)

'Lamini' is a great LLM tool that supports lots of LLM and helps us to train and utilize them.


Contents:
1. Introduction
2. Why finetune
3. Where finetuning fits in
4. Instruction finetuning
5. Data preparation
6. Training process
7. Evaluation and iteration
8. Consideration on getting started now
9. Conclusion

I recommend you to execute codes directly on DeepLearning.AI course platform.
Also, try to execute your own codes and check how the model makes output.

---

이 저장소는 DeepLearning.AI에서 무료로 제공하는 Evaluating and Debugging Generative AI의 강의 자료를 저장하기 위해 생성되었습니다 🤖  
(강의 링크는 위를 참고해주세요!)  

강의에서 파일을 직접 다운로드 받을 수 있으면 좋았을텐데 그게 안돼서 직접 내용을 옮겼습니다.✍🏻  

본 강의에서는 OpenAI의 API를 제공하는데요, 강의 환경이 아니면 사용할 수 없는 API입니다.  
**그래서 저처럼 각자의 환경에서 테스트를 해보실 분들은 본인의 API를 사용해서 코드를 돌려볼 수 있습니다.**  
(대신 비용이 청구되겠지만요 🥲)  

'Lamini'는 여러 LLM들을 지원하여, 이를 학습하고 활용하기에 아주 유용한 툴입니다.


강의 목차:
1. Introduction
2. Why finetune: 왜 finetuning인가
3. Where finetuning fits in: finetuning이 적합한 곳은?
4. Instruction finetuning
5. Data preparation: 데이터 준비
6. Training process: 학습 과정
7. Evaluation and iteration: 평가 및 반복
8. Consideration on getting started now: 어떻게 시작하면 좋을까?
9. Conclusion

개인적으로는 강의를 제공하는 DeepLearning.AI 플랫폼을 이용하시는 걸 추천드립니다.  
또한 강의를 들으면서 본인만의 코드를 직접 입력하고 결과물을 확인해보는 것이 내용 이해에 큰 도움이 되는 것 같습니다.
  
