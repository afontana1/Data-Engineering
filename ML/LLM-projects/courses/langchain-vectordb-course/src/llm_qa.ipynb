{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keys import OPENAI_API_KEY, ACTIVELOOP_TOKEN\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"ACTIVELOOP_TOKEN\"] = ACTIVELOOP_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from newspaper import Article # https://github.com/codelucas/newspaper\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_urls = [\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/jay-migliaccio-ibm-watson-on-leveraging-ai-to-improve-productivity/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/ai-and-big-data-expo-north-america-begins-in-less-than-one-week/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/28/palantir-demos-how-ai-can-used-military/\"\n",
    "]\n",
    "\n",
    "session = requests.Session()\n",
    "pages_content = [] # where we save the scraped articles\n",
    "\n",
    "for url in article_urls:\n",
    "    try:\n",
    "        time.sleep(2) # sleep two seconds for gentle scraping\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            article = Article(url)\n",
    "            article.download() # download HTML of webpage\n",
    "            article.parse() # parse HTML to extract the article text\n",
    "            pages_content.append({ \"url\": url, \"text\": article.text })\n",
    "        else:\n",
    "            print(f\"Failed to fetch article at {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while fetching article at {url}: {e}\")\n",
    "\n",
    "#If an error occurs while fetching an article, we catch the exception and print\n",
    "#an error message. This ensures that even if one article fails to download,\n",
    "#the rest of the articles can still be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Document Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bharat/mambaforge/envs/llm-env/lib/python3.11/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.19) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n",
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"bharatr\"\n",
    "my_activeloop_dataset_name = \"langchain_course_qabot_with_source\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the article texts into small chunks. While doing so, we keep track of each\n",
    "# chunk metadata (i.e. the URL where it comes from). Each metadata is a dictionary and\n",
    "# we need to use the \"source\" key for the document source so that we can then use the\n",
    "# RetrievalQAWithSourcesChain class which will automatically retrieve the \"source\" item\n",
    "# from the metadata dictionary.\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "all_texts, all_metadatas = [], []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        all_texts.append(chunk)\n",
    "        all_metadatas.append({ \"source\": d[\"url\"] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://bharatr/langchain_course_qabot_with_source', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      " embedding  embedding  (49, 1536)  float32   None   \n",
      "    id        text      (49, 1)      str     None   \n",
      " metadata     json      (49, 1)      str     None   \n",
      "   text       text      (49, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['59b9fdec-3d25-11ee-82a4-78af089a20b3',\n",
       " '59b9fefa-3d25-11ee-82a4-78af089a20b3',\n",
       " '59b9ff4a-3d25-11ee-82a4-78af089a20b3',\n",
       " '59b9ff9a-3d25-11ee-82a4-78af089a20b3',\n",
       " '59b9ffcc-3d25-11ee-82a4-78af089a20b3',\n",
       " '59b9fffe-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0026-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0076-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba00a8-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba010c-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0134-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba015c-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0184-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba01ac-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba01d4-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba01f2-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba021a-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0242-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba026a-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0288-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba02b0-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba02e2-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba030a-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0332-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba035a-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0382-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba03aa-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba03d2-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0404-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0422-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba044a-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0472-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0490-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba04b8-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba04e0-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0508-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0526-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba054e-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0576-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0594-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba05bc-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba05e4-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba060c-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba063e-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0666-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba068e-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba06b6-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba06de-3d25-11ee-82a4-78af089a20b3',\n",
       " '59ba0706-3d25-11ee-82a4-78af089a20b3']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we add all the chunks to the deep lake, along with their metadata\n",
    "db.add_texts(all_texts, all_metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a RetrievalQAWithSourcesChain chain, which is very similar to a\n",
    "# standard retrieval QA chain but it also keeps track of the sources of the\n",
    "# retrieved documents\n",
    "\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm,\n",
    "                                                    chain_type=\"stuff\",\n",
    "                                                    retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      " Geoffrey Hinton believes that the rapid development of generative AI products is \"racing towards danger\" and that false text, images, and videos created by AI could lead to a situation where average people \"would not be able to know what is true anymore.\" He also expressed concerns about the impact of AI on the job market, as machines could eventually replace roles such as paralegals, personal assistants, and translators.\n",
      "\n",
      "Sources:\n",
      "- https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\n"
     ]
    }
   ],
   "source": [
    "# We generate a response to a query using the chain. The response object is a dictionary containing\n",
    "# an \"answer\" field with the textual answer to the query, and a \"sources\" field containing a string made\n",
    "# of the concatenation of the metadata[\"source\"] strings of the retrieved documents.\n",
    "d_response = chain({\"question\": \"What does Geoffrey Hinton think about recent trends in AI?\"})\n",
    "\n",
    "print(\"Response:\")\n",
    "print(d_response[\"answer\"])\n",
    "print(\"Sources:\")\n",
    "for source in d_response[\"sources\"].split(\", \"):\n",
    "    print(\"- \" + source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
