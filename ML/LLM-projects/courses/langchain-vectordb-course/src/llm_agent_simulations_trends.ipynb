{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Simulations - CAMEL and Generative Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Simulation projects in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Autonomous Agents are created with distinct personalities or roles. \n",
    "- These agents are designed to interact with each other autonomously, without the need for constant human supervision or intervention. This allows for the emergence of unique and compelling behaviors as the agents communicate with each other.\n",
    "- Agents achieve \"tool specialization\": one agent might be equipped with tools for coding, while another could be optimized for normal interactions. This allows for the potential of a \"stacking\" effect, where different agents are responsible for different aspects of a task, creating a more complex and dynamic simulation environment.\n",
    "- Agent Simulation projects, such as CAMEL and Generative Agents, introduce innovative simulation environments and adaptive long-term memory based on events. The differences lie in their **environments** and **memory mechanisms**.\n",
    "- The LangChain Reasoning and Acting (ReAct) framework also operates in a loop until a stopping criterion is met. Task execution -> Interactive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the CAMEL project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CAMEL stands for **C**ommunicative **A**gents for **M**ind **E**xploration of **L**arge Scale Language Model Society\n",
    "- Agents use `inception prompting` to guide their interactions towards completing tasks while aligning with the initial human intent. This shift towards autonomy in agents may significantly reduce the need for human supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/camel-ai/camel/master/misc/framework.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display the example framework\n",
    "from IPython.display import Image\n",
    "\n",
    "img_url = 'https://raw.githubusercontent.com/camel-ai/camel/master/misc/framework.png'\n",
    "Image(url=img_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example illustrates this framework for a stock market trading bot. The steps are:\n",
    "1. Human user has an idea to accomplish, in this case a trading bot for the stock market.\n",
    "2. Task involves two AI agents, an AI assistant with Python programming skills, and another AI user with stock trading expertise.\n",
    "3. A \"task specifier agent\" refines the idea into a (series of) well-defined task(s) that the assistant can work on, making the task(s) more specific, like coding or analyses on stock data.\n",
    "4. The AI user and AI assistant start interacting. They communicate through chat, with instructions, collaborating to solve the specified task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can solve a complex task without / minimal human intervention\n",
    "- Challenges include hallucinations, role-flipping, conversation deviation, termination conditions etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are Generative Agents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inspired by the paper \"Generative Agents: Interactive Simulacra of Human Behavior.\"\n",
    "- The simulation environment in the Generative Agents project comprises 25 different agents, creating an intricate and highly specific setting. These generative agents possess an extended memory stored as a single stream.\n",
    "- Memory is composed of '**Observations**', which are derived from interactions and dialogues within the virtual world concerning themselves or others, and '**Reflections**', which are core memories that have been summarized and resurfaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/joonspk-research/generative_agents/main/cover.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Idea of the simulation\n",
    "from IPython.display import Image\n",
    "\n",
    "img_url = 'https://raw.githubusercontent.com/joonspk-research/generative_agents/main/cover.png'\n",
    "Image(url=img_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The long-term memory system of these agents consists of several components:\n",
    "- **Importance reflection steps:** This component assigns an importance score to each observation. The score serves as a reference during retrieval, allowing the system to fetch significant memories and disregard less relevant ones.\n",
    "- **Reflection steps:** These steps allow the agent to \"pause\" and evaluate the generalizations it has learned. These reflections can then be retrieved along with normal memories. This process aids in condensing information and spotting patterns in recent memories.\n",
    "- **A retriever that combines recency, relevancy, and importance:** This advanced memory retriever surfaces memories that are similar to the current situation, occurred recently, and hold a high importance score. This model of memory retrieval closely mirrors how humans recall memories.\n",
    "\n",
    "The retriever logic was later found to be generalizable. Therefore, it was added as a `TimeWeightedVectorStoreRetriever`, which also records the last time the memory was accessed.  \n",
    "The project represents agents that emulate human activities in a simulated environment akin to the virtual world in **The Sims**.\n",
    "\n",
    "The core of this architecture is the \"Memory Stream\", a database that maintains a comprehensive record of an agentâ€™s experiences. It retrieves and synthesizes the most relevant memories to guide the agent's actions, contributing to more consistent and coherent behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Insights and Trends of Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **AutoGPT** pushed GPT-4 towards full autonomy, which has gained notable attention and popularity.\n",
    "- \"**Plan-and-Execute**\" agents separate high-level planning from immediate execution, which improves efficiency and performance of the agents.\n",
    "- GPT-4's **Plugin** and **Code Interpreter** abilities augment the model's abilities and opens up a wide variety of use cases like data analysis, visualization, internet access etc.\n",
    "- Efficiencies of the \"Small context window with retriever approach\" vs \"Large context window without retrievers\" need to be compared. In this regard **Anthropic**'s new **Claude** model supports a context window of **100k tokens**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
