{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keys import OPENAI_API_KEY, ACTIVELOOP_TOKEN\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['ACTIVELOOP_TOKEN'] = ACTIVELOOP_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autonomous Agents for Analysis Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scrape several Artificial Intelligence news\n",
    "\n",
    "import requests\n",
    "from newspaper import Article # https://github.com/codelucas/newspaper\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_urls = [\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/23/meta-open-source-speech-ai-models-support-over-1100-languages/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/18/beijing-launches-campaign-against-ai-generated-misinformation/\"\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/jay-migliaccio-ibm-watson-on-leveraging-ai-to-improve-productivity/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/ai-and-big-data-expo-north-america-begins-in-less-than-one-week/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/eu-committees-green-light-ai-act/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/09/wozniak-warns-ai-will-power-next-gen-scams/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/09/infocepts-ceo-shashank-garg-on-the-da-market-shifts-and-impact-of-ai-on-data-analytics/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/28/palantir-demos-how-ai-can-used-military/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/26/ftc-chairwoman-no-ai-exemption-to-existing-laws/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/24/bill-gates-ai-teaching-kids-literacy-within-18-months/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/21/google-creates-new-ai-division-to-challenge-openai/\"\n",
    "]\n",
    "\n",
    "session = requests.Session()\n",
    "pages_content = [] # where we save the scraped articles\n",
    "\n",
    "for url in article_urls:\n",
    "    try:\n",
    "        time.sleep(2) # sleep two seconds for gentle scraping\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            article = Article(url)\n",
    "            article.download() # download HTML of webpage\n",
    "            article.parse() # parse HTML to extract the article text\n",
    "            pages_content.append({ \"url\": url, \"text\": article.text })\n",
    "        else:\n",
    "            print(f\"Failed to fetch article at {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while fetching article at {url}: {e}\")\n",
    "\n",
    "# If an error occurs while fetching an article, we catch the exception and print\n",
    "#an error message. This ensures that even if one article fails to download,\n",
    "#the rest of the articles can still be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "# We'll use an embedding model to compute our documents' embeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# We'll store the documents and their embeddings in the deep lake vector db\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "# Setup deep lake\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"bharatr\"\n",
    "my_activeloop_dataset_name = \"langchain_course_analysis_outline\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the article texts into small chunks\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "all_texts = []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        all_texts.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://bharatr/langchain_course_analysis_outline', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      " embedding  embedding  (94, 1536)  float32   None   \n",
      "    id        text      (94, 1)      str     None   \n",
      " metadata     json      (94, 1)      str     None   \n",
      "   text       text      (94, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ef90e6b8-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e7b2-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e7f8-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e82a-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e85c-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e88e-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e8c0-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e906-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e938-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e96a-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e992-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e9ba-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90e9d8-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ea00-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ea1e-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ea46-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ea6e-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ea8c-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90eab4-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90eadc-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90eafa-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90eb22-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90eb54-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90eb72-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90eb9a-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ebb8-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ebe0-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ec08-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ec26-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ec4e-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ec76-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ec94-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ecbc-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ece4-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ed0c-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ed2a-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ed52-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ed7a-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ed98-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90edc0-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90edde-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ee06-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ee2e-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ee4c-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ee6a-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ee92-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90eeb0-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90eece-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90eeec-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ef14-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ef32-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ef50-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ef6e-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90ef8c-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90efbe-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90efdc-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90effa-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f018-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f040-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f05e-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f07c-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f09a-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f0c2-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f0e0-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f0fe-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f11c-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f144-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f162-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f180-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f19e-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f1bc-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f1da-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f1f8-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f216-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f234-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f25c-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f27a-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f2ac-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f2d4-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f2f2-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f310-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f338-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f356-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f374-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f392-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f3ba-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f3e2-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f536-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f55e-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f572-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f586-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f59a-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f5a4-4046-11ee-8d90-78af089a20b3',\n",
       " 'ef90f5cc-4046-11ee-8d90-78af089a20b3']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we add all the chunks to the Deep lake\n",
    "db.add_texts(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the retriever object from the deep lake db object and set the number\n",
    "# of retrieved documents to 3\n",
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs['k'] = 3\n",
    "\n",
    "# We define some variables that will be used inside our custom tool\n",
    "CUSTOM_TOOL_DOCS_SEPARATOR =\"\\n---------------\\n\" # how to join together the retrieved docs to form a single string\n",
    "\n",
    "# This is the function that defines our custom tool that retrieves relevant\n",
    "# docs from Deep Lake\n",
    "def retrieve_n_docs_tool(query: str) -> str:\n",
    "    \"\"\"Searches for relevant documents that may contain the answer to the query.\"\"\"\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    texts = [doc.page_content for doc in docs]\n",
    "    texts_merged = \"---------------\\n\" + CUSTOM_TOOL_DOCS_SEPARATOR.join(texts) + \"\\n---------------\"\n",
    "    return texts_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.tools import Tool\n",
    "\n",
    "# We create the tool that uses the \"retrieve_n_docs_tool\" function\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search Private Docs\",\n",
    "        func=retrieve_n_docs_tool,\n",
    "        description=\"useful for when you need to answer questions about current events about Artificial Intelligence\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "\n",
    "# let's create the Plan and Execute agent\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "planner = load_chat_planner(model)\n",
    "executor = load_agent_executor(model, tools, verbose=True)\n",
    "agent = PlanAndExecute(planner=planner, executor=executor, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "steps=[Step(value='Research and gather information on the current state of Artificial Intelligence (AI) regulations by governments in different countries.'), Step(value='Organize the information by country and categorize it based on the level of AI regulation.'), Step(value='Provide an overview of the AI regulations in each country, including any specific laws or policies that have been implemented.'), Step(value='Include information on the key areas covered by the regulations, such as data privacy, algorithmic transparency, liability, and ethical considerations.'), Step(value='Highlight any notable differences or similarities between the regulations in different countries.'), Step(value='Summarize the overall trends and developments in AI regulations globally.'), Step(value='Given the above steps taken, provide an overview of Artificial Intelligence regulations by governments by country. ')]\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": \"Artificial Intelligence regulations by governments in different countries\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "“US-based AI developers will likely steal a march on their European competitors given the news that the EU parliamentary committees have green-lit its groundbreaking AI Act, where AI systems will need to be categorised according to their potential for harm from the outset. The US tech approach is typically to experiment first and, once market and product fit is established, to retrofit to other markets and their regulatory framework. This approach fosters innovation whereas EU-based AI developers will need to take note of the new rules and develop systems and processes which may take the edge off their ability to innovate. The UK is adopting a similar approach to the US, although the proximity of the EU market means that UK-based developers are more likely to fall into step with the EU ruleset from the outset. However, the potential to experiment in a safe space – a regulatory sandbox – may prove very attractive.”\n",
      "---------------\n",
      "Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "The Internal Market Committee and the Civil Liberties Committee of the European Parliament have endorsed new transparency and risk-management rules for artificial intelligence systems known as the AI Act.\n",
      "\n",
      "This marks a major step in the development of AI regulation in Europe, as these are the first-ever rules for AI. The rules aim to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "After the vote, co-rapporteur Brando Benifei (S&D, Italy) said:\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe current state of Artificial Intelligence (AI) regulations by governments in different countries is as follows:\n",
      "\n",
      "In the European Union (EU), the EU parliamentary committees have recently approved the groundbreaking AI Act. This act categorizes AI systems based on their potential for harm and introduces transparency and risk-management rules. The aim is to ensure that AI systems are safe, transparent, traceable, and non-discriminatory. The UK, being part of the EU, is likely to align with these regulations as well.\n",
      "\n",
      "In the United States, the approach to AI regulation is typically more focused on experimentation and market fit before retrofitting to regulatory frameworks. This approach fosters innovation. However, there is no comprehensive federal AI regulation in place yet.\n",
      "\n",
      "It's important to note that regulations can vary across different countries and regions. It would be beneficial to research specific countries of interest to get a more detailed understanding of their AI regulations.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The current state of AI regulations is as follows: In the EU, the AI Act has been approved, categorizing AI systems based on potential harm and introducing transparency and risk-management rules. The US has a more experimental approach, with no comprehensive federal AI regulation in place yet.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Research and gather information on the current state of Artificial Intelligence (AI) regulations by governments in different countries.\n",
      "\n",
      "Response: The current state of AI regulations is as follows: In the EU, the AI Act has been approved, categorizing AI systems based on potential harm and introducing transparency and risk-management rules. The US has a more experimental approach, with no comprehensive federal AI regulation in place yet.\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": {\n",
      "    \"tool_input\": \"AI regulations by country\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "“US-based AI developers will likely steal a march on their European competitors given the news that the EU parliamentary committees have green-lit its groundbreaking AI Act, where AI systems will need to be categorised according to their potential for harm from the outset. The US tech approach is typically to experiment first and, once market and product fit is established, to retrofit to other markets and their regulatory framework. This approach fosters innovation whereas EU-based AI developers will need to take note of the new rules and develop systems and processes which may take the edge off their ability to innovate. The UK is adopting a similar approach to the US, although the proximity of the EU market means that UK-based developers are more likely to fall into step with the EU ruleset from the outset. However, the potential to experiment in a safe space – a regulatory sandbox – may prove very attractive.”\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\n",
      "Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "The Internal Market Committee and the Civil Liberties Committee of the European Parliament have endorsed new transparency and risk-management rules for artificial intelligence systems known as the AI Act.\n",
      "\n",
      "This marks a major step in the development of AI regulation in Europe, as these are the first-ever rules for AI. The rules aim to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "After the vote, co-rapporteur Brando Benifei (S&D, Italy) said:\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the information gathered from the search, here is the organized information by country and the level of AI regulation:\n",
      "\n",
      "1. European Union (EU):\n",
      "   - The EU has approved the AI Act, which categorizes AI systems based on potential harm.\n",
      "   - The AI Act introduces transparency and risk-management rules for AI systems.\n",
      "   - Exemptions are provided for research activities and AI components under open-source licenses.\n",
      "   - Regulatory sandboxes are promoted to test AI before deployment.\n",
      "   - Citizens have the right to file complaints about AI systems and receive explanations of decisions.\n",
      "   - The EU AI Office will monitor the implementation of the AI rulebook.\n",
      "\n",
      "2. United States (US):\n",
      "   - The US does not have comprehensive federal AI regulation in place yet.\n",
      "   - The US takes an experimental approach to AI development.\n",
      "   - Market and product fit is established first, followed by retrofitting to regulatory frameworks.\n",
      "   - This approach fosters innovation among US-based AI developers.\n",
      "\n",
      "3. United Kingdom (UK):\n",
      "   - The UK is adopting a similar approach to the US in terms of AI regulation.\n",
      "   - However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\n",
      "   - The UK also has the potential for regulatory sandboxes to experiment in a safe space.\n",
      "\n",
      "Please note that this information is based on the search results and may not be exhaustive.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Organize the information by country and categorize it based on the level of AI regulation.\n",
      "\n",
      "Response: Based on the information gathered from the search, here is the organized information by country and the level of AI regulation:\n",
      "\n",
      "1. European Union (EU):\n",
      "   - The EU has approved the AI Act, which categorizes AI systems based on potential harm.\n",
      "   - The AI Act introduces transparency and risk-management rules for AI systems.\n",
      "   - Exemptions are provided for research activities and AI components under open-source licenses.\n",
      "   - Regulatory sandboxes are promoted to test AI before deployment.\n",
      "   - Citizens have the right to file complaints about AI systems and receive explanations of decisions.\n",
      "   - The EU AI Office will monitor the implementation of the AI rulebook.\n",
      "\n",
      "2. United States (US):\n",
      "   - The US does not have comprehensive federal AI regulation in place yet.\n",
      "   - The US takes an experimental approach to AI development.\n",
      "   - Market and product fit is established first, followed by retrofitting to regulatory frameworks.\n",
      "   - This approach fosters innovation among US-based AI developers.\n",
      "\n",
      "3. United Kingdom (UK):\n",
      "   - The UK is adopting a similar approach to the US in terms of AI regulation.\n",
      "   - However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\n",
      "   - The UK also has the potential for regulatory sandboxes to experiment in a safe space.\n",
      "\n",
      "Please note that this information is based on the search results and may not be exhaustive.\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The current state of AI regulations in different countries is as follows:\\n\\n1. European Union (EU):\\n   - The EU has approved the AI Act, which categorizes AI systems based on potential harm.\\n   - The AI Act introduces transparency and risk-management rules for AI systems.\\n   - Exemptions are provided for research activities and AI components under open-source licenses.\\n   - Regulatory sandboxes are promoted to test AI before deployment.\\n   - Citizens have the right to file complaints about AI systems and receive explanations of decisions.\\n   - The EU AI Office will monitor the implementation of the AI rulebook.\\n\\n2. United States (US):\\n   - The US does not have comprehensive federal AI regulation in place yet.\\n   - The US takes an experimental approach to AI development.\\n   - Market and product fit is established first, followed by retrofitting to regulatory frameworks.\\n   - This approach fosters innovation among US-based AI developers.\\n\\n3. United Kingdom (UK):\\n   - The UK is adopting a similar approach to the US in terms of AI regulation.\\n   - However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\\n   - The UK also has the potential for regulatory sandboxes to experiment in a safe space.\\n\\nPlease note that this information is based on the search results and may not be exhaustive.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Provide an overview of the AI regulations in each country, including any specific laws or policies that have been implemented.\n",
      "\n",
      "Response: The current state of AI regulations in different countries is as follows:\n",
      "\n",
      "1. European Union (EU):\n",
      "   - The EU has approved the AI Act, which categorizes AI systems based on potential harm.\n",
      "   - The AI Act introduces transparency and risk-management rules for AI systems.\n",
      "   - Exemptions are provided for research activities and AI components under open-source licenses.\n",
      "   - Regulatory sandboxes are promoted to test AI before deployment.\n",
      "   - Citizens have the right to file complaints about AI systems and receive explanations of decisions.\n",
      "   - The EU AI Office will monitor the implementation of the AI rulebook.\n",
      "\n",
      "2. United States (US):\n",
      "   - The US does not have comprehensive federal AI regulation in place yet.\n",
      "   - The US takes an experimental approach to AI development.\n",
      "   - Market and product fit is established first, followed by retrofitting to regulatory frameworks.\n",
      "   - This approach fosters innovation among US-based AI developers.\n",
      "\n",
      "3. United Kingdom (UK):\n",
      "   - The UK is adopting a similar approach to the US in terms of AI regulation.\n",
      "   - However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\n",
      "   - The UK also has the potential for regulatory sandboxes to experiment in a safe space.\n",
      "\n",
      "Please note that this information is based on the search results and may not be exhaustive.\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The current objective is to include information on the key areas covered by the AI regulations, such as data privacy, algorithmic transparency, liability, and ethical considerations. I can provide an overview of these key areas for each country mentioned in the previous steps.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": \"AI regulations key areas\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "In a demo showcasing AIP, a military operator responsible for monitoring activity within Eastern Europe receives an alert that military equipment is amassed in a field 30km from friendly forces.\n",
      "\n",
      "AIP leverages large language models to allow operators to quickly ask questions such as:\n",
      "\n",
      "What enemy units are in the region?\n",
      "\n",
      "Task new imagery for this location at a resolution of one metre or higher\n",
      "\n",
      "Generate three courses of action to target this enemy equipment\n",
      "\n",
      "Analyse the battlefield, considering a Stryker vehicle and a platoon-size unit\n",
      "\n",
      "How many Javelin missiles does Team Omega have?\n",
      "\n",
      "Assign jammers to each of the validated high-priority communications targets\n",
      "\n",
      "Summarise the operational plan\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\n",
      "Summarise the operational plan\n",
      "\n",
      "As the operator poses questions, the LLM is using real-time information integrated from across public and classified sources. Data is automatically tagged and protected by classification markings, and AIP enforces which parts of the organisation the LLM has access to while respecting an individual’s permissions, role, and need to know.\n",
      "\n",
      "Every response from AIP retains links back to the underlying data records to enable transparency for the user who can investigate as necessary.\n",
      "\n",
      "AIP unleashes the power of large language models and cutting-edge AI for defense and military organisations while aiming to do so with the appropriate guardrails and high levels of ethics and transparency that are required for such sensitive applications.\n",
      "\n",
      "﻿\n",
      "\n",
      "(Image Credit: Palantir)\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe previous steps have provided information on the current state of AI regulations in different countries, including the European Union (EU), the United States (US), and the United Kingdom (UK). However, the information does not specifically mention the key areas covered by these regulations, such as data privacy, algorithmic transparency, liability, and ethical considerations.\n",
      "\n",
      "To address the current objective of including information on these key areas, I will search for relevant information on AI regulations and their key areas.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": \"AI regulations key areas\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "In a demo showcasing AIP, a military operator responsible for monitoring activity within Eastern Europe receives an alert that military equipment is amassed in a field 30km from friendly forces.\n",
      "\n",
      "AIP leverages large language models to allow operators to quickly ask questions such as:\n",
      "\n",
      "What enemy units are in the region?\n",
      "\n",
      "Task new imagery for this location at a resolution of one metre or higher\n",
      "\n",
      "Generate three courses of action to target this enemy equipment\n",
      "\n",
      "Analyse the battlefield, considering a Stryker vehicle and a platoon-size unit\n",
      "\n",
      "How many Javelin missiles does Team Omega have?\n",
      "\n",
      "Assign jammers to each of the validated high-priority communications targets\n",
      "\n",
      "Summarise the operational plan\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\n",
      "Summarise the operational plan\n",
      "\n",
      "As the operator poses questions, the LLM is using real-time information integrated from across public and classified sources. Data is automatically tagged and protected by classification markings, and AIP enforces which parts of the organisation the LLM has access to while respecting an individual’s permissions, role, and need to know.\n",
      "\n",
      "Every response from AIP retains links back to the underlying data records to enable transparency for the user who can investigate as necessary.\n",
      "\n",
      "AIP unleashes the power of large language models and cutting-edge AI for defense and military organisations while aiming to do so with the appropriate guardrails and high levels of ethics and transparency that are required for such sensitive applications.\n",
      "\n",
      "﻿\n",
      "\n",
      "(Image Credit: Palantir)\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search for information on the key areas covered by AI regulations did not provide the expected results. However, I can still provide a general overview of the key areas typically covered by AI regulations, including data privacy, algorithmic transparency, liability, and ethical considerations.\n",
      "\n",
      "Data privacy: AI regulations often include provisions to protect the privacy of individuals' data that is collected and processed by AI systems. This may involve requirements for obtaining consent, ensuring data security, and providing individuals with control over their personal data.\n",
      "\n",
      "Algorithmic transparency: Regulations may address the need for transparency in AI systems, particularly those that have a significant impact on individuals or society. This may involve requirements for explaining how AI systems make decisions and ensuring that they are not biased or discriminatory.\n",
      "\n",
      "Liability: AI regulations may establish rules regarding liability for any harm caused by AI systems. This can include determining who is responsible for any damages or injuries caused by AI systems and establishing mechanisms for compensation.\n",
      "\n",
      "Ethical considerations: Regulations may also address ethical considerations related to AI, such as ensuring that AI systems are developed and used in a manner that aligns with societal values and norms. This can involve guidelines for responsible AI development, deployment, and use.\n",
      "\n",
      "Please note that the specific details of AI regulations and the extent to which these key areas are covered can vary between countries.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Include information on the key areas covered by the regulations, such as data privacy, algorithmic transparency, liability, and ethical considerations.\n",
      "\n",
      "Response: The search for information on the key areas covered by AI regulations did not provide the expected results. However, I can still provide a general overview of the key areas typically covered by AI regulations, including data privacy, algorithmic transparency, liability, and ethical considerations.\n",
      "\n",
      "Data privacy: AI regulations often include provisions to protect the privacy of individuals' data that is collected and processed by AI systems. This may involve requirements for obtaining consent, ensuring data security, and providing individuals with control over their personal data.\n",
      "\n",
      "Algorithmic transparency: Regulations may address the need for transparency in AI systems, particularly those that have a significant impact on individuals or society. This may involve requirements for explaining how AI systems make decisions and ensuring that they are not biased or discriminatory.\n",
      "\n",
      "Liability: AI regulations may establish rules regarding liability for any harm caused by AI systems. This can include determining who is responsible for any damages or injuries caused by AI systems and establishing mechanisms for compensation.\n",
      "\n",
      "Ethical considerations: Regulations may also address ethical considerations related to AI, such as ensuring that AI systems are developed and used in a manner that aligns with societal values and norms. This can involve guidelines for responsible AI development, deployment, and use.\n",
      "\n",
      "Please note that the specific details of AI regulations and the extent to which these key areas are covered can vary between countries.\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I have already gathered information on the AI regulations in different countries and organized it by country. Now, I need to identify any notable differences or similarities between the regulations.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": {\n",
      "    \"tool_input\": \"Differences and similarities between AI regulations in different countries\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "“US-based AI developers will likely steal a march on their European competitors given the news that the EU parliamentary committees have green-lit its groundbreaking AI Act, where AI systems will need to be categorised according to their potential for harm from the outset. The US tech approach is typically to experiment first and, once market and product fit is established, to retrofit to other markets and their regulatory framework. This approach fosters innovation whereas EU-based AI developers will need to take note of the new rules and develop systems and processes which may take the edge off their ability to innovate. The UK is adopting a similar approach to the US, although the proximity of the EU market means that UK-based developers are more likely to fall into step with the EU ruleset from the outset. However, the potential to experiment in a safe space – a regulatory sandbox – may prove very attractive.”\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\n",
      "Khan did not specifically name any companies or products, but her comments will likely increase pressure on major tech firms like Google and Microsoft that are currently engaged in a race to sell more advanced AI tools.\n",
      "\n",
      "The warnings from top US regulators come at a time when EU lawmakers are negotiating new rules designed to regulate AI, with some in the US calling for similar legislation.\n",
      "\n",
      "The regulators said that many of the most harmful AI products might already contravene existing laws protecting civil rights and preventing fraud.\n",
      "\n",
      "For her part, Khan reiterated that “there is no AI exemption to the laws on the books.”\n",
      "\n",
      "Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The event is co-located with Digital Transformation Week.\n",
      "\n",
      "Explore other upcoming enterprise technology events and webinars powered by TechForge here.\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the search results, here are some notable differences and similarities between the AI regulations in different countries:\n",
      "\n",
      "1. European Union (EU):\n",
      "- The EU has approved the AI Act, which categorizes AI systems based on potential harm.\n",
      "- The AI Act introduces transparency and risk-management rules for AI systems.\n",
      "- Exemptions are provided for research activities and AI components under open-source licenses.\n",
      "- Regulatory sandboxes are promoted to test AI before deployment.\n",
      "- Citizens have the right to file complaints about AI systems and receive explanations of decisions.\n",
      "- The EU AI Office will monitor the implementation of the AI rulebook.\n",
      "\n",
      "2. United States (US):\n",
      "- The US does not have comprehensive federal AI regulation in place yet.\n",
      "- The US takes an experimental approach to AI development.\n",
      "- Market and product fit is established first, followed by retrofitting to regulatory frameworks.\n",
      "- This approach fosters innovation among US-based AI developers.\n",
      "\n",
      "3. United Kingdom (UK):\n",
      "- The UK is adopting a similar approach to the US in terms of AI regulation.\n",
      "- However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\n",
      "- The UK also has the potential for regulatory sandboxes to experiment in a safe space.\n",
      "\n",
      "Some notable differences include the EU's categorization of AI systems based on potential harm and the promotion of regulatory sandboxes, which are not present in the US and UK regulations. The US and UK take a more experimental approach to AI development, while the EU has a more structured regulatory framework.\n",
      "\n",
      "Please note that this information is based on the search results and may not be exhaustive.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Highlight any notable differences or similarities between the regulations in different countries.\n",
      "\n",
      "Response: Based on the search results, here are some notable differences and similarities between the AI regulations in different countries:\n",
      "\n",
      "1. European Union (EU):\n",
      "- The EU has approved the AI Act, which categorizes AI systems based on potential harm.\n",
      "- The AI Act introduces transparency and risk-management rules for AI systems.\n",
      "- Exemptions are provided for research activities and AI components under open-source licenses.\n",
      "- Regulatory sandboxes are promoted to test AI before deployment.\n",
      "- Citizens have the right to file complaints about AI systems and receive explanations of decisions.\n",
      "- The EU AI Office will monitor the implementation of the AI rulebook.\n",
      "\n",
      "2. United States (US):\n",
      "- The US does not have comprehensive federal AI regulation in place yet.\n",
      "- The US takes an experimental approach to AI development.\n",
      "- Market and product fit is established first, followed by retrofitting to regulatory frameworks.\n",
      "- This approach fosters innovation among US-based AI developers.\n",
      "\n",
      "3. United Kingdom (UK):\n",
      "- The UK is adopting a similar approach to the US in terms of AI regulation.\n",
      "- However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\n",
      "- The UK also has the potential for regulatory sandboxes to experiment in a safe space.\n",
      "\n",
      "Some notable differences include the EU's categorization of AI systems based on potential harm and the promotion of regulatory sandboxes, which are not present in the US and UK regulations. The US and UK take a more experimental approach to AI development, while the EU has a more structured regulatory framework.\n",
      "\n",
      "Please note that this information is based on the search results and may not be exhaustive.\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To summarize the overall trends and developments in AI regulations globally, I can review the previous steps and extract the key information. This will include the current state of AI regulations in different countries, the key areas covered by the regulations, and any notable differences or similarities between countries.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The overall trends and developments in AI regulations globally are as follows: The European Union (EU) has approved the AI Act, which categorizes AI systems based on potential harm and introduces transparency and risk-management rules. Exemptions are provided for research activities and AI components under open-source licenses, and regulatory sandboxes are promoted for testing AI before deployment. Citizens have the right to file complaints about AI systems and receive explanations of decisions. The EU AI Office will monitor the implementation of the AI rulebook. In the United States (US) and the United Kingdom (UK), there is no comprehensive federal AI regulation in place yet. Both countries take an experimental approach to AI development, with market and product fit established first, followed by retrofitting to regulatory frameworks. The UK is more likely to align with the EU ruleset due to the proximity of the EU market. Notable differences include the EU's categorization of AI systems based on potential harm and the promotion of regulatory sandboxes, which are not present in the US and UK regulations. The US and UK prioritize innovation among AI developers. Please note that this information is based on the search results and may not be exhaustive.\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Summarize the overall trends and developments in AI regulations globally.\n",
      "\n",
      "Response: The overall trends and developments in AI regulations globally are as follows: The European Union (EU) has approved the AI Act, which categorizes AI systems based on potential harm and introduces transparency and risk-management rules. Exemptions are provided for research activities and AI components under open-source licenses, and regulatory sandboxes are promoted for testing AI before deployment. Citizens have the right to file complaints about AI systems and receive explanations of decisions. The EU AI Office will monitor the implementation of the AI rulebook. In the United States (US) and the United Kingdom (UK), there is no comprehensive federal AI regulation in place yet. Both countries take an experimental approach to AI development, with market and product fit established first, followed by retrofitting to regulatory frameworks. The UK is more likely to align with the EU ruleset due to the proximity of the EU market. Notable differences include the EU's categorization of AI systems based on potential harm and the promotion of regulatory sandboxes, which are not present in the US and UK regulations. The US and UK prioritize innovation among AI developers. Please note that this information is based on the search results and may not be exhaustive.\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Based on the steps taken, here is an overview of Artificial Intelligence regulations by governments in different countries:\\n\\n1. European Union (EU):\\n- The EU has approved the AI Act, which categorizes AI systems based on potential harm.\\n- The AI Act introduces transparency and risk-management rules for AI systems.\\n- Exemptions are provided for research activities and AI components under open-source licenses.\\n- Regulatory sandboxes are promoted to test AI before deployment.\\n- Citizens have the right to file complaints about AI systems and receive explanations of decisions.\\n- The EU AI Office will monitor the implementation of the AI rulebook.\\n\\n2. United States (US):\\n- The US does not have comprehensive federal AI regulation in place yet.\\n- The US takes an experimental approach to AI development.\\n- Market and product fit is established first, followed by retrofitting to regulatory frameworks.\\n- This approach fosters innovation among US-based AI developers.\\n\\n3. United Kingdom (UK):\\n- The UK is adopting a similar approach to the US in terms of AI regulation.\\n- However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\\n- The UK also has the potential for regulatory sandboxes to experiment in a safe space.\\n\\nPlease note that this information is based on the steps taken and may not be exhaustive.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Given the above steps taken, provide an overview of Artificial Intelligence regulations by governments by country. \n",
      "\n",
      "Response: Based on the steps taken, here is an overview of Artificial Intelligence regulations by governments in different countries:\n",
      "\n",
      "1. European Union (EU):\n",
      "- The EU has approved the AI Act, which categorizes AI systems based on potential harm.\n",
      "- The AI Act introduces transparency and risk-management rules for AI systems.\n",
      "- Exemptions are provided for research activities and AI components under open-source licenses.\n",
      "- Regulatory sandboxes are promoted to test AI before deployment.\n",
      "- Citizens have the right to file complaints about AI systems and receive explanations of decisions.\n",
      "- The EU AI Office will monitor the implementation of the AI rulebook.\n",
      "\n",
      "2. United States (US):\n",
      "- The US does not have comprehensive federal AI regulation in place yet.\n",
      "- The US takes an experimental approach to AI development.\n",
      "- Market and product fit is established first, followed by retrofitting to regulatory frameworks.\n",
      "- This approach fosters innovation among US-based AI developers.\n",
      "\n",
      "3. United Kingdom (UK):\n",
      "- The UK is adopting a similar approach to the US in terms of AI regulation.\n",
      "- However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\n",
      "- The UK also has the potential for regulatory sandboxes to experiment in a safe space.\n",
      "\n",
      "Please note that this information is based on the steps taken and may not be exhaustive.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# we test the agent\n",
    "response = agent.run(\"Write an overview of Artificial Intelligence regulations by governments by country\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
