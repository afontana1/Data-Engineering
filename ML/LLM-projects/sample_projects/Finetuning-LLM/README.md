# Finetuning-LLM

## Finetuning using Mistral with QLora and PEFt

This section provides a guide on how to perform finetuning using Mistral with QLora and PEFt. The process involves the following steps:

1. **Setup Environment**: Ensure that your environment is set up with all the necessary dependencies for Mistral, QLora, and PEFt.
2. **Prepare Data**: Prepare your dataset for finetuning. This involves preprocessing your data into a suitable format for training.
3. **Configure Finetuning Parameters**: Set up the finetuning parameters, including the learning rate, batch size, and the number of epochs.
4. **Initiate Finetuning**: Start the finetuning process using Mistral with the QLora and PEFt configurations.
5. **Evaluate Model**: After finetuning, evaluate the performance of your model on a validation set to ensure that it meets your expectations.
6. **Deploy Model**: Once satisfied with the model's performance, you can deploy it for inference.

For a detailed demonstration of the finetuning process using Mistral, QLora, and PEFt, refer to the notebook `Fine_Tuning_with_Mistral_QLora_PEFt.ipynb` included in this repository.
