{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Add scraped data from GCS bucket to Weaviate\n",
        "\n",
        "###### Run this notebook to add **new** scarped data for websites in our GCS bucket. Files that already exist in Weaviate will be skipped."
      ],
      "metadata": {
        "id": "V-Pbk2D2a3fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "!pip install weaviate-client\n",
        "!pip install llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlZq6fQja3pN",
        "outputId": "611a9240-aa96-405c-bea1-b1d9b3a6f1c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-3.25.3-py3-none-any.whl (120 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/120.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/120.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (2.31.0)\n",
            "Collecting validators<1.0.0,>=0.21.2 (from weaviate-client)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.2.1-py2.py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=3.2 in /usr/local/lib/python3.10/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (41.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2023.7.22)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.2->authlib<2.0.0,>=1.2.1->weaviate-client) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.2->authlib<2.0.0,>=1.2.1->weaviate-client) (2.21)\n",
            "Installing collected packages: validators, authlib, weaviate-client\n",
            "Successfully installed authlib-1.2.1 validators-0.22.0 weaviate-client-3.25.3\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.9.3.post1-py3-none-any.whl (886 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.0/887.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.6)\n",
            "Collecting aiostream<0.6.0,>=0.5.2 (from llama-index)\n",
            "  Downloading aiostream-0.5.2-py3-none-any.whl (39 kB)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.12.2 (from llama-index)\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json<0.6.0,>=0.5.7 (from llama-index)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
            "Collecting httpx (from llama-index)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n",
            "Collecting openai>=1.1.0 (from llama-index)\n",
            "  Downloading openai-1.3.3-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas[jinja2] in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting urllib3<2 (from llama-index)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index) (2.5)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->llama-index)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index) (1.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (4.66.1)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (1.10.13)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (2023.7.22)\n",
            "Collecting httpcore (from httpx->llama-index)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (1.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.3.3->llama-index) (2.31.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "\u001b[33mWARNING: pandas 1.5.3 does not provide the extra 'jinja2'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas[jinja2]->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas[jinja2]->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai>=1.1.0->llama-index) (1.1.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->llama-index) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas[jinja2]->llama-index) (1.16.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore->httpx->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, mypy-extensions, marshmallow, h11, deprecated, beautifulsoup4, aiostream, typing-inspect, httpcore, tiktoken, httpx, dataclasses-json, openai, llama-index\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiostream-0.5.2 beautifulsoup4-4.12.2 dataclasses-json-0.5.14 deprecated-1.2.14 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 llama-index-0.9.3.post1 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.3.3 tiktoken-0.5.1 typing-inspect-0.9.0 urllib3-1.26.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import json\n",
        "from google.cloud import storage\n",
        "from google.oauth2 import service_account\n",
        "from datetime import datetime, timezone\n",
        "from weaviate import Client\n",
        "import pandas as pd\n",
        "from datetime import datetime, timezone\n",
        "from weaviate import Client\n",
        "from weaviate.exceptions import UnexpectedStatusCodeException\n",
        "from google.cloud import storage\n",
        "\n",
        "# Additional imports for the llama_index module\n",
        "from llama_index import Document\n",
        "from llama_index.node_parser import SimpleNodeParser\n",
        "from llama_index.vector_stores import WeaviateVectorStore\n",
        "from llama_index import VectorStoreIndex, StorageContext\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "from io import BytesIO\n",
        "from llama_index.vector_stores.types import ExactMatchFilter, MetadataFilters\n",
        "\n",
        "# Define the Weaviate IP address\n",
        "WEAVIATE_IP_ADDRESS = \"34.42.138.162\"\n",
        "\n",
        "# Set OpenAI API key in the environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "MtaYiYiOa9W-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def authenticate_with_service_account(key_path):\n",
        "    \"\"\"\n",
        "    Authenticate using a service account key.\n",
        "\n",
        "    Parameters:\n",
        "    - key_path (str): Path to the service account key file.\n",
        "\n",
        "    Returns:\n",
        "    - credentials (google.auth.credentials.Credentials): Google Cloud credentials.\n",
        "    \"\"\"\n",
        "    credentials = service_account.Credentials.from_service_account_file(\n",
        "        key_path,\n",
        "        scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
        "    )\n",
        "    return credentials\n",
        "\n",
        "def text_chunk_exists(client, website_address, timestamp):\n",
        "    \"\"\"\n",
        "    Check if a TextChunk with a specific website address and timestamp already exists in Weaviate.\n",
        "\n",
        "    Parameters:\n",
        "    - client (weaviate.Client): The Weaviate client object to interact with the Weaviate instance.\n",
        "    - website_address (str): The website address to check.\n",
        "    - timestamp (str): The timestamp to check in RFC 3339 format.\n",
        "\n",
        "    Returns:\n",
        "    - bool: True if the Pages exists in Weaviate, False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    # GraphQL query to retrieve Pages based on website address and timestamp\n",
        "    query = f\"\"\"\n",
        "    {{\n",
        "      Get {{\n",
        "        Pages (where: {{\n",
        "            operator: And\n",
        "            operands: [{{\n",
        "                path: [\"websiteAddress\"],\n",
        "                operator: Equal,\n",
        "                valueString: \"{website_address}\"\n",
        "            }}, {{\n",
        "                path: [\"timestamp\"],\n",
        "                operator: Equal,\n",
        "                valueText: \"{timestamp}\"\n",
        "            }}]\n",
        "        }}) {{\n",
        "          __typename\n",
        "        }}\n",
        "      }}\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    result = client.query.raw(query)\n",
        "    print(result) # Print the result for debugging\n",
        "\n",
        "    # # Check if the Pages exists based on the query results\n",
        "    # return result['data']['Get']['Pages'] is not None\n",
        "\n",
        "    # Check if the Pages exists based on the query results\n",
        "    return len(result['data']['Get']['Pages']) > 0\n",
        "\n",
        "\n",
        "def extract_website_and_timestamp(filename):\n",
        "    \"\"\"\n",
        "    Extract website address and timestamp from a filename.\n",
        "    Split the filename by '_' and check if there are at least two parts\n",
        "\n",
        "    Parameters:\n",
        "    - filename (str): The input filename.\n",
        "\n",
        "    Returns:\n",
        "    - website_address (str): Extracted website address.\n",
        "    - timestamp (str): Extracted timestamp.\n",
        "    \"\"\"\n",
        "    filename_parts = filename.split('_')\n",
        "    if len(filename_parts) >= 2:\n",
        "        website_address, timestamp = filename_parts[0][len(\"data/\"):], filename_parts[1].split('.csv')[0]\n",
        "        return website_address, timestamp\n",
        "    else:\n",
        "        # Handle the case where the filename doesn't match the expected structure\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "Y0zMZWqtio4Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate to allow access to GCS\n",
        "credentials = authenticate_with_service_account(key_path = \"key/sample_data/rag-detective-389f2d6f87a9.json\")\n",
        "\n",
        "# Define name of GCS bucket\n",
        "bucket_name = \"ac215_scraper_bucket\""
      ],
      "metadata": {
        "id": "o7Qhi4NgjlTc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Google Cloud Storage client and bucket\n",
        "storage_client = storage.Client(credentials=credentials)\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "# List all files in the bucket\n",
        "files = bucket.list_blobs()\n",
        "\n",
        "# Set up Weaviate client\n",
        "client = Client(url=\"http://\" + WEAVIATE_IP_ADDRESS + \":8080\")\n",
        "\n",
        "# Iterate through each file in the bucket\n",
        "for file in files:\n",
        "    csv_file = os.path.basename(file.name)\n",
        "    print(csv_file)\n",
        "\n",
        "    # Extract website_address and timestamp\n",
        "    website_address, timestamp = extract_website_and_timestamp(file.name)\n",
        "\n",
        "    # Print the extracted values\n",
        "    print(f\"Website Address: {website_address}\")\n",
        "    print(f\"Timestamp: {timestamp}\")\n",
        "\n",
        "    # Now, call the text_chunk_exists function with the extracted values\n",
        "    result = text_chunk_exists(client, website_address, timestamp)\n",
        "    print(result)\n",
        "\n",
        "    # If file is not in Weaviate, add it!\n",
        "    if result == False:\n",
        "      print(f\"Adding {csv_file} to Weaviate!\")\n",
        "\n",
        "      # Get the blob from the bucket\n",
        "      filename = file.name\n",
        "      blob = bucket.blob(filename)\n",
        "\n",
        "      # Download the file contents as bytes\n",
        "      file_contents = blob.download_as_bytes()\n",
        "\n",
        "      # Use BytesIO to convert the bytes content to a file-like object\n",
        "      file_like_object = BytesIO(file_contents)\n",
        "\n",
        "      # Create a Pandas DataFrame from the file-like object\n",
        "      df = pd.read_csv(file_like_object)\n",
        "      print(df.head())\n",
        "\n",
        "      # Manually assemble the documents\n",
        "      documents = []\n",
        "      for _, row in df.iterrows():\n",
        "          document = Document(\n",
        "              text=row['text'],\n",
        "              metadata={\n",
        "                  'websiteAddress': website_address,\n",
        "                  'timestamp': timestamp\n",
        "              }\n",
        "          )\n",
        "          document.doc_id = row['key']\n",
        "          documents.append(document)\n",
        "\n",
        "      # Create the parser and nodes\n",
        "      parser = SimpleNodeParser.from_defaults(chunk_size=1024, chunk_overlap=20)\n",
        "      nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "      # construct vector store\n",
        "      vector_store = WeaviateVectorStore(weaviate_client = client, index_name=\"Pages\", text_key=\"text\")\n",
        "      # setting up the storage for the embeddings\n",
        "      storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
        "      # set up the index\n",
        "      index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
        "\n",
        "      print(f\"Added {csv_file} to Weaviate!\")"
      ],
      "metadata": {
        "id": "MoajigS5eU1_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}