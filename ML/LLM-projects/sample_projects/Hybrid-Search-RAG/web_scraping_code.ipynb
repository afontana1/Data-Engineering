{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "# URL of the XML sitemap\n",
    "sitemap_url = 'https://www.ey.com/en_in/sitemap/topics.xml'\n",
    "\n",
    "# Fetch the XML content from the URL\n",
    "response = requests.get(sitemap_url)\n",
    "xml_content = response.content\n",
    "\n",
    "# Parse the XML content\n",
    "root = ET.fromstring(xml_content)\n",
    "\n",
    "# Define the namespace if needed (based on your XML structure)\n",
    "namespace = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "\n",
    "# Open a CSV file for writing\n",
    "with open('sitemap_data.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header row\n",
    "    csv_writer.writerow(['Website', 'Date'])\n",
    "    \n",
    "    # Extract and write the links and dates\n",
    "    for url in root.findall('.//ns:url', namespace):\n",
    "        loc = url.find('ns:loc', namespace).text\n",
    "        lastmod = url.find('ns:lastmod', namespace).text\n",
    "        # Write the row to the CSV file\n",
    "        csv_writer.writerow([loc, lastmod])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Function to extract content from a blog URL\n",
    "def extract_blog_content(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Extract author name\n",
    "            author_div = soup.find('div', class_='surfaceProfile-author-description')\n",
    "            if author_div:\n",
    "                author_name_tag = author_div.find('a')\n",
    "                author_name = author_name_tag.get_text(strip=True) if author_name_tag else ''\n",
    "            else:\n",
    "                author_name = ''\n",
    "            \n",
    "            # Extract related topics\n",
    "            related_topics_div = soup.find('div', class_='col-xs-12 col-sm-8 col-sm-offset-1 col-md-12 col-md-offset-0 col-lg-offset-0 default-style')\n",
    "            if related_topics_div:\n",
    "                related_topics_tags = related_topics_div.find_all('a')\n",
    "                related_topics = ', '.join(tag.get_text(strip=True) for tag in related_topics_tags)\n",
    "            else:\n",
    "                related_topics = ''\n",
    "            \n",
    "            # Extract page content\n",
    "            def extract_markdown_content(div):\n",
    "                markdown_content = []\n",
    "                for element in div:\n",
    "                    if element.name == 'h1':\n",
    "                        markdown_content.append(f\"# {element.get_text(strip=True)}\")\n",
    "                    elif element.name == 'h2':\n",
    "                        markdown_content.append(f\"## {element.get_text(strip=True)}\")\n",
    "                    elif element.name == 'p':\n",
    "                        markdown_content.append(f\"{element.get_text(strip=True)}\")\n",
    "                    elif element.name == 'ul':\n",
    "                        for li in element.find_all('li', recursive=False):\n",
    "                            markdown_content.append(f\"- {li.get_text(strip=True)}\")\n",
    "                    elif element.name == 'li':\n",
    "                        markdown_content.append(f\"- {element.get_text(strip=True)}\")\n",
    "                return \"\\n\".join(markdown_content)\n",
    "            \n",
    "            main_div = soup.find('div', class_='optional-components paragraphSystem')\n",
    "            if main_div:\n",
    "                content_divs = main_div.find_all('div', class_='richText component section richText-copy-block col-xs-12')\n",
    "                markdown_content = []\n",
    "                for content_div in content_divs:\n",
    "                    inner_div = content_div.find('div', class_='component-content')\n",
    "                    if inner_div:\n",
    "                        rich_text_div = inner_div.find('div', class_='richText-content')\n",
    "                        if rich_text_div:\n",
    "                            markdown_content.append(extract_markdown_content(rich_text_div.children))\n",
    "                \n",
    "                page_content = \"\\n\\n\".join(markdown_content)\n",
    "            else:\n",
    "                page_content = ''\n",
    "            \n",
    "            # Extract unique PDF links\n",
    "            pdf_links = set()\n",
    "            pdf_divs = soup.find_all('div', class_='fileList-download')\n",
    "            for pdf_div in pdf_divs:\n",
    "                pdf_link_tag = pdf_div.find('a', class_='fileList-download-link')\n",
    "                if pdf_link_tag:\n",
    "                    pdf_link = pdf_link_tag.get('href')\n",
    "                    if pdf_link:\n",
    "                        pdf_links.add(pdf_link)\n",
    "            \n",
    "            return author_name, related_topics, list(pdf_links), page_content\n",
    "        else:\n",
    "            return '', '', [], ''\n",
    "    except Exception as e:\n",
    "        return '', '', [], ''\n",
    "\n",
    "# Read CSV file\n",
    "input_file = 'sitemap_data.csv'\n",
    "output_file = 'blogs_data_500.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "# Iterate through each website in the CSV and extract data\n",
    "for index, row in df.iterrows():\n",
    "    website_url = row['Website']\n",
    "    start_time = time.time()\n",
    "    author_name, related_topics, pdf_links, page_content = extract_blog_content(website_url)\n",
    "    print(time.time()-start_time)\n",
    "    # Store extracted data in the DataFrame\n",
    "    df.at[index, 'author_name'] = author_name\n",
    "    df.at[index, 'related_topics'] = related_topics\n",
    "    df.at[index, 'pdf_links'] = ', '.join(pdf_links)  # Join list into a string\n",
    "    df.at[index, 'page_content'] = page_content\n",
    "\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "print(\"Content extraction complete. Data saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_unstructured():\n",
    "    import pandas as pd\n",
    "    content = []\n",
    "    df = pd.read_csv('blogs_data_500.csv')\n",
    "    websites = df['Website'].tolist()\n",
    "    loader = UnstructuredURLLoader(websites)\n",
    "    loaded_data = loader.load()\n",
    "    for data in loaded_data:\n",
    "        content.append(data.page_content)\n",
    "    return content\n",
    "\n",
    "def data_preprocessing():\n",
    "    content = data_loading_unstructured()\n",
    "    df = pd.read_csv('blogs_data_500.csv')\n",
    "    new_data = pd.DataFrame({'page_content':content})\n",
    "    df = df.drop('page_content',axis=1)\n",
    "    concate_df = pd.concat([df, new_data],axis=1)\n",
    "    concate_df['author_name'] = concate_df['author_name'].apply(lambda x:str(x))\n",
    "    concate_df['related_topics'] = concate_df['related_topics'].apply(lambda x:str(x))\n",
    "    concate_df['pdf_links'] = concate_df['related_topics'].apply(lambda x:str(x))\n",
    "    concate_df['page_content'] = concate_df['page_content'].apply(lambda x:str(x))\n",
    "    concate_df = concate_df[concate_df['page_content']!=\"A custom errorhandler for 404 responses\"]\n",
    "    concate_df = concate_df.reset_index(drop=True)\n",
    "    concate_df['page_content'] = concate_df['page_content'].apply(lambda x:str(x))\n",
    "    unstructured_data = concate_df.copy()\n",
    "    for i, rows in unstructured_data.iterrows():\n",
    "    result = rows[5]\n",
    "    strings_to_remove = [\n",
    "        \"with us\\n\\nOur locations\\n\\nMy EY\\n\\nSite map\\n\\nLegal and privacy\\n\\nOpen Facebook profile\\n\\nOpen X profile\\n\\nOpen LinkedIn profile\\n\\nOpen Youtube profile\\n\\nEY refers to the global organization, and may refer to one or more, of the member firms of Ernst & Young Global Limited, each of which is a separate legal entity. Ernst & Young Global Limited, a UK company limited by guarantee, does not provide services to clients.\\n\\nYou are visiting EY in (en)\\n\\nin en\",\n",
    "        \"EY Logo\\n\\nInsights\\n\\nAsking the better questions that unlock new answers to the working world's most complex issues.\\n\\nExplore\\n\\nTrending topics\\n\\nSee more\\n\\nSee more\\n\\nSpotlight\\n\\nAI insights\\n\\nCEO agenda\\n\\nCFO agenda\\n\\nEY Center for board matters\\n\\nEY podcasts\\n\\nEY webcasts\\n\\nOperations leaders\\n\\nTechnology leaders\\n\\nSee more\\n\\nServices\\n\\nEY helps clients create long-term value for all stakeholders. Enabled by data and technology, our services and solutions provide trust through assurance and help clients transform, grow and operate.\\n\\nExplore\\n\\nSee more\\n\\nSpotlight\\n\\nEY.ai - A unifying platform\\n\\nStrategy, transaction and transformation consulting\\n\\nTechnology transformation\\n\\nTax function operations\\n\\nClimate change and sustainability services\\n\\nEY Ecosystems\\n\\nEY Nexus: business transformation platform\\n\\nIndustries\\n\\nDiscover how EY insights and services are helping to reframe the future of your industry.\\n\\nExplore\\n\\nSee more\\n\\nCase studies\\n\\nAdvanced Manufacturing\\n\\nHow a manufacturer eliminates cost and value leakages with AI-ML\\n\\n03 Jul 2024Vinayak vipul\\n\\nConsulting\\n\\nHow a young cement company grew 2.5x with organizational and functional transformation\\n\\n05 Apr 2024EY India\\n\\nAI\\n\\nHow a state government transformed into an ecotourism haven\\n\\n12 Mar 2024EY India\\n\\nCareers\\n\\nWe bring together extraordinary people, like you, to build a better working world.\\n\\nExplore\\n\\nSee more\\n\\nSpotlight\\n\\nExperienced professionals\\n\\nEY-Parthenon careers\\n\\nStudent and entry level programs\\n\\nTalent community\\n\\nAbout us\\n\\nAt EY, our purpose is building a better working world. The insights and services we provide help to create long-term value for clients, people and society, and to build trust in the capital markets.\\n\\nExplore\\n\\nSee more\\n\\nSpotlight\\n\\nEY expands its EY ESG Compass platform with new innovative use-cases\\n\\n06 Aug 2024EY India\\n\\nAddressing customs, payment, and logistics challenges key to stronger e-commerce exports growth from India: EY-ASSOCHAM report\\n\\n24 Jul 2024EY India\\n\\nPE/VC investments in May 2024 exceeded US$6.9 billion across 115 deals, 54% growth Y-o-Y: EY-IVCA report\\n\\n01 Jul 2024EY India\\n\\nSearch\\n\\nSee all results for ' '\\n\\nNo results have been found\\n\\nTopics\\n\\nSee All\\n\\nGeneral\\n\\nSee All\\n\\nPeople\\n\\nSee All\\n\\nRecent Searches\\n\\nTrending\\n\\nUnion Budget 2024-25: Accelerating fiscal consolidation for sustained growth\\n\\nUnion Budget 2024-25: Drive fiscal consolidation for lower interest rates, boost private investment, and job growth.\\n\\n26 Jul 2024 Tax\\n\\nHow India Inc. can navigate the road to financial resilience\\n\\nExplore key findings from the 2024 Cost of Capital Survey, revealing insights into India Inc.'s financial resilience and strategic growth.\\n\\n17 Jul 2024\\n\\nImpact of new GST law on skill-based online games\\n\\nExplore the effects of the new GST law on skill-based online gaming. Understand the implications for players and industry with our in-depth analysis.\\n\\n04 Jul 2024 Tax\\n\\nMy EY My EY\\n\\nSelect your location\\n\\nLocal\",\n",
    "        \"Facebook\\n\\nTwitter\\n\\nLinkedIn\\n\\nLink Copied\",\n",
    "        \"Related articles\",\n",
    "        \"Rebecca Dabbs\\n\\nHow EY can help\\n\\nEnvironment, health and safety\\n\\nEY CCaSS teams can help reduce the risk of EHS incidents and support decision-making to improve outcomes associated with EHS. Find out how.\\n\\nRead more\\n\\nConnect\",\n",
    "        \"\\n\\nRead more\\n\\nConnect \",\n",
    "        \" sites\\n\\n\",\n",
    "        \"Related topics\",\n",
    "        \"Read more\",\n",
    "        \"Connect \",\n",
    "        \"Subscribe\",\n",
    "        \"Contact us to learn more\",\n",
    "        \"Like what you’ve seen? Get in touch to learn more.\",\n",
    "        \"Direct to your inbox\",\n",
    "        \"Stay up to date with our Editor‘s picks newsletter.\"\n",
    "    ]\n",
    "    for string_to_remove in strings_to_remove:\n",
    "        result = re.sub(re.escape(string_to_remove), '', result)\n",
    "    unstructured_data.at[i, 'page_content'] = result\n",
    "    return unstructured_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
