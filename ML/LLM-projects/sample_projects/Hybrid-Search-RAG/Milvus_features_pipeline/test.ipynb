{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c9d994-306e-402b-ac89-cb3f32ef79b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU \"semantic-router[fastembed]\" langchain langchain_community==0.2.6 fastembed==0.3.2 langchain_core openai pymilvus bs4 \"grpcio<=1.63.0,>=1.49.1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50eca98-19c1-49c9-8518-815fce37a436",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_76/2354882201.py\", line 8, in <module>\n",
      "    from pymilvus import FieldSchema, CollectionSchema, DataType, Collection, connections, utility\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pymilvus/__init__.py\", line 13, in <module>\n",
      "    from .client import __version__\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pymilvus/client/__init__.py\", line 15, in <module>\n",
      "    __version__ = get_distribution(\"pymilvus\").version\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pkg_resources/__init__.py\", line 478, in get_distribution\n",
      "    # through to the default implementation\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pkg_resources/__init__.py\", line 354, in get_provider\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pkg_resources/__init__.py\", line 909, in require\n",
      "    processed.add(req)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pkg_resources/__init__.py\", line 800, in resolve\n",
      "    # ignore hidden distros\n",
      "pkg_resources.ContextualVersionConflict: (setuptools 65.6.3 (/opt/conda/lib/python3.10/site-packages), Requirement.parse('setuptools>69'), {'pymilvus'})\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "from langchain_core.documents import Document\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from openai import OpenAI\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType, Collection, connections, utility\n",
    "from typing import Any, List, Tuple, Dict, Literal, Optional\n",
    "from pydantic import Field\n",
    "from semantic_router.schema import DocumentSplit\n",
    "from langchain_core.documents import Document\n",
    "from semantic_router.splitters import RollingWindowSplitter\n",
    "from semantic_router.utils.logger import logger\n",
    "from semantic_router.encoders import FastEmbedEncoder\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f9c63d-218e-42aa-9f0c-edc2cfb00580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_main_links(url):\n",
    "  response = requests.get(url)\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "  main_links = []\n",
    "\n",
    "  # Extracting links with \"index.html\" considering nesting\n",
    "  for a in soup.find_all('a', href=True):\n",
    "    href = a['href']\n",
    "    if href and href.endswith(\"index.html\"):  # Check for ending with \"index.html\"\n",
    "      full_url = urljoin(url, href)\n",
    "      # Avoid duplicate links and links pointing to external domains\n",
    "      if full_url not in main_links and full_url.startswith(url):\n",
    "        main_links.append(full_url)\n",
    "\n",
    "  return main_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac3ca306-1956-402b-a1ee-f10311e1aebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"https://www.ey.com/en_in/supply-chain\")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b300e2a4-f185-4fe9-abf8-1fdce793e9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_div = soup.find('div', class_='contentGridGeneral component section default-style col-xs-12')\n",
    "\n",
    "# Extract all links (anchor tags) within the target div\n",
    "if target_div:\n",
    "    links = target_div.find_all('a', href=True)\n",
    "    for link in links:\n",
    "        print(link['href'])\n",
    "else:\n",
    "    print(\"Target div not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ef24fcf-665c-478d-b2ff-2127d4306d19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<h3 class=\"content-grid-title\">Our latest thinking</h3>\n",
      "<div class=\"row\"></div>\n",
      "<div class=\"controls\">\n",
      "<div class=\"is-hidden buttons\">\n",
      "<button class=\"show-more\">Show more</button>\n",
      "</div>\n",
      "<div class=\"is-hidden pagination\">\n",
      "<button class=\"is-disabled prev\"><span class=\"arrow\"></span>Previous</button>\n",
      "<div class=\"pagination-list\"></div>\n",
      "<button class=\"is-disabled next\"><span class=\"arrow\"></span>Next</button>\n",
      "</div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# URL of the page\n",
    "url = 'https://www.ey.com/en_in/supply-chain'  # Replace with the actual URL\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Locate the element\n",
    "content_grid_element = soup.find('div', class_='content-grid animation-part-on container grid is-hidden')\n",
    "\n",
    "# Get the content\n",
    "content = content_grid_element.decode_contents()  # Or use .text for just the text content\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7124c93a-7801-41e3-9f2c-51666ae4b6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author Name: Alexy ThomasByAlexy ThomasPartner, Technology Consulting, EY IndiaTechnology enthusiast, Data-driven.\n",
      "Related Topics: Related topicsTechnologySustainabilityDigitalTechnology leader's agendaEmerging technology\n",
      "Page Content: Software industry must adopt green coding and efficient algorithms to curb rising carbon emissions.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the blog\n",
    "url = \"https://www.ey.com/en_in/technology/sustainable-coding-is-the-need-for-a-greener-tomorrow\"\n",
    "\n",
    "# Send a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extract the author name\n",
    "    author_div = soup.find('div', class_='surfaceProfile-author-description')\n",
    "    author_name = author_div.get_text(strip=True) if author_div else 'Author not found'\n",
    "    \n",
    "    # Extract related topics\n",
    "    related_topics_div = soup.find('div', class_='col-xs-12 col-sm-8 col-sm-offset-1 col-md-12 col-md-offset-0 col-lg-offset-0 default-style')\n",
    "    related_topics = related_topics_div.get_text(strip=True) if related_topics_div else 'Related topics not found'\n",
    "    \n",
    "    # Extract page content\n",
    "    content_div = soup.find('div', class_='richText component section richText-copy-block col-xs-12')\n",
    "    page_content = content_div.get_text(strip=True) if content_div else 'Page content not found'\n",
    "    \n",
    "    # Print extracted information\n",
    "    print(\"Author Name:\", author_name)\n",
    "    print(\"Related Topics:\", related_topics)\n",
    "    print(\"Page Content:\", page_content)\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95f7a66e-1c99-45fb-966e-30b40b82f906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author Name: Alexy ThomasByAlexy ThomasPartner, Technology Consulting, EY IndiaTechnology enthusiast, Data-driven.\n",
      "Related Topics: Related topicsTechnologySustainabilityDigitalTechnology leader's agendaEmerging technology\n",
      "Page Content (Markdown):\n",
      " \n",
      "\n",
      "In May 2021, industry giants Microsoft, Thoughtworks, Accenture, and GitHub teamed up with the Joint Development Foundation Projects and The Linux Foundation to launch the Green Software Foundation. This non-profit is laser-focused on building a community for eco-friendly software development. The driving forces? A growing corporate awareness of the energy toll exacted by software development and operation— a pressing concern in our digital space. Until recently, sustainability in software and architectures took a back seat, with many companies mistakenly assuming that, unlike hardware, software did not pose environmental challenges. However, this perception shifted as it became clear that while software does not directly consume energy, poor development practices and its influence on computer hardware significantly impact overall energy consumption and carbon emissions.\n",
      "\n",
      "According to Green Software Foundation, to calculate the operational emissions associate with software, multiply the electricity consumption of the hardware the software is running on by the regional, granular marginal emissions rate. The marginal emissions rate reflects the change in emissions associated with a change in demand.\n",
      "Testing formula for Sustainability\n",
      "SCI  =  (E * I)  +  M  per  R\n",
      "Where:\n",
      "E = Energy Consumption (kilowatt hours) for different components of the software boundary over a given time period\n",
      "I = Emissions Factors – available from GHG Protocol, but should be tracked down to the regional level if possible\n",
      "M = Embodied emissions data for servers, laptops and other devices used in the relevant area.\n",
      "R = Functional Unit being used (e.g., CO2e; days; etc. )\n",
      "\n",
      "What you can do\n",
      "- Architect: Engineers and architects have to work more closely together to produce the most sustainable code. Architect should choose the best possible framework.\n",
      "- Developer: They can control code reuse, select patterns, choose language and how to build CD/CI release trains. Developers can also utilize IDE plugins and other tools to monitor electricity use in real time.\n",
      "- Tester: Testing and measuring application software’s carbon intensity at various release and deployment cycles.\n",
      "- UX designer: Reimagine every step of the user journey and design process infused with sustainability. User journeys should be under constant review and improvement.\n",
      "- Infra architect: Adopt shared and managed services model to reduce amount of infra needed.\n",
      "- DevOps engineer: Should have clear test goals.  Deploy DevOps processes that will support environmental testing in CD/CI cycles, utilizing standard industry.\n",
      "PDF Links: ['https://assets.ey.com/content/dam/ey-sites/ey-com/en_in/topics/technology/2024/ey-tech-trends-2024.pdf?download', 'https://assets.ey.com/content/dam/ey-sites/ey-com/en_in/topics/technology/2024/ey-tech-trends-2024.pdf?download']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the blog\n",
    "url = \"https://www.ey.com/en_in/technology/sustainable-coding-is-the-need-for-a-greener-tomorrow\"\n",
    "\n",
    "# Send a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extract the author name\n",
    "    author_div = soup.find('div', class_='surfaceProfile-author-description')\n",
    "    author_name = author_div.get_text(strip=True) if author_div else 'Author not found'\n",
    "    \n",
    "    # Extract related topics\n",
    "    related_topics_div = soup.find('div', class_='col-xs-12 col-sm-8 col-sm-offset-1 col-md-12 col-md-offset-0 col-lg-offset-0 default-style')\n",
    "    related_topics = related_topics_div.get_text(strip=True) if related_topics_div else 'Related topics not found'\n",
    "    \n",
    "    # Extract page content\n",
    "    def extract_markdown_content(div):\n",
    "        markdown_content = []\n",
    "        for element in div:\n",
    "            if element.name == 'h1':\n",
    "                markdown_content.append(f\"# {element.get_text(strip=True)}\")\n",
    "            elif element.name == 'h2':\n",
    "                markdown_content.append(f\"## {element.get_text(strip=True)}\")\n",
    "            elif element.name == 'p':\n",
    "                markdown_content.append(f\"{element.get_text(strip=True)}\")\n",
    "            elif element.name == 'ul':\n",
    "                for li in element.find_all('li', recursive=False):\n",
    "                    markdown_content.append(f\"- {li.get_text(strip=True)}\")\n",
    "            elif element.name == 'li':\n",
    "                markdown_content.append(f\"- {element.get_text(strip=True)}\")\n",
    "        return \"\\n\".join(markdown_content)\n",
    "    \n",
    "    # Navigate through the hierarchy to find content\n",
    "    main_div = soup.find('div', class_='optional-components paragraphSystem')\n",
    "    if main_div:\n",
    "        content_divs = main_div.find_all('div', class_='richText component section richText-copy-block col-xs-12')\n",
    "        markdown_content = []\n",
    "        for content_div in content_divs:\n",
    "            inner_div = content_div.find('div', class_='component-content')\n",
    "            if inner_div:\n",
    "                rich_text_div = inner_div.find('div', class_='richText-content')\n",
    "                if rich_text_div:\n",
    "                    markdown_content.append(extract_markdown_content(rich_text_div.children))\n",
    "        \n",
    "        page_content = \"\\n\\n\".join(markdown_content)\n",
    "    else:\n",
    "        page_content = 'Page content not found'\n",
    "    \n",
    "    # Extract PDF download links\n",
    "    pdf_links = []\n",
    "    pdf_divs = soup.find_all('div', class_='fileList-download')\n",
    "    for pdf_div in pdf_divs:\n",
    "        pdf_link_tag = pdf_div.find('a', class_='fileList-download-link')\n",
    "        if pdf_link_tag:\n",
    "            pdf_link = pdf_link_tag.get('href')\n",
    "            if pdf_link:\n",
    "                pdf_links.append(pdf_link)\n",
    "    \n",
    "    # Print extracted information\n",
    "    print(\"Author Name:\", author_name)\n",
    "    print(\"Related Topics:\", related_topics)\n",
    "    print(\"Page Content (Markdown):\\n\", page_content)\n",
    "    print(\"PDF Links:\", pdf_links)\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789cfe6f-accb-42bf-ae9e-dcce2a3855fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616037ef-5169-45f1-a403-24258ae2f5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
