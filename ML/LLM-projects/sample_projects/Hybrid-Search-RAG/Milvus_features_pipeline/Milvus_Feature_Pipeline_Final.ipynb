{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU \"semantic-router[fastembed]\" langchain langchain_community==0.2.6 fastembed==0.3.2 langchain_core openai pymilvus bs4 \"grpcio<=1.63.0,>=1.49.1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.1.16 requires tiktoken<1,>=0.7, but you have tiktoken 0.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU semantic-chunkers==0.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "from langchain_core.documents import Document\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from openai import OpenAI\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType, Collection, connections, utility\n",
    "from typing import Any, List, Tuple, Dict, Literal, Optional\n",
    "from pydantic import Field\n",
    "from semantic_router.schema import DocumentSplit\n",
    "from langchain_core.documents import Document\n",
    "from semantic_router.splitters import RollingWindowSplitter\n",
    "from semantic_router.utils.logger import logger\n",
    "from semantic_router.encoders import FastEmbedEncoder\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Define the Credentials\n",
    "ZILLIZ_CLOUD_URI = \"\"          # os.environ['ZILLIZ_URI'] #\"https://in03-c2cc7c5da8decab.api.gcp-us-west1.zillizcloud.com\"\n",
    "ZILLIZ_CLOUD_API_KEY = \"\"      # os.environ['ZILLIZ_API_KEY']  #\"1a8a395165813d72085da55dde1db494f31fc95444ebb4f9e1f9e38127406c2ba82eb29f8b8e3d79c4a06618016e67ac77816ad9\"\n",
    "COLLECTION_NAME=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DENSE_EMBEDDING_MODEL = \"jinaai/jina-embeddings-v2-base-en\"\n",
    "SPARSE_EMBEDDING_MODEL = \"Qdrant/bm42-all-minilm-l6-v2-attentions\"\n",
    "SEMANTIC_ENCODER = \"jinaai/jina-embeddings-v2-base-en\"\n",
    "#For Rolling Window Technique\n",
    "SEMANTIC_SCORE_THERESHOLD = 0.3\n",
    "MIN_SPLII_TOKENS = 100\n",
    "MAX_SPLIT_TOKENS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the Milvus connection and collection status First\n",
    "def connection_status(collection_name):\n",
    "    connections.connect(\n",
    "        uri=ZILLIZ_CLOUD_URI,\n",
    "        token=ZILLIZ_CLOUD_API_KEY\n",
    "    )\n",
    "\n",
    "    utility.get_server_version()\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(COLLECTION_NAME)\n",
    "    else:\n",
    "        print(f\"New Collection -> {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "from pydantic import BaseModel, Field, model_validator, validator\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "class SparseFastEmbedEmbeddings(BaseModel, Embeddings):\n",
    "    \"\"\"Qdrant FastEmbedding models.\n",
    "    FastEmbed is a lightweight, fast, Python library built for embedding generation.\n",
    "\n",
    "    To use this class, you must install the `fastembed` Python package.\n",
    "\n",
    "    `pip install fastembed`\n",
    "    Example:\n",
    "        from langchain_community.embeddings import FastEmbedEmbeddings\n",
    "        fastembed = FastEmbedEmbeddings()\n",
    "    \"\"\"\n",
    "\n",
    "    model_name: str = \"BAAI/bge-small-en-v1.5\"\n",
    "    \"\"\"Name of the FastEmbedding model to use\n",
    "    Defaults to \"BAAI/bge-small-en-v1.5\"\n",
    "    Find the list of supported models at\n",
    "    https://qdrant.github.io/fastembed/examples/Supported_Models/\n",
    "    \"\"\"\n",
    "\n",
    "    cache_dir: Optional[str] = Field(default=None)\n",
    "    \"\"\"The path to the cache directory.\n",
    "    Defaults to `local_cache` in the parent directory\n",
    "    \"\"\"\n",
    "\n",
    "    threads: Optional[int] = Field(default=None)\n",
    "    \"\"\"The number of threads single onnxruntime session can use.\n",
    "    Defaults to None\n",
    "    \"\"\"\n",
    "\n",
    "    doc_embed_type: str = \"default\"\n",
    "    \"\"\"Type of embedding to use for documents\n",
    "    The available options are: \"default\" and \"passage\"\n",
    "    \"\"\"\n",
    "\n",
    "    model: Any = Field(default=None, exclude=True)  # Renamed to 'model' and marked as private\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "        extra = 'forbid'\n",
    "\n",
    "    @model_validator(mode='before')\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        \"\"\"Validate that FastEmbed has been installed.\"\"\"\n",
    "        return values\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        self._initialize_model()\n",
    "\n",
    "    def _initialize_model(self):\n",
    "        \"\"\"Initialize the FastEmbed model.\"\"\"\n",
    "        try:\n",
    "            # >= v0.2.0\n",
    "            from fastembed import SparseTextEmbedding\n",
    "\n",
    "            self.model = SparseTextEmbedding(\n",
    "                model_name=self.model_name,\n",
    "                cache_dir=self.cache_dir,\n",
    "                threads=self.threads,\n",
    "            )\n",
    "        except ImportError as ie:\n",
    "            try:\n",
    "                # < v0.2.0\n",
    "                from fastembed.embedding import FlagEmbedding\n",
    "\n",
    "                self.model = FlagEmbedding(\n",
    "                    model_name=self.model_name,\n",
    "                    cache_dir=self.cache_dir,\n",
    "                    threads=self.threads,\n",
    "                )\n",
    "            except ImportError:\n",
    "                raise ImportError(\n",
    "                    \"Could not import 'fastembed' Python package. \"\n",
    "                    \"Please install it with `pip install fastembed`.\"\n",
    "                ) from ie\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Generate embeddings for documents using FastEmbed.\n",
    "\n",
    "        Args:\n",
    "            texts: The list of texts to embed.\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings, one for each text.\n",
    "        \"\"\"\n",
    "        embeddings: List[np.ndarray]\n",
    "        if self.doc_embed_type == \"passage\":\n",
    "            embeddings = self.model.passage_embed(texts)\n",
    "        else:\n",
    "            embeddings = self.model.embed(texts)\n",
    "        return [\n",
    "            {int(idx): float(val) for idx, val in zip(embed.indices, embed.values)}\n",
    "            for embed in embeddings\n",
    "        ]\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate query embeddings using FastEmbed.\n",
    "\n",
    "        Args:\n",
    "            text: The text to embed.\n",
    "\n",
    "        Returns:\n",
    "            Embeddings for the text.\n",
    "        \"\"\"\n",
    "        query_embeddings: np.ndarray = next(self.model.query_embed(text))\n",
    "        return query_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intelligent WebCrawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_document(content, main_link, section_id, author_name, related_topics, pdf_links):\n",
    "    doc_data = Document(page_content=content, metadata = {\"source_link\":main_link, \"author_name\":author_name, \"related_topics\":related_topics, \"pdf_links\":pdf_links})\n",
    "    return doc_data\n",
    "\n",
    "def Scrape_data():\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('output_websites_10.csv')\n",
    "    df = df.fillna(\"nan\")\n",
    "    documents = []\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract data from the DataFrame\n",
    "        main_link = row['Website']\n",
    "        content = row['page_content']\n",
    "        author_name = row['author_name']\n",
    "        related_topics = row['related_topics']\n",
    "        pdf_links = row['pdf_links']\n",
    "        section_id = index  # Or another unique identifier if available\n",
    "        \n",
    "        # Create Document instance\n",
    "        doc_data = create_document(\n",
    "            content=content,\n",
    "            main_link=main_link,\n",
    "            section_id=section_id,\n",
    "            author_name=author_name,\n",
    "            related_topics=related_topics,\n",
    "            pdf_links=pdf_links\n",
    "        )\n",
    "        \n",
    "        # Append to documents list\n",
    "        documents.append(doc_data)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embedding_dim(model_name):\n",
    "    embeddings = FastEmbedEmbeddings(model_name=model_name)\n",
    "    document_embeddings = embeddings.embed_documents(\"Have a great day\")\n",
    "    return len(document_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_collection(collection_name, model_name):\n",
    "    dimension = get_embedding_dim(model_name)\n",
    "    fields = [\n",
    "        FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "        FieldSchema(name=\"source_link\", dtype=DataType.VARCHAR, max_length=1000),\n",
    "        FieldSchema(\n",
    "            name=\"text\", dtype=DataType.VARCHAR, max_length=65535\n",
    "        ),\n",
    "        FieldSchema(\n",
    "            name=\"author_name\", dtype=DataType.VARCHAR, max_length=65535\n",
    "            ),\n",
    "        FieldSchema(\n",
    "            name=\"related_topics\", dtype=DataType.VARCHAR, max_length=65535\n",
    "            ),\n",
    "        FieldSchema(\n",
    "            name=\"pdf_links\", dtype=DataType.VARCHAR, max_length=65535\n",
    "        ),\n",
    "        FieldSchema(name=\"sparse_vector\", dtype=DataType.SPARSE_FLOAT_VECTOR),\n",
    "        FieldSchema(name=\"dense_vector\", dtype=DataType.FLOAT_VECTOR, dim=dimension),\n",
    "    ]\n",
    "\n",
    "    schema = CollectionSchema(fields=fields)\n",
    "    collection = Collection(name=collection_name, schema=schema, shards_num=1, consistency_level=\"Strong\")\n",
    "\n",
    "    dense_index_params = {\n",
    "        \"index_type\": \"IVF_SQ8\",\n",
    "        \"metric_type\": \"L2\",\n",
    "        \"params\": {\"nlist\": 128},\n",
    "    }\n",
    "\n",
    "    sparse_index_params = {\n",
    "        \"index_type\": \"SPARSE_INVERTED_INDEX\",\n",
    "        \"metric_type\": \"IP\",\n",
    "    }\n",
    "    collection.create_index(field_name=\"sparse_vector\", index_params=sparse_index_params)\n",
    "    collection.create_index(field_name=\"dense_vector\", index_params=dense_index_params)\n",
    "    collection.load()\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dense_encode_docs(texts: List[str], embed_model):\n",
    "    embeddings = FastEmbedEmbeddings(model_name=embed_model)\n",
    "    document_embeddings = embeddings.embed_documents(texts)\n",
    "    return document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sparse_encode_docs(texts: List[str], embed_model):\n",
    "    embeddings = SparseFastEmbedEmbeddings(model_name=embed_model)\n",
    "    document_embeddings = embeddings.embed_documents(texts)\n",
    "    return document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def embed_insert(data: list, collection, sparse_embed_model, dense_embed_model):\n",
    "    print(data[1])\n",
    "    if data[1] == '':\n",
    "        sparse_embeddings = 0.2\n",
    "    else:\n",
    "        sparse_embeddings = sparse_encode_docs(data[1], sparse_embed_model)\n",
    "    print(sparse_embeddings)\n",
    "    dense_embeddings = dense_encode_docs(data[1], dense_embed_model)\n",
    "    collection.insert(\n",
    "        [\n",
    "            data[0], # source            \n",
    "            data[1], # text, page_content\n",
    "            data[2], # author_name\n",
    "            data[3], # related_topics\n",
    "            data[4], #pdf_links\n",
    "            sparse_embeddings, # sparse_embedding\n",
    "            dense_embeddings, # dense_embeddings\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_metadata(doc):\n",
    "    doc_metadata = doc.metadata\n",
    "    source_link_meta = doc_metadata['source_link']\n",
    "    author_name = doc_metadata['author_name']\n",
    "    related_topics = doc_metadata['related_topics']\n",
    "    pdf_links = doc_metadata['pdf_links']\n",
    "    page_content = doc.page_content\n",
    "    final_doc = []\n",
    "    \n",
    "    metadata = { \n",
    "        \"author_name\": author_name,\n",
    "        \"related_topics\": related_topics,\n",
    "        \"source_link\": source_link_meta,\n",
    "        \"pdf_links\" : pdf_links\n",
    "    }\n",
    "    doc_obj = Document(page_content=page_content, metadata=metadata)\n",
    "    final_doc.append(doc_obj)\n",
    "\n",
    "    return final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def semantic_splitter(encoder_name, semantic_score_threshold, min_split_tokens, max_split_tokens):\n",
    "    encoder = FastEmbedEncoder(name=encoder_name)\n",
    "\n",
    "    encoder.score_threshold = semantic_score_threshold\n",
    "\n",
    "    splitter = RollingWindowSplitter(\n",
    "        encoder=encoder,\n",
    "        dynamic_threshold=False,\n",
    "        min_split_tokens=min_split_tokens,\n",
    "        max_split_tokens=max_split_tokens,\n",
    "        window_size=3,\n",
    "        plot_splits=False,  # set this to true to visualize chunking\n",
    "        enable_statistics=True  # to print chunking stats\n",
    "    )\n",
    "    return splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def insert_data_db(prepared_data, collection_obj, collection_name, sparse_embed_model, dense_embed_model):\n",
    "    data_batch = [[], [], [], [], []]\n",
    "    overall_time_st = time.time()\n",
    "    BATCH_SIZE = 2\n",
    "    current_source = None\n",
    "    section = 0\n",
    "    current_title = None\n",
    "    doc_title = None\n",
    "\n",
    "    for content in prepared_data:\n",
    "        source = content.metadata[\"source_link\"]\n",
    "        page_content = content.page_content\n",
    "        author_name = content.metadata[\"author_name\"]\n",
    "        related_topics = content.metadata[\"related_topics\"]\n",
    "        pdf_links = content.metadata[\"pdf_links\"]\n",
    "\n",
    "        data_batch[0].append(source)\n",
    "        data_batch[1].append(page_content)\n",
    "        data_batch[2].append(author_name)\n",
    "        data_batch[3].append(related_topics)\n",
    "        data_batch[4].append(pdf_links)\n",
    "        print(\"Inside Data embed\")\n",
    "        st = time.time()\n",
    "        ins = embed_insert(data_batch, collection_obj, sparse_embed_model, dense_embed_model)\n",
    "        print(\"Total time taken to  process each batch & insert data to milvus is: \", time.time() - st)\n",
    "        data_batch = [[], [], [], [], []]\n",
    "        print(\"=\"*100)\n",
    "        # break\n",
    "\n",
    "    print(\"overall time to prepare data for insertion: \", time.time() - overall_time_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Store_data_Milvus():\n",
    "    count = 0\n",
    "    #Check the Connection status with Milvus\n",
    "    connection_status(COLLECTION_NAME)\n",
    "\n",
    "    # Create a collection\n",
    "    collection = create_collection(COLLECTION_NAME, DENSE_EMBEDDING_MODEL)\n",
    "    print(\"Successfully Loaded the Collection\")\n",
    "    \n",
    "    # Scrape the Base-URL Data\n",
    "    scraped_data_lst = Scrape_data()\n",
    "\n",
    "    # Prepare Data\n",
    "    # splitter = semantic_splitter(SEMANTIC_ENCODER, SEMANTIC_SCORE_THERESHOLD, MIN_SPLII_TOKENS, MAX_SPLIT_TOKENS)\n",
    "\n",
    "    # Prepare Metadata and Store in Milvus\n",
    "    for data in scraped_data_lst:\n",
    "        count+=1\n",
    "        #splits = splitter([data.page_content])\n",
    "        #doc_metadata = data.metadata\n",
    "        prepared_data = build_metadata(data)\n",
    "        insert_data_db(prepared_data, collection, COLLECTION_NAME, SPARSE_EMBEDDING_MODEL, DENSE_EMBEDDING_MODEL)\n",
    "    return {f\"Successfully Store Data Into the Milvus = {count}\"}, collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 78545.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Loaded the Collection\n",
      "Inside Data embed\n",
      "['nan']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 83330.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{605416826: 0.54747262015521}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 56833.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to  process each batch & insert data to milvus is:  1.3303184509277344\n",
      "====================================================================================================\n",
      "overall time to prepare data for insertion:  1.3303935527801514\n",
      "Inside Data embed\n",
      "['We are in the fourth industrial revolution. Industry 4.0 is not simply a buzzword or a term thrown around by the Davos crowd: it is affecting every sector and every business operating today, and the automotive industry is no exception.\\nIndustry 4.0 is an integration of the physical, biological and digital worlds, built on a base of emerging technological breakthroughs including autonomous capabilities, artificial intelligence, the Internet of Things (IoT), next-generation wireless technologies, nanotechnology, big data, blockchain and cloud computing. Some of this technology is in use today — on a mass scale, or just emerging and being tested. Others, such as blockchain and cutting-edge autonomous capabilities, are in their infancy and not widely adopted or understood.\\nThe pace of change is becoming more rapid. Customer expectations are higher and seemingly ever-increasing. At the same time, demand is becoming more and more volatile. For example, say a photograph of a celebrity wearing a particular brand goes viral, or a social media influencer makes a video about a particular cosmetic. Sellouts in these cases may seem almost instantaneous. Unconventional channels are creating disruption and impacting supply chains in a matter of hours, not months.\\nWhile these examples are retail-focused, they demonstrate how disruption impacts global supply chains. To operate in this more-volatile environment with an entirely different dynamic, we need to embrace new capabilities that enable greater agility.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 83886.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{72180827: 0.08241453017587189, 91759785: 0.13876122107466396, 1477368786: 0.07116120847170014, 516830072: 0.11656306897276514, 764297089: 0.0956499870729184, 963753705: 0.031397939681800886, 1797597072: 0.06588673898883333, 754797265: 0.046365528127682236, 212482175: 0.02285022994031179, 663467227: 0.022839335441771184, 127229232: 0.1453456290373526, 1084770517: 0.06780988607424018, 194714415: 0.03267902765431698, 1481737067: 0.027195393066978227, 1961226291: 0.05837752603218234, 1240248262: 0.048951726973203775, 100532018: 0.04982787911994433, 22861070: 0.036087131053190905, 1973498388: 0.11741920929575403, 1968306389: 0.03182387958160889, 1836140557: 0.04492324592404377, 1885148710: 0.06099961223619103, 743323000: 0.09617045904720956, 121956570: 0.07721492027104743, 74040069: 0.05909253065208892, 1999429279: 0.025493330396733425, 1010104944: 0.024772569252480718, 2073907658: 0.051496339234144164, 575755316: 0.051868611554156695, 2094241111: 0.0634874575393666, 1341778817: 0.030284395398535127, 517580246: 0.10658566704667446, 1607792561: 0.062255248943161645, 34379837: 0.06618652601697439, 2088942923: 0.07776896855693012, 1077417228: 0.07231082874992528, 1218230531: 0.07494340868624742, 130722334: 0.10440259124380329, 2120095081: 0.03695252348827905, 243731433: 0.036113868114226164, 422891595: 0.07012340355616645, 622510934: 0.1332074153534452, 463724087: 0.07456455387099392, 989116115: 0.08473967302290653, 389009823: 0.2013448177546404, 1570547443: 0.1160460950308652, 609543353: 0.07303518732452641, 640124220: 0.0415534164728791, 1599545163: 0.06009390271842725, 595088298: 0.06052917840588947, 1005783980: 0.045619042876492745, 1167338989: 0.07313577641812889, 2005097560: 0.03237299824319108, 242553538: 0.07276865823518987, 498892314: 0.0628939145515508, 1140766032: 0.04176305731272842, 1543434194: 0.030196303185373505, 1550334664: 0.03274383091271003, 1685876570: 0.03646817560418651, 1630634065: 0.04139797788584847, 617246313: 0.04647037882844568, 1473125286: 0.025691625257001187, 21025631: 0.03362742838509362, 1075114912: 0.0954240559113113, 1372955919: 0.0542664913653484, 732777880: 0.024888273614117027, 267423339: 0.029987661555994482, 1778150425: 0.028150642331255547, 724849589: 0.027597418387699735, 2058513491: 0.019245768633894256, 1504846510: 0.045983663065620566, 1809361651: 0.07649840714389712, 2035475614: 0.03253520346951184, 2044745418: 0.028049469086067234, 17239783: 0.0680064040382461, 1095013673: 0.09494042958425977, 1667382587: 0.055592556665496416, 939837349: 0.031044443090298274, 1885399095: 0.09196978838057543, 412854099: 0.029821913432669368, 1612003016: 0.08562729854749239, 1517563190: 0.05931823967604251, 67003442: 0.05189975168873745, 266525280: 0.06238274356703334, 917062287: 0.025506774441840446, 639288724: 0.08413928131639824, 503502471: 0.11340285949247045, 444038860: 0.14643500049658423, 580887246: 0.02094281973071278, 1792659531: 0.029867097244399062, 2144252429: 0.025909860664506616, 1278538786: 0.04944518631175317, 1609399999: 0.0822032759574503, 1969202985: 0.10218622502330106, 958659146: 0.02194535341333242, 1529782145: 0.047737136721147946, 939302382: 0.03670076492861527, 1075669042: 0.07668863250912207, 1755032060: 0.0518072295306342, 581432272: 0.01844311807053841, 446617493: 0.04886615260418208, 1372199004: 0.05154276430283652, 64771992: 0.09334193143367249, 876558472: 0.04668705452114, 2063746700: 0.03492518859300966, 1122754679: 0.0663995545252615, 655576192: 0.03955989950655738, 733815364: 0.025774025114047815, 327797310: 0.026832261978939707, 1983760977: 0.03817149056152745, 1491351846: 0.02768390777898194, 1398540754: 0.033553139121870974, 422208903: 0.04424093446949352, 647928480: 0.030711329527795442, 1207805233: 0.041886019564637667, 1759213418: 0.1045541839728048}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 57932.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to  process each batch & insert data to milvus is:  1.5732359886169434\n",
      "====================================================================================================\n",
      "overall time to prepare data for insertion:  1.5733070373535156\n",
      "Inside Data embed\n",
      "['nan']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 93902.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{605416826: 0.54747262015521}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 64726.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to  process each batch & insert data to milvus is:  1.3502233028411865\n",
      "====================================================================================================\n",
      "overall time to prepare data for insertion:  1.350301742553711\n",
      "Inside Data embed\n",
      "['In the next 10 years, you will undoubtedly see instances of new entrants being acquired by traditional original equipment manufacturers (OEMs). Both have problems that are not easy to solve. But when these two types of companies are paired together, these problems can be addressed.\\nBoth new entrants and traditional OEMs have strengths and weaknesses — and both have competitive advantages. Having less experience means having fewer constraints and less fear — after all, there is less to lose. But it also comes with a lack of wisdom and practical knowledge, as well as a tendency to make more mistakes along the way.\\nThe automotive industry has existed for over 100 years. A lot of the large OEMs have spent decades really honing how they can make their supply chain lean; build and sell cars on a large scale, at a high volume and cost-effectively; get the cars out to consumers who actually use them; and help drivers maintain those cars. Over those decades, those OEMs have grown massive. They now lack agility. They struggle to achieve speed to market when they have a new, creative idea that needs to be launched fast. That’s where their own inertia of being large works against them. This is where the new entrants break the mold.\\n\\nTraditional OEMs are not about to wait. They are going to recognize innovative changes to the way cars are made and the way we use those cars. They will reproduce what the new entrants do faster and at scale. Instead of taking a decade, it will take traditional OEMs three to five years to scale an innovation as well as or better than new entrants.\\nFrom managing the status quo (an existing supplier base, dealer network and customer base) to turning to new products with new requirements (supplier base, parts, plants and revenue model), striking a balance will be critical to maintaining the value of the company and mitigating the risk of an overnight stock wipeout.\\nWe are not seeing the full effect of the electrification and new entrants yet. New entrants still need to figure out how to have financially viable business models in the longer term with the products and services at scale.\\nAcquisitions aren’t the only situations in which traditional OEMs and new entrants can play off of each other’s strengths: it would also be fascinating to see a joint venture between the two. Under this scenario, all of the knowledge from the traditional OEM could be used with the new entrant, allowing everyone to innovate. It happens in the tech world all the time.\\nWhether through acquisitions or joint ventures — however it plays out — it’s very likely that you’ll see traditional OEMs and new entrants working together in the coming decade. They’ll do it because they need each other.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 96791.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{2120095081: 0.030136486505468227, 2031875777: 0.09101072892564589, 822745112: 0.030184995155695653, 2080324914: 0.022652398098358728, 226476184: 0.03464970906735155, 1709928829: 0.032375361887268465, 422208903: 0.03727423973471161, 1661642123: 0.11411650748913786, 1121893475: 0.04296738834107226, 671628476: 0.08196821313615255, 997549709: 0.040587590206890255, 982420702: 0.1115268282769978, 889891204: 0.06529379150637314, 1298509709: 0.14604074362736227, 2115005279: 0.0374948086616197, 407719845: 0.025875974336239106, 930102859: 0.033244498045950505, 358389376: 0.02938495606100379, 2045916435: 0.026685756930343887, 1442710396: 0.03439720484507354, 466714812: 0.03984889272232966, 1153915709: 0.02129328867126128, 2132027491: 0.022195197759756237, 179297712: 0.03675228686564671, 1091666738: 0.040253374650811184, 1599545163: 0.0555361433571254, 1584003560: 0.035841820462838805, 1583132830: 0.025740216215929347, 997052087: 0.044332018435943504, 275574541: 0.08767755927073857, 832098838: 0.021892747872463755, 1750676654: 0.019098907954220683, 705771791: 0.035249088601339684, 1432942394: 0.0531753163465595, 847411504: 0.03217191334406956, 1706587157: 0.027599895718687345, 1752023156: 0.016608339157325437, 834323496: 0.03221315336372475, 2143229425: 0.05346888695878926, 3581950: 0.03305977252012487, 1870200871: 0.058658142987822556, 818939763: 0.021868564627044004, 165077569: 0.020138957577086305, 917062287: 0.018992541672184494, 1478513963: 0.04152019314760652, 803464829: 0.019252769367302785, 1079027559: 0.02178224332120754, 1973498388: 0.14216603090277372, 91759785: 0.03400233730076766, 332135977: 0.022803871928604877, 829318785: 0.04987672680831689, 54081900: 0.017289967573868827, 2117458213: 0.04984825797113241, 11115416: 0.01568468453470085, 1035914140: 0.052717557776465945, 214084523: 0.02158688870349882, 1652119407: 0.03261612862623395, 1075669042: 0.052024698363998485, 1755032060: 0.043132450354464134, 385490568: 0.050087863134013845, 2087367745: 0.03604952805381238, 118532059: 0.04546073801085643, 2011139606: 0.0913140316063833, 1005783980: 0.04358396382784241, 1612531086: 0.018842305691422666, 378940769: 0.02380820324813774, 151069542: 0.02815488471167828, 243669559: 0.021425026689302202, 997012898: 0.01799130279291912, 1407412762: 0.043584161110623465, 553793032: 0.020245783443485488, 640124220: 0.02997799156927176, 1402904868: 0.022053279073085255, 1915816983: 0.08632369338887413, 339478471: 0.029734125714587174, 756358085: 0.02327309568677857, 1110755108: 0.034232175561424306, 1759213418: 0.10341172933778994, 336398707: 0.026653317819272052, 236277287: 0.023224169746202825, 997512866: 0.04523457089208333, 1690623792: 0.05796549392956899, 1412784057: 0.07978348278814901, 2032101475: 0.04099911784879866, 1491351846: 0.02053482524753691, 592326839: 0.050072144231833045, 1935863057: 0.06676785273378112, 313111706: 0.0582826058268242, 1742989274: 0.04955861086533421, 189262593: 0.03020775617401653, 1271411175: 0.024419626379268037, 1212042314: 0.03481315354530973, 103767893: 0.04235987991621687, 108710752: 0.022146869671773886, 281546400: 0.03614554557789395, 845321163: 0.050620708291708276, 617246313: 0.027885945600173805, 842018159: 0.026534130356227696, 1789161334: 0.03491532939690518, 819028769: 0.03416301003540815, 1215666339: 0.022571294013704453, 148299209: 0.016661543428054162, 1296924235: 0.035801567443044385, 297260153: 0.04587856124226779, 498297388: 0.020778358866611134, 2135986242: 0.032137380704125966, 900543307: 0.038241613831639515, 407244595: 0.053999721479044444, 1838611330: 0.04948500855336339, 1010104944: 0.03108665811335428, 753981150: 0.05779959294998717, 818409348: 0.06720254827687644, 1075114912: 0.04155616139120281, 1900214453: 0.03458493616622006, 818319522: 0.045103351236422284, 516115046: 0.037113966097945164, 28501148: 0.0401184123487739, 1371333942: 0.056899558360605215, 302067699: 0.05439649376333713, 1172383616: 0.05632174512728834, 371180111: 0.0637187125917673, 1495822459: 0.06395173256835873, 644716969: 0.023167216562051677, 1289414591: 0.041041924761679595, 1277177331: 0.04774570966555983, 456196542: 0.03682400600920607, 1789311006: 0.11181344094221882, 1323379187: 0.07673073745427952, 730784284: 0.11068451299069355, 1058501323: 0.019282727966720797, 1711954: 0.11511348974852519, 1117393019: 0.024531423905515607, 2142141949: 0.023460797811394554, 818459139: 0.032272577601690916, 508896879: 0.04240195789915461, 372734888: 0.02606571545420802, 1240248262: 0.04759736723176878, 408354071: 0.020765735449681928, 754797265: 0.022263142422950643, 1342301861: 0.056473826421721794, 438347465: 0.11371865659295341, 626948129: 0.02441678660582634, 1732471882: 0.026724196075649267, 551536775: 0.029138028390082248, 1621828384: 0.04111345527255394, 1013647041: 0.051094596889426434, 1964082269: 0.07070896924254029, 909597911: 0.023075452878877904, 2100873926: 0.03248121988254655}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 79437.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to  process each batch & insert data to milvus is:  1.8597614765167236\n",
      "====================================================================================================\n",
      "overall time to prepare data for insertion:  1.8598403930664062\n",
      "Inside Data embed\n",
      "['nan']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 65707.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{605416826: 0.54747262015521}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 52560.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to  process each batch & insert data to milvus is:  1.333639144897461\n",
      "====================================================================================================\n",
      "overall time to prepare data for insertion:  1.3337140083312988\n",
      "Inside Data embed\n",
      "['nan']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 97165.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{605416826: 0.54747262015521}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 56527.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to  process each batch & insert data to milvus is:  1.315864086151123\n",
      "====================================================================================================\n",
      "overall time to prepare data for insertion:  1.3159425258636475\n",
      "Inside Data embed\n",
      "['nan']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 82241.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{605416826: 0.54747262015521}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 80659.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to  process each batch & insert data to milvus is:  1.3455543518066406\n",
      "====================================================================================================\n",
      "overall time to prepare data for insertion:  1.3456342220306396\n",
      "Inside Data embed\n",
      "['nan']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 92521.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{605416826: 0.54747262015521}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 58254.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to  process each batch & insert data to milvus is:  1.3408019542694092\n",
      "====================================================================================================\n",
      "overall time to prepare data for insertion:  1.340874195098877\n",
      "Inside Data embed\n",
      "[\"“To adapt to change, it is important to focus the change on yourself rather than the people around you,” says EY alumna Sandipa Maharaj as we caught up with her to hear about her professional and personal journey with EY.\\nCurrently the Finance Director of Consumer-Packaged Goods at Imperial Logistics, Sandipa started her career with EY as an article and stayed with EY for five years till 2009.\\nEY was, to her, “the type of place where you looked forward to going to work every day.” It was where, she says, she formed the base for her career. “My articles provided a fantastic base for me, in terms of learning all-round skills, not just the technical side of accounting. It also started opening my mind up to the impact that a CA could have in an organization.”\\nAfter her articleship, Sandipa went on for a secondment at EY’s Central London office – an experience she describes as a “growing point” in her life. “I think I grew, not only as a professional, but in my personal capacity, as well. I was exposed to so much more than just the technical side.”\\nEY wasn’t always about work for Sandipa. Passionate about mentoring and guiding young students, she regularly went out to schools and gave talks to underprivileged kids on how to become a CA.\\nSandipa learned the importance of investing in people early on. She continues to put that into practice and encourages others to do so as well. “EY taught me, from a very young age, the importance of investing in people and I carry that through my career with me now. It definitely provided me with the tools I needed to get to where I wanted to go.”\\nBut how exactly should organizations invest in people? According to Sandipa, it is by aligning their activities on the job with a larger purpose. “Loyalty doesn't come from just having a job; it comes from connecting with the purpose of the business. And that emotional connection is vitally important.”\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 90524.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{755629816: 0.03366459343806322, 540174517: 0.06293186052798466, 617246313: 0.08236473100127008, 440359455: 0.03914669670799726, 876558472: 0.04029823824279665, 1401966460: 0.03079040354948972, 1300596145: 0.083990889076511, 663467227: 0.03352467728284505, 396618896: 0.052305718373484716, 2044745418: 0.036881496247507944, 463553571: 0.10894323684945462, 1720411956: 0.11595342910134418, 2101488140: 0.13048184025141984, 80470104: 0.118169295967776, 1884322716: 0.023251929700671598, 74419931: 0.02635108744279035, 1488352908: 0.07073713716740473, 8834632: 0.0630597058807963, 1393816860: 0.05998043180468328, 407983593: 0.026854719179747556, 984398166: 0.10701460443040225, 910587127: 0.054909852401461144, 1407412762: 0.0952929365644648, 1299760888: 0.07395992883128201, 115441729: 0.07851620063601529, 2099277384: 0.11247110717688394, 1177690189: 0.10087992975945495, 1561499504: 0.03398590807788757, 257805136: 0.06035761226435835, 1257441684: 0.08423902273901973, 1881538586: 0.03152502469166097, 297260153: 0.041514517796504315, 822745112: 0.029105983607683236, 10984773: 0.019418134143559255, 2020385534: 0.04021892784168568, 2045916435: 0.03808815143810178, 1455480578: 0.03175955164765245, 1404934148: 0.024907362109560544, 2136405083: 0.03655568617411807, 108710752: 0.03693541572519497, 189262593: 0.050403346821903575, 1481737067: 0.029631432855526774, 520205939: 0.027252651673150576, 14784032: 0.023866384448166297, 1010104944: 0.04320404445485368, 1563718956: 0.031981583261793435, 1815584999: 0.02596189320830424, 754797265: 0.022561801578502242, 1644170059: 0.04895160123192647, 1557059678: 0.05436378121574011, 212438410: 0.057354865026249, 662754433: 0.09558112262151275, 1889329599: 0.033824349156648115, 2071720296: 0.1705654805593308, 1706587157: 0.023562471654274584, 2091876921: 0.023975932751418908, 418093614: 0.0376071453438192, 939302382: 0.03429922152267578, 245496272: 0.11190722373893065, 2100873926: 0.044576455158048575, 957769532: 0.10757456365226839, 1392449935: 0.09402159341822768, 1802853965: 0.021611803376390896, 436751995: 0.07317173086354656, 313111706: 0.05774870482523976, 588610688: 0.03665097213990411, 338155252: 0.08194343958279858, 1871711020: 0.050100584881180896, 1640262985: 0.05422605658272616, 275574541: 0.03214400945520806, 2099560782: 0.026818188469474778, 1097942161: 0.053148298046130533, 648501015: 0.04484715203016745, 2019785588: 0.0357193870160904, 82883857: 0.027439446184965473, 1428087568: 0.043472563842629375, 1184049365: 0.02771438341108926, 818939763: 0.02577478228777285, 1402873769: 0.04604332617677839, 121538519: 0.022964889938874748, 343224137: 0.03466476302350611, 677727288: 0.03258737206496825, 1804363299: 0.05756715506064623, 1209733406: 0.031686439525588965, 114620842: 0.04925431445405688, 1771611464: 0.05227586075661386, 1583324998: 0.021060987036024173, 1660628907: 0.04773566709203801, 1648371143: 0.02157345039388965, 1793137844: 0.025267295748842428, 221841881: 0.05691992311637636, 542041464: 0.05262282797279131, 1473125286: 0.028442456390157883, 550510908: 0.09931079501364783, 1724426273: 0.0508752924112155, 1354311854: 0.021428731071647722, 1911071232: 0.02231400966632718, 3581950: 0.04828854591348381, 1038999390: 0.03173423282380089, 2005097560: 0.03900982878875167, 1639365079: 0.04997903925551985, 717653329: 0.04086358480796725, 1523874731: 0.033748428766755066, 640494850: 0.035780380851695257, 1116117978: 0.06711561816336674, 1491351846: 0.03247919336846462, 997012898: 0.024627818273238594, 898174745: 0.0324253207654387, 1277427225: 0.05266685286004248, 2001158628: 0.028335497361839608, 1391213695: 0.05630453537337674, 116350199: 0.05111570390952077, 1947820556: 0.055318759229980155, 24515841: 0.04124291658239852, 933802348: 0.03944645709217464, 1610871652: 0.10265422467324355, 1752023156: 0.020465106752585928, 1223115691: 0.03720798100160961, 1240248262: 0.05607701283874085, 1783180195: 0.05941492451676226, 1061267272: 0.048268456993793736}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 82241.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to  process each batch & insert data to milvus is:  1.8365111351013184\n",
      "====================================================================================================\n",
      "overall time to prepare data for insertion:  1.8365843296051025\n",
      "Inside Data embed\n",
      "['Sesha was born and brought up in Chennai in a south Indian family. Since childhood, he developed a strong inclination towards finance and numbers, also influenced by his father’s interest in the financial markets. At 15, he surprised his parents, when contrary to everyone’s expectations and wishes of him joining IIT and becoming an engineer, he decided to pursue chartered accountancy. This choice also happened to then become a great motivation for him to push hard and prove himself to his family. In his teens, he spent a lot of time going through CEO statements, analyzing annual reports of companies and understanding and reworking the ratios to increase his understanding and expertise in financial markets.\\nReminiscing about how his association with EY began, he recalls his cousin, who is also his mentor in life, encouraging him to gain experience at a big four consulting firm as he felt that would be a strong start to his career. On his advice, Sesha applied to some of them and as destiny would have it, he got the first interview call from EY. After seven grilling rounds, he was selected as one of four hires among the 50+ applications. Recalling his initial impressions at EY, Sesha shared, “I was awed and enthralled by what I experienced on the first day and the kind of people I met. By the time the other companies called, I had already made up my mind to start my tenure with EY and didn’t even attend any other interviews.” Describing his experience as wonderful, he shares that his stint was very productive as he got the opportunity to work across various sectors, assignments and with different teams.\\nAlso, his interactions with the exceptional talent and inspiring leaders at EY enriched his experience. He shares that Terry Thomas and N Balaji, Partners at the EY Chennai office, left an everlasting impact on him and went on to be his friends, philosophers and guides in his professional journey thereafter. He thanks EY’s culture and team spirit that made erstwhile colleagues like Vijay Shankar (Partner in Bangalore) and Shankari (Director in Chennai) best friends for life. Sesha strongly feels that the constant access to leaders gave him a lot of exposure and impacted his overall perception of life. It also brought out the curious kid in him every day. He proudly declares, “While I was born and brought up in Chennai but professionally, I was born and brought up in EY! Striving for excellence and always looking for opportunity to learn and improve are key traits EY has taught me for life.”\\nSesha travelled extensively and worked on several engagements during his tenure which helped him get excellent insights and an opportunity to identify the nuts and bolts of how a company operates. “The length and breadth of work that I got at EY was unmatched and is something that I miss since leaving EY,” he shares. One of the highlights of his experience was the opportunity to work with the central division (mother entity) of a client in the US, after they were impressed with Sesha and his team’s performance on the same project with the Indian division of the firm. It was a proud moment for Sesha and his team as it was one of the first instances that EY India had won a mandate in the US.\\nThe cosmopolitan culture and working with people from across the world made his EY experience even better and he feels that diversity helps you become a well-rounded professional. Interestingly, he became better at Hindi at EY!\\nIn 2007, Sesha got an opportunity to work with Barclays in Singapore. He had recently got married at that time and the chance to work in an exciting new city eventually lured him abroad to gain some experience with the bank. Banking, which was thriving at that time, was a completely different world for him. Speaking of the challenges he faced and how the EY experience helped him transition into the new role, he says, “What I do in banking is very niche - product control. As a function, it is time sensitive, high risk and extremely demanding and challenging. I believe EY prepared me well for it. Even though I was not from a banking, financial services and insurance (BFSI) background, I adapted to it well. The challenge was to learn about financial products in a very thorough manner. So, the leadership and managerial foundation from my years at EY helped me get a strong start in my new role.” In 2011, after spending over four years in Singapore, Sesha wanted to come back to his family in India for personal reasons. In the absence of good opportunities in Chennai for him, he joined Credit Suisse, Pune as a Vice President. It was when their product control practice was being set-up. Credit Suisse gave him the exposure to a leadership role, as he set up a function, built a team and created capabilities. After being promoted to Director and spending some time in Pune, he was keen to come back to his family city, Chennai.\\nSesha moved to Chennai and joined back Barclays. He has been working in the banking and product control domain for over 12 years now. Recounting his experience, he says, “I have continued doing similar work for the last twelve years. I feel, it’s a very good high. I also brought a lot of risk and control mindset into it (learnings from EY days), which really helped me bring something to the table even though I was new to the industry in the initial years. Sesha is leading a team of over 70 people at Barclays. He is looking after the primary market, which deals with IPO, advisory, loan syndication and bank’s treasury. Investment and international Banking is going through a very interesting and challenging phase. Things are not always favorable, and he tries to turn every challenge into an opportunity and that is something which keeps him excited!\\nSesha’ s advice to the young generation today would be to dig deep, instead of digging wide. To always have an edge over others, one should be curious, confident and spend a lot of time digging deeper to become an expert in a field. He further says that people usually tend to get distracted if they have multiple plans, so one should have fewer plans and ideas and give one’s best to them. 10 years down the line, he would love to be in a global leadership role or start his own entrepreneurial venture. If he gets an opportunity, he would also like to take an education break to study more.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 97921.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{2037567939: 0.16628876822784142, 76510512: 0.0444355718703626, 1788524165: 0.032779594741726384, 1012272114: 0.08850820943323101, 943113075: 0.05487899160863433, 1672556481: 0.06300563691468324, 1853937968: 0.04591179603852249, 874403274: 0.024727138402153417, 1118570297: 0.04131630466850118, 659326392: 0.028009567395102297, 524963102: 0.02694102510665017, 1832758249: 0.03344585180573012, 719013046: 0.029699632404390094, 984398166: 0.0902424187576577, 1308688855: 0.04512775578422707, 1706587157: 0.026617682708933416, 266525280: 0.02961876212054542, 936994131: 0.04941655693535829, 313111706: 0.059121488325604404, 570245443: 0.03614622586811311, 508896879: 0.13068653239386122, 1690623792: 0.09423078072266669, 697303812: 0.06521459391106253, 2090661150: 0.025836694734035697, 319147430: 0.04089420450995254, 655621628: 0.02274122124986989, 534475871: 0.02475677581669569, 1372955919: 0.02388930672660167, 1699170408: 0.023792166221464097, 276369190: 0.03918842231866337, 1858909382: 0.07883696402384213, 1473125286: 0.029544973772737577, 856081220: 0.11659322951686371, 894451947: 0.02473276273317912, 1130296790: 0.029746565404084633, 762484745: 0.1067205351730237, 2071720296: 0.11223006598793647, 315472241: 0.03258555023633788, 1975257448: 0.020236104079485055, 198527388: 0.02653630487605274, 1530184374: 0.04000630590937676, 254839692: 0.02398256792295853, 1277694805: 0.02357849360728173, 1097223116: 0.038427874424891546, 1526106719: 0.05734015742128506, 11115416: 0.020380221225326605, 54081900: 0.022143966681683263, 2058513491: 0.01768448273260109, 108710752: 0.017260466898198025, 306302384: 0.12131490307108575, 1715992043: 0.0375359587948232, 412527760: 0.036446967616681966, 1960190313: 0.04492853181018487, 62221562: 0.04983120704164524, 1442710396: 0.056732697948349085, 446319932: 0.04747168613380144, 960678656: 0.03557541765184469, 1679721915: 0.06640510162287895, 724849589: 0.03229329825063506, 1279999991: 0.04446586326171101, 1525091691: 0.05487186462113856, 2027866036: 0.04624910709688286, 463553571: 0.10054102281424755, 732690489: 0.03460026873384191, 385392376: 0.032017430293800296, 169773347: 0.0631261206812486, 1804363299: 0.06930075191195452, 2019785588: 0.03773278644793606, 1038999390: 0.02559069320034836, 1713488374: 0.03225560426163402, 275574541: 0.04659875273903111, 463724087: 0.058110566642085235, 1308276157: 0.07633471648865464, 509670003: 0.07951264323180823, 787166532: 0.05336982139082748, 283447355: 0.021887680779905636, 551536775: 0.0275528452795112, 1561499504: 0.03868675632568712, 257805136: 0.032486215808470505, 1033633057: 0.04195404808839815, 804460016: 0.03314461660776603, 1224153719: 0.09560578354054548, 820773949: 0.023003824130819604, 1443829736: 0.04082832658752686, 1918041394: 0.06743720140461403, 632657554: 0.04230002903670372, 1625298470: 0.04467487854406477, 848489962: 0.06383759938161468, 1557059678: 0.03562784764388899, 1042626614: 0.03546380829412556, 2037283124: 0.023450057029226794, 970442630: 0.06123700278709213, 1322470211: 0.021909770447226796, 118156056: 0.06520097655420332, 1634657082: 0.060103358216330005, 163831485: 0.02007287145080991, 1889686612: 0.0309464702049501, 1181836714: 0.031245594490353842, 755629816: 0.0374567386825111, 63891579: 0.038500772123362184, 912846650: 0.039392821589248894, 796388130: 0.03212078653666, 520205939: 0.031690828890586664, 1830401145: 0.03039133537696684, 1300596145: 0.033723589054949675, 1944832113: 0.03180318340013344, 1778636274: 0.026204565428955457, 842018159: 0.021624892962529146, 418093614: 0.033705338375376676, 1831455959: 0.0536383810741727, 1587604933: 0.024727952374570903, 1899688029: 0.02691323317409352, 396618896: 0.04358883698333218, 2099560782: 0.02901445566904405, 1811598579: 0.04361956551973507, 1251791561: 0.037842252155895914, 818319522: 0.035703246658730606, 846361587: 0.03031267834714546, 189262593: 0.03464292476019384, 1432619228: 0.026103199350171157, 2135545454: 0.02657636128127762, 1961226291: 0.05004990112968763, 1679435792: 0.03572464834780617, 327797310: 0.029461643128303367, 1508301219: 0.05736603937757197, 1602970658: 0.025683640682143034, 1968306389: 0.02925879458859351, 923372184: 0.03473268768435365, 2017215381: 0.035851531262370805, 1042458203: 0.08106496964615019, 700218182: 0.04307294847671934, 1463187771: 0.07237428539046346, 9661306: 0.06866017227241206, 967714644: 0.032921243419677115, 1303743332: 0.07469516120231555, 1928848833: 0.03957805755627359, 1871711020: 0.03766754490357749, 1454755048: 0.02140417664756268, 1749778245: 0.04075440543225155, 939302382: 0.02478394621037879, 1802853965: 0.015158042636681529, 1141099794: 0.03999617975541766, 2030235830: 0.05004682681515317, 1209733406: 0.03374731238134455, 1488352908: 0.04127987333345084, 1393816860: 0.026731330886555865, 1376006215: 0.018724339612410962, 881524070: 0.025833713703940917, 620348882: 0.034852038895012434, 1323257324: 0.03224904176986256, 810263605: 0.04684426955265587, 755754355: 0.03372347009458063, 366928855: 0.02260113228952031, 1849535340: 0.06191196931167658, 676590565: 0.06668085139645336, 482661607: 0.04098644340027349, 897967023: 0.08242449294453523, 910587127: 0.03653215671658509, 981249831: 0.03341113335473112, 1686264380: 0.029615618380185345, 1322743076: 0.03608867101807951, 2120211764: 0.04108901753558574, 1648371143: 0.025317822321456237, 41486142: 0.03710297137434758, 825292241: 0.0248927596763164, 834835684: 0.03491793681134507, 1536353147: 0.04843897058678086, 542041464: 0.04330416649042738, 1481737067: 0.030033076748939957, 75480261: 0.030196766357181392, 2059428356: 0.031534262743090055, 1060026284: 0.048365460771640965, 894492446: 0.05078699863657951, 343224137: 0.031720164374852144, 1404934148: 0.025220080536199115, 1644170059: 0.03962960009025869, 2012469550: 0.030603246658615364}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 78840.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to  process each batch & insert data to milvus is:  1.8050026893615723\n",
      "====================================================================================================\n",
      "overall time to prepare data for insertion:  1.805077314376831\n"
     ]
    }
   ],
   "source": [
    "# Store The Data Into The Milvus\n",
    "message, collection = Store_data_Milvus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ey.com/en_in/advanced-manufacturing'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('output_websites.csv')\n",
    "df['Website'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to check the data from Present in the Milvus\n",
    "collection_query_source = collection.query(expr='source_link like \"https://www.ey.com/en_in/advanced-manufacturing\"', output_fields=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Successfully Store Data Into the Milvus = 304'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
