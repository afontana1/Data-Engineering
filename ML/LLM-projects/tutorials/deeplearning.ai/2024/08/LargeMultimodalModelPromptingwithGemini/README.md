# [Large Multimodal Model Prompting with Gemini](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/)

![Promo banner for](https://ci3.googleusercontent.com/meips/ADKq_Na9Tkp-uHkpk5LyGeR35JyEcQoOGW-j7GBO7VS7lklagsVRIEX0Lz-BO41Y8rCYIVkqkFm9ocOHrWO47pvI5WkPmh0HWUMJd6mDH790kGgh-ULu0JBdofmzTZky3CFe-1uHqk9Om64Ral2i4dfzapXJRtNskkCHBQzhlURV-EgZTdla8cSaQ80z2gnkVhP7pmkggS-953v_j3l6rP_BIW-y9vxgwfVG_i1amlS4zg=s0-d-e1-ft#https://info.deeplearning.ai/hs-fs/hubfs/DeepLearning_Gemini_Banner_2070x1080.png?width=1120&upscale=true&name=DeepLearning_Gemini_Banner_2070x1080.png)

Dear learner, 

 

Introducing Large Multimodal Model Prompting with Gemini, a new short course built in collaboration with Google Cloud, and taught by Erwin Huizenga, Developer Advocate for Generative AI at Google Cloud.

 

Large Multimodal Models (LMMs) represent a significant evolution from language models by integrating different data modalities, allowing for more comprehensive outputs based on varied input types such as text, images, and video.

 

For LMMs, prompt structure becomes even more important. For example, placing text inputs, such as a patientâ€™s medical history, before image inputs like an X-ray, can improve the modelâ€™s interpretation. Conversely, for tasks like image captioning, leading with the image may yield better results. In this course, you'll explore best practices for multimodal prompting, and learn how to properly set parameters for optimized results.

 

Additionally, youâ€™ll learn how to integrate Gemini with external APIs and databases using function calling, with the ability to infuse your applications with real-time data and dynamic content.

Enroll Today

![Launch email GIFs (40)](https://ci3.googleusercontent.com/meips/ADKq_NaAl_q7VZDiEmQqF0jZLw69gm0kVImzztthG-WhKskRmEjiAUyoJs5LCdpcFoGSykMD50o2glgROlKzmuTa80qB1WJfvFbIlNR_b1ur7Pd1tpLXwOZsxcQZ_G7IZCdfowRJzzJRmhoMZMhguYRYkwWfvq6qFqsoriRa2zWvND8puqIxYIG-R63VAeph5Nkf5VQX2DzuBzE0tDrl1uwP=s0-d-e1-ft#https://info.deeplearning.ai/hs-fs/hubfs/Launch%20email%20GIFs%20(40).gif?width=1120&upscale=true&name=Launch%20email%20GIFs%20(40).gif)

In detail, youâ€™ll explore:

  -  Introduction to Gemini Models: Learn the differences and use cases for Gemini Nano, Pro, Flash, and Ultra. Understand how to select optimal models based on capability, latency, and cost.
  -  Multimodal Prompting and Parameter Control: Learn techniques for structuring effective text-image-video prompts. Fine-tune key parameters like temperature, top_p, top_k to control model creativity vs determinism.
  -  Best Practices for Multimodal Prompting: Get hands-on experience with prompt engineering for Gemini multimodal models, and role assignment, task decomposition, and formatting. 
  -  Creating Use Cases with Images: Build engaging multimodal applications like interior design assistants and receipt itemization tools. 
  -  Developing Use Cases with Videos: Implement "needle in the haystack" semantic video search powered by Gemini's large context window. 
  -  Integrating Real-Time Data with Function Calling: Extend Gemini with external knowledge and live data via function calling and API integration. Combine Gemini's Natural Language Understanding (NLU) capabilities with APIs for up-to-date facts and interactive services.

Start building advanced AI applications that can reason across multiple data modalities today!

 

> Note that due to technical requirements, this course features downloadable-only notebooks on the learning platform. You are free to download, review, and run these notebooks on your own.

## Details
- Learn state-of-the-art techniques for getting the most out of multimodal AI with Googleâ€™s Gemini model family.

- Leverage the power of Geminiâ€™s cross-modal attention to fuse information from text, images, and video for complex reasoning tasks.

- Extend Geminiâ€™s capabilities with external knowledge and live data via function calling and API integration.


|Lesson|Video|Code|
|-|-|-|
|Introduction|[video](https://dyckms5inbsqq.cloudfront.net/GC/C4/L0/sc-GC-C4-L0-master.m3u8)||
|Introduction to Gemini Models|[video](https://dyckms5inbsqq.cloudfront.net/GC/C4/L1/sc-GC-C4-L1-master.m3u8)||
|Multimodal Prompting and Parameter Control|[video](https://dyckms5inbsqq.cloudfront.net/GC/C4/L2/sc-GC-C4-L2-master.m3u8)|[code](https://github.com/https-deeplearning-ai/sc-gc-c4-gemini-public/tree/main/lesson-2)|
|Best Practices for Multimodal Prompting|[video](https://dyckms5inbsqq.cloudfront.net/GC/C4/L3/sc-GC-C4-L3-master.m3u8)||
|Creating Use Cases with Images|[video](https://dyckms5inbsqq.cloudfront.net/GC/C4/L4/sc-GC-C4-L4-master.m3u8)|[code](https://github.com/https-deeplearning-ai/sc-gc-c4-gemini-public/tree/main/lesson-4)|
|Developing Use Cases with Videos|[video](https://dyckms5inbsqq.cloudfront.net/GC/C4/L5/sc-GC-C4-L5-master.m3u8)|[code](https://github.com/https-deeplearning-ai/sc-gc-c4-gemini-public/tree/main/lesson-5)|
|Integrating Real-Time Data with Function Calling|[video](https://dyckms5inbsqq.cloudfront.net/GC/C4/L6/sc-GC-C4-L6-master.m3u8)|[code](https://github.com/https-deeplearning-ai/sc-gc-c4-gemini-public/tree/main/lesson-6)|
|Conclusion|[video](https://dyckms5inbsqq.cloudfront.net/GC/C4/Conclusion/sc-GC-C4-Conclusion-master.m3u8)||
|How to Set Up your Google Cloud Account - Try it out Yourself (optional)||[code]()|


## Try it out Yourself
Thank you for taking the time to go through this course! 


Due to technical requirements, we cannot  provide you with a lab environment to run the notebooks. However, in this document, weâ€™ll walk you step-by-step on how to set up Google Cloud, and do multimodal prompting with Gemini models via VertexAI on your own. This is completely optional. You can learn to use Gemini by simply viewing the course.


ðŸ’» You can access the official github repository of this course from [here](https://www.google.com/url?q=https://github.com/https-deeplearning-ai/sc-gc-c4-gemini-public&sa=D&source=editors&ust=1724806171124720&usg=AOvVaw0BAgF_oCnbSwSB86VQlbd3).

The github repository contains:

- 4 folders, which include the notebooks and supplementary files for each lesson.
  - The notebooks can run as Google Colabs as they are. (Open the links in a new tab.)
    - [Colab of Lesson 2: Multimodal Prompting and Parameter Control](https://www.google.com/url?q=https://colab.sandbox.google.com/github/https-deeplearning-ai/sc-gc-c4-gemini-public/blob/main/lesson-2/L2_colab_prompting_and_parameters.ipynb&sa=D&source=editors&ust=1724806171125472&usg=AOvVaw3s5zEkSayi5sA6q5Keun-I)
    - [Colab of Lesson 4: Creating Use Cases with Images](https://www.google.com/url?q=https://colab.sandbox.google.com/github/https-deeplearning-ai/sc-gc-c4-gemini-public/blob/main/lesson-4/L4_colab_images.ipynb&sa=D&source=editors&ust=1724806171125819&usg=AOvVaw1BlU9QDGbYywgqb5vVSLrM)
    - [Colab of Lesson 5: Developing Use Cases with Videos](https://www.google.com/url?q=https://colab.sandbox.google.com/github/https-deeplearning-ai/sc-gc-c4-gemini-public/blob/main/lesson-5/L5_colab_videos.ipynb&sa=D&source=editors&ust=1724806171126217&usg=AOvVaw3SOrOBTNXGZ4LkAwdD5D3f)
    - [Colab of Lesson 6: Integrating Real-Time Data with Function Calling](https://www.google.com/url?q=https://colab.sandbox.google.com/github/https-deeplearning-ai/sc-gc-c4-gemini-public/blob/main/lesson-6/L6_colab_function_calling.ipynb&sa=D&source=editors&ust=1724806171126628&usg=AOvVaw3pv34hvvrR0VdjRQz9KrPg)
- A `requirements.txt` file to help you to set up your environment (if running locally)

NOTE: The steps below will walk you through how to set up your Google Cloud account to run these notebooks ONLY as Colabs.