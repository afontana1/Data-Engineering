{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain of Thought (CoT) Prompting Tutorial\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial introduces Chain of Thought (CoT) prompting, a powerful technique in prompt engineering that encourages AI models to break down complex problems into step-by-step reasoning processes. We'll explore how to implement CoT prompting using OpenAI's GPT models and the LangChain library.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "As AI language models become more advanced, there's an increasing need to guide them towards producing more transparent, logical, and verifiable outputs. CoT prompting addresses this need by encouraging models to show their work, much like how humans approach complex problem-solving tasks. This technique not only improves the accuracy of AI responses but also makes them more interpretable and trustworthy.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. **Basic CoT Prompting**: Introduction to the concept and simple implementation.\n",
    "2. **Advanced CoT Techniques**: Exploring more sophisticated CoT approaches.\n",
    "3. **Comparative Analysis**: Examining the differences between standard and CoT prompting.\n",
    "4. **Problem-Solving Applications**: Applying CoT to various complex tasks.\n",
    "\n",
    "## Method Details\n",
    "\n",
    "The tutorial will guide learners through the following methods:\n",
    "\n",
    "1. **Setting up the environment**: We'll start by importing necessary libraries and setting up the OpenAI API.\n",
    "\n",
    "2. **Basic CoT Implementation**: We'll create simple CoT prompts and compare their outputs to standard prompts.\n",
    "\n",
    "3. **Advanced CoT Techniques**: We'll explore more complex CoT strategies, including multi-step reasoning and self-consistency checks.\n",
    "\n",
    "4. **Practical Applications**: We'll apply CoT prompting to various problem-solving scenarios, such as mathematical word problems and logical reasoning tasks.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "By the end of this tutorial, learners will have a solid understanding of Chain of Thought prompting and its applications. They will be equipped with practical skills to implement CoT techniques in various scenarios, improving the quality and interpretability of AI-generated responses. This knowledge will be valuable for anyone working with large language models, from developers and researchers to business analysts and decision-makers relying on AI-powered insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Chain of Thought Prompting\n",
    "\n",
    "Let's start with a simple example to demonstrate the difference between a standard prompt and a Chain of Thought prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Response:\n",
      "The average speed of the train is 60 km/h.\n",
      "\n",
      "Chain of Thought Response:\n",
      "Step 1: Calculate the average speed by dividing the total distance traveled by the total time taken.\n",
      "\n",
      "Step 2: Average speed = Total distance / Total time\n",
      "\n",
      "Step 3: Average speed = 120 km / 2 hours\n",
      "\n",
      "Step 4: Average speed = 60 km/h\n",
      "\n",
      "Therefore, the average speed of the train is 60 km/h.\n"
     ]
    }
   ],
   "source": [
    "# Standard prompt\n",
    "standard_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer the following question conciesly: {question}.\"\n",
    ")\n",
    "\n",
    "# Chain of Thought prompt\n",
    "cot_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer the following question step by step conciesly: {question}\"\n",
    ")\n",
    "\n",
    "# Create chains\n",
    "standard_chain = standard_prompt | llm\n",
    "cot_chain = cot_prompt | llm\n",
    "\n",
    "# Example question\n",
    "question = \"If a train travels 120 km in 2 hours, what is its average speed in km/h?\"\n",
    "\n",
    "# Get responses\n",
    "standard_response = standard_chain.invoke(question).content\n",
    "cot_response = cot_chain.invoke(question).content\n",
    "\n",
    "print(\"Standard Response:\")\n",
    "print(standard_response)\n",
    "print(\"\\nChain of Thought Response:\")\n",
    "print(cot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Chain of Thought Techniques\n",
    "\n",
    "Now, let's explore a more advanced CoT technique that encourages multi-step reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Calculate the total distance traveled and the total time taken for the entire journey.\n",
      "2. Total distance = 150 km + 100 km = 250 km.\n",
      "   Total time = (150 km / 60 km/h) + (100 km / 50 km/h).\n",
      "3. Total time = (2.5 hours) + (2 hours) = 4.5 hours.\n",
      "4. The total distance traveled is 250 km, and the total time taken is 4.5 hours. To find the average speed, we divide the total distance by the total time:\n",
      "   Average speed = Total distance / Total time\n",
      "                   = 250 km / 4.5 hours\n",
      "                   ≈ 55.56 km/h.\n",
      "5. Therefore, the average speed for the entire journey is approximately 55.56 km/h.\n"
     ]
    }
   ],
   "source": [
    "advanced_cot_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"Solve the following problem step by step. For each step:\n",
    "1. State what you're going to calculate\n",
    "2. Write the formula you'll use (if applicable)\n",
    "3. Perform the calculation\n",
    "4. Explain the result\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Solution:\"\"\"\n",
    ")\n",
    "\n",
    "advanced_cot_chain = advanced_cot_prompt | llm\n",
    "\n",
    "complex_question = \"A car travels 150 km at 60 km/h, then another 100 km at 50 km/h. What is the average speed for the entire journey?\"\n",
    "\n",
    "advanced_cot_response = advanced_cot_chain.invoke(complex_question).content\n",
    "print(advanced_cot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis\n",
    "\n",
    "Let's compare the effectiveness of standard prompting vs. CoT prompting on a more challenging problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Response:\n",
      "It will take approximately 3 hours and 56 minutes for the tank to overflow.\n",
      "\n",
      "Chain of Thought Response:\n",
      "Step 1: Calculate the volume of the water in the tank when it is 2/3 full.\n",
      "1. Calculate the volume of the cylinder\n",
      "   Formula: V = πr^2h\n",
      "   V = 3.14159 * (1.5)^2 * 4\n",
      "   V ≈ 28.27433 cubic meters\n",
      "\n",
      "2. Calculate the volume of water in the tank when it is 2/3 full\n",
      "   Volume = 2/3 * 28.27433\n",
      "   Volume ≈ 18.84955 cubic meters\n",
      "\n",
      "Step 2: Calculate how long it will take for the tank to overflow.\n",
      "1. Calculate the remaining volume until the tank overflows\n",
      "   Remaining Volume = 28.27433 - 18.84955\n",
      "   Remaining Volume ≈ 9.42478 cubic meters\n",
      "\n",
      "2. Convert the remaining volume to liters\n",
      "   Remaining Volume in liters = 9424.78 * 1000\n",
      "   Remaining Volume in liters = 9424.78 liters\n",
      "\n",
      "3. Calculate the time it will take for the tank to overflow\n",
      "   Time = Remaining Volume / Rate of water addition\n",
      "   Time = 9424.78 / 10\n",
      "   Time ≈ 942.478 minutes\n",
      "\n",
      "Step 3: Convert the time to hours and minutes\n",
      "1. Convert the time to hours\n",
      "   Hours = 942.478 / 60\n",
      "   Hours ≈ 15.70797 hours\n",
      "\n",
      "2. Calculate the remaining minutes\n",
      "   Remaining Minutes = 0.70797 * 60\n",
      "   Remaining Minutes ≈ 42.4782 minutes\n",
      "\n",
      "Step 4: Final answer\n",
      "It will take approximately 15 hours and 42 minutes for the tank to overflow when water is being added at a rate of 10 liters per minute.\n"
     ]
    }
   ],
   "source": [
    "challenging_question = \"\"\"\n",
    "A cylindrical water tank with a radius of 1.5 meters and a height of 4 meters is 2/3 full. \n",
    "If water is being added at a rate of 10 liters per minute, how long will it take for the tank to overflow? \n",
    "Give your answer in hours and minutes, rounded to the nearest minute. \n",
    "(Use 3.14159 for π and 1000 liters = 1 cubic meter)\"\"\"\n",
    "\n",
    "standard_response = standard_chain.invoke(challenging_question).content\n",
    "cot_response = advanced_cot_chain.invoke(challenging_question).content\n",
    "\n",
    "print(\"Standard Response:\")\n",
    "print(standard_response)\n",
    "print(\"\\nChain of Thought Response:\")\n",
    "print(cot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem-Solving Applications\n",
    "\n",
    "Now, let's apply CoT prompting to a more complex logical reasoning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the logical puzzle step by step.\n",
      "\n",
      "### List the Facts:\n",
      "\n",
      "1. **Characters Involved:**\n",
      "   - Amy\n",
      "   - Bob\n",
      "   - Charlie\n",
      "\n",
      "2. **Statements:**\n",
      "   - Amy says, \"Bob is a liar.\"\n",
      "   - Bob says, \"Charlie alternates between truth and lies.\"\n",
      "   - Charlie says, \"Amy and I are both liars.\"\n",
      "\n",
      "3. **Roles:**\n",
      "   - One person is a truth-teller (always tells the truth).\n",
      "   - One person is a liar (always lies).\n",
      "   - One person alternates between truth and lies.\n",
      "\n",
      "### Identify Possible Roles or Conditions:\n",
      "\n",
      "- Each character can be either:\n",
      "  - A truth-teller\n",
      "  - A liar\n",
      "  - An alternator\n",
      "\n",
      "### Note the Constraints:\n",
      "\n",
      "1. There is exactly one truth-teller, one liar, and one alternator.\n",
      "2. The statements made by each character must align with their assigned roles.\n",
      "\n",
      "### Generate Possible Scenarios:\n",
      "\n",
      "Let's analyze each possible assignment of roles systematically:\n",
      "\n",
      "#### Scenario 1: Amy is the Truth-teller\n",
      "\n",
      "- **Amy (Truth-teller):** \"Bob is a liar.\"\n",
      "- **Bob (Liar):** This would imply Bob is lying about Charlie alternating.\n",
      "- **Charlie (Alternator):** \"Amy and I are both liars.\"\n",
      "\n",
      "  - If Charlie is alternating, his statement must be a lie since he would alternate from a previous truth. However, for him to be a liar in this statement, it must be false, which means Amy isn't a liar (consistent with her being a truth-teller), but he would be contradicting himself by saying he is a liar (which is a lie).\n",
      "\n",
      "#### Scenario 2: Amy is the Liar\n",
      "\n",
      "- **Amy (Liar):** \"Bob is a liar.\" (False, so Bob is not a liar)\n",
      "- **Bob (Truth-teller):** \"Charlie alternates between truth and lies.\"\n",
      "- **Charlie (Alternator):** \"Amy and I are both liars.\"\n",
      "\n",
      "  - Charlie’s statement would have to be false (right now) as Amy is indeed a liar, but Charlie is not (since he’s an alternator). This matches his alternating nature.\n",
      "\n",
      "#### Scenario 3: Amy is the Alternator\n",
      "\n",
      "- **Amy (Alternator):** \"Bob is a liar.\"\n",
      "- **Bob (Truth-teller):** \"Charlie alternates between truth and lies.\"\n",
      "- **Charlie (Liar):** \"Amy and I are both liars.\"\n",
      "\n",
      "  - Bob’s statement is true, meaning Charlie is indeed alternating, which contradicts the assumption of Charlie being a liar.\n",
      "\n",
      "### Test Each Scenario:\n",
      "\n",
      "After testing each scenario, only Scenario 2 holds consistently:\n",
      "\n",
      "- **Amy (Liar):** Her statement \"Bob is a liar\" is false, which is consistent with Bob being the truth-teller.\n",
      "- **Bob (Truth-teller):** His statement \"Charlie alternates between truth and lies\" is true.\n",
      "- **Charlie (Alternator):** His alternating nature allows him to say \"Amy and I are both liars,\" which aligns with him alternating and being false at that moment.\n",
      "\n",
      "### Eliminate Inconsistent Scenarios:\n",
      "\n",
      "- Scenario 1 and Scenario 3 lead to contradictions and are therefore eliminated.\n",
      "\n",
      "### Conclude the Solution:\n",
      "\n",
      "- **Amy is the Liar.**\n",
      "- **Bob is the Truth-teller.**\n",
      "- **Charlie is the Alternator.**\n",
      "\n",
      "### Provide a Clear Answer:\n",
      "\n",
      "Amy is the liar because her statement is false. Bob is the truth-teller because his statement is true. Charlie is the alternator because his statement is false at this instance, consistent with his alternating nature. This is the only scenario that fits all the constraints without contradiction.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "logical_reasoning_prompt = PromptTemplate(\n",
    "    input_variables=[\"scenario\"],\n",
    "    template=\"\"\"Analyze the following logical puzzle thoroughly. Follow these steps in your analysis:\n",
    "\n",
    "List the Facts:\n",
    "\n",
    "Summarize all the given information and statements clearly.\n",
    "Identify all the characters or elements involved.\n",
    "Identify Possible Roles or Conditions:\n",
    "\n",
    "Determine all possible roles, behaviors, or states applicable to the characters or elements (e.g., truth-teller, liar, alternator).\n",
    "Note the Constraints:\n",
    "\n",
    "Outline any rules, constraints, or relationships specified in the puzzle.\n",
    "Generate Possible Scenarios:\n",
    "\n",
    "Systematically consider all possible combinations of roles or conditions for the characters or elements.\n",
    "Ensure that all permutations are accounted for.\n",
    "Test Each Scenario:\n",
    "\n",
    "For each possible scenario:\n",
    "Assume the roles or conditions you've assigned.\n",
    "Analyze each statement based on these assumptions.\n",
    "Check for consistency or contradictions within the scenario.\n",
    "Eliminate Inconsistent Scenarios:\n",
    "\n",
    "Discard any scenarios that lead to contradictions or violate the constraints.\n",
    "Keep track of the reasoning for eliminating each scenario.\n",
    "Conclude the Solution:\n",
    "\n",
    "Identify the scenario(s) that remain consistent after testing.\n",
    "Summarize the findings.\n",
    "Provide a Clear Answer:\n",
    "\n",
    "State definitively the role or condition of each character or element.\n",
    "Explain why this is the only possible solution based on your analysis.\n",
    "Scenario:\n",
    "\n",
    "{scenario}\n",
    "\n",
    "Analysis:\"\"\")\n",
    "\n",
    "logical_reasoning_chain = logical_reasoning_prompt | llm\n",
    "\n",
    "logical_puzzle = \"\"\"In a room, there are three people: Amy, Bob, and Charlie. \n",
    "One of them always tells the truth, one always lies, and one alternates between truth and lies. \n",
    "Amy says, 'Bob is a liar.' \n",
    "Bob says, 'Charlie alternates between truth and lies.' \n",
    "Charlie says, 'Amy and I are both liars.' \n",
    "Determine the nature (truth-teller, liar, or alternator) of each person.\"\"\"\n",
    "\n",
    "logical_reasoning_response = logical_reasoning_chain.invoke(logical_puzzle).content\n",
    "print(logical_reasoning_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
