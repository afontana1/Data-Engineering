{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Learning and In-Context Learning Tutorial\n",
    "\n",
    "## Overview\n",
    "This tutorial explores the cutting-edge techniques of Few-Shot Learning and In-Context Learning using OpenAI's GPT models and the LangChain library. These methods enable AI models to perform complex tasks with minimal examples, revolutionizing the way we approach machine learning problems.\n",
    "\n",
    "## Motivation\n",
    "Traditional machine learning often requires large datasets for training, which can be time-consuming and resource-intensive. Few-Shot Learning and In-Context Learning address this limitation by leveraging the power of large language models to perform tasks with just a handful of examples. This approach is particularly valuable in scenarios where labeled data is scarce or expensive to obtain.\n",
    "\n",
    "## Key Components\n",
    "1. **OpenAI's GPT Models**: State-of-the-art language models that serve as the foundation for our learning techniques.\n",
    "2. **LangChain Library**: A powerful tool that simplifies the process of working with large language models.\n",
    "3. **PromptTemplate**: A structured way to format inputs for the language model.\n",
    "4. **LLMChain**: Manages the interaction between the prompt and the language model.\n",
    "\n",
    "## Method Details\n",
    "\n",
    "### 1. Basic Few-Shot Learning\n",
    "- Implementation of a sentiment classification task using few-shot learning.\n",
    "- Demonstration of how to structure a prompt with examples for the model to learn from.\n",
    "- Explanation of how the model generalizes from these examples to new inputs.\n",
    "\n",
    "### 2. Advanced Few-Shot Techniques\n",
    "- Exploration of multi-task learning for sentiment analysis and language detection.\n",
    "- Discussion on how to design prompts that enable a single model to perform multiple related tasks.\n",
    "- Insights into the benefits of this approach, such as improved efficiency and better generalization.\n",
    "\n",
    "### 3. In-Context Learning\n",
    "- Demonstration of in-context learning for a custom task (e.g., text transformation).\n",
    "- Explanation of how models can adapt to new tasks based solely on examples provided in the prompt.\n",
    "- Discussion on the flexibility and limitations of this approach.\n",
    "\n",
    "### 4. Best Practices and Evaluation\n",
    "- Guidelines for selecting effective examples for few-shot learning.\n",
    "- Techniques for prompt engineering to optimize model performance.\n",
    "- Implementation of an evaluation framework to assess model accuracy.\n",
    "- Discussion on the importance of diverse test cases and appropriate metrics.\n",
    "\n",
    "## Conclusion\n",
    "Few-Shot Learning and In-Context Learning represent a significant advancement in the field of artificial intelligence. By enabling models to perform complex tasks with minimal examples, these techniques open up new possibilities for AI applications in areas where data is limited. This tutorial provides a solid foundation for understanding and implementing these powerful methods, equipping learners with the tools to leverage large language models effectively in their own projects.\n",
    "\n",
    "As the field continues to evolve, mastering these techniques will be crucial for AI practitioners looking to stay at the forefront of natural language processing and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY') # OpenAI API key\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Few-Shot Learning\n",
    "\n",
    "We'll implement a basic few-shot learning scenario for sentiment classification.\n",
    "\n",
    "Sentiment Classification:\n",
    "- Definition: Determining the emotional tone behind a series of words.\n",
    "- Applications: Customer service, market research, social media analysis.\n",
    "\n",
    "Few-Shot Learning Approach:\n",
    "1. Provide a small set of labeled examples (3 in this case).\n",
    "2. Structure the prompt to clearly present examples and the new input.\n",
    "3. Leverage the pre-trained knowledge of the language model.\n",
    "\n",
    "Key Components:\n",
    "- PromptTemplate: Structures the input for the model.\n",
    "- LLMChain: Manages the interaction between the prompt and the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I can't believe how great this new restaurant is!\n",
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "def few_shot_sentiment_classification(input_text):\n",
    "    few_shot_prompt = PromptTemplate(\n",
    "        input_variables=[\"input_text\"],\n",
    "        template=\"\"\"\n",
    "        Classify the sentiment as Positive, Negative, or Neutral.\n",
    "        \n",
    "        Examples:\n",
    "        Text: I love this product! It's amazing.\n",
    "        Sentiment: Positive\n",
    "        \n",
    "        Text: This movie was terrible. I hated it.\n",
    "        Sentiment: Negative\n",
    "        \n",
    "        Text: The weather today is okay.\n",
    "        Sentiment: Neutral\n",
    "        \n",
    "        Now, classify the following:\n",
    "        Text: {input_text}\n",
    "        Sentiment:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = few_shot_prompt | llm\n",
    "    result = chain.invoke(input_text).content\n",
    "\n",
    "    # Clean up the result\n",
    "    result = result.strip()\n",
    "    # Extract only the sentiment label\n",
    "    if ':' in result:\n",
    "        result = result.split(':')[1].strip()\n",
    "    \n",
    "    return result  # This will now return just \"Positive\", \"Negative\", or \"Neutral\"\n",
    "\n",
    "test_text = \"I can't believe how great this new restaurant is!\"\n",
    "result = few_shot_sentiment_classification(test_text)\n",
    "print(f\"Input: {test_text}\")\n",
    "print(f\"Predicted Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Few-Shot Techniques\n",
    "\n",
    "We'll now explore multi-task learning for sentiment analysis and language detection.\n",
    "\n",
    "Multi-task Learning:\n",
    "- Definition: Training a model to perform multiple related tasks simultaneously.\n",
    "- Benefits: Improved efficiency, better generalization, reduced overfitting.\n",
    "\n",
    "Implementation:\n",
    "1. Design a prompt template that includes examples for multiple tasks.\n",
    "2. Use task-specific instructions to guide the model's behavior.\n",
    "3. Demonstrate how the same model can switch between tasks based on input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Result: German\n"
     ]
    }
   ],
   "source": [
    "def multi_task_few_shot(input_text, task):\n",
    "    few_shot_prompt = PromptTemplate(\n",
    "        input_variables=[\"input_text\", \"task\"],\n",
    "        template=\"\"\"\n",
    "        Perform the specified task on the given text.\n",
    "        \n",
    "        Examples:\n",
    "        Text: I love this product! It's amazing.\n",
    "        Task: sentiment\n",
    "        Result: Positive\n",
    "        \n",
    "        Text: Bonjour, comment allez-vous?\n",
    "        Task: language\n",
    "        Result: French\n",
    "        \n",
    "        Now, perform the following task:\n",
    "        Text: {input_text}\n",
    "        Task: {task}\n",
    "        Result:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = few_shot_prompt | llm\n",
    "    return chain.invoke({\"input_text\": input_text, \"task\": task}).content\n",
    "\n",
    "print(multi_task_few_shot(\"I can't believe how great this is!\", \"sentiment\"))\n",
    "print(multi_task_few_shot(\"Guten Tag, wie geht es Ihnen?\", \"language\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Context Learning\n",
    "\n",
    "In-Context Learning allows models to adapt to new tasks based on examples provided in the prompt.\n",
    "\n",
    "Key Aspects:\n",
    "1. No fine-tuning required: The model learns from examples in the prompt.\n",
    "2. Flexibility: Can be applied to a wide range of tasks.\n",
    "3. Prompt engineering: Careful design of prompts is crucial for performance.\n",
    "\n",
    "Example Implementation:\n",
    "We'll demonstrate in-context learning for a custom task (converting text to pig latin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: python\n",
      "Output: Output: ythonpay\n"
     ]
    }
   ],
   "source": [
    "def in_context_learning(task_description, examples, input_text):\n",
    "    example_text = \"\".join([f\"Input: {e['input']}\\nOutput: {e['output']}\\n\\n\" for e in examples])\n",
    "    \n",
    "    in_context_prompt = PromptTemplate(\n",
    "        input_variables=[\"task_description\", \"examples\", \"input_text\"],\n",
    "        template=\"\"\"\n",
    "        Task: {task_description}\n",
    "        \n",
    "        Examples:\n",
    "        {examples}\n",
    "        \n",
    "        Now, perform the task on the following input:\n",
    "        Input: {input_text}\n",
    "        Output:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = in_context_prompt | llm\n",
    "    return chain.invoke({\"task_description\": task_description, \"examples\": example_text, \"input_text\": input_text}).content\n",
    "\n",
    "task_desc = \"Convert the given text to pig latin.\"\n",
    "examples = [\n",
    "    {\"input\": \"hello\", \"output\": \"ellohay\"},\n",
    "    {\"input\": \"apple\", \"output\": \"appleay\"}\n",
    "]\n",
    "test_input = \"python\"\n",
    "\n",
    "result = in_context_learning(task_desc, examples, test_input)\n",
    "print(f\"Input: {test_input}\")\n",
    "print(f\"Output: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices and Evaluation\n",
    "\n",
    "To maximize the effectiveness of few-shot and in-context learning:\n",
    "\n",
    "1. Example Selection:\n",
    "   - Diversity: Cover different aspects of the task.\n",
    "   - Clarity: Use unambiguous examples.\n",
    "   - Relevance: Choose examples similar to expected inputs.\n",
    "   - Balance: Ensure equal representation of classes/categories.\n",
    "   - Edge cases: Include examples of unusual or difficult cases.\n",
    "\n",
    "2. Prompt Engineering:\n",
    "   - Clear instructions: Specify the task explicitly.\n",
    "   - Consistent format: Maintain a uniform structure for examples and inputs.\n",
    "   - Conciseness: Avoid unnecessary information that may confuse the model.\n",
    "\n",
    "3. Evaluation:\n",
    "   - Create a diverse test set.\n",
    "   - Compare model predictions to true labels.\n",
    "   - Use appropriate metrics (e.g., accuracy, F1 score) based on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: This product exceeded my expectations!\n",
      "Predicted: Positive\n",
      "Actual: Positive\n",
      "Correct: True\n",
      "\n",
      "Input: I'm utterly disappointed with the service.\n",
      "Predicted: Negative\n",
      "Actual: Negative\n",
      "Correct: True\n",
      "\n",
      "Input: The temperature today is 72 degrees.\n",
      "Predicted: Neutral\n",
      "Actual: Neutral\n",
      "Correct: True\n",
      "\n",
      "Model Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model_func, test_cases):\n",
    "    '''\n",
    "    Evaluate the model on a set of test cases.\n",
    "\n",
    "    Args:\n",
    "    model_func: The function that makes predictions.\n",
    "    test_cases: A list of dictionaries, where each dictionary contains an \"input\" text and a \"label\" for the input.\n",
    "\n",
    "    Returns:\n",
    "    The accuracy of the model on the test cases. \n",
    "    '''\n",
    "    correct = 0\n",
    "    total = len(test_cases)\n",
    "    \n",
    "    for case in test_cases:\n",
    "        input_text = case['input']\n",
    "        true_label = case['label']\n",
    "        prediction = model_func(input_text).strip()\n",
    "        \n",
    "        is_correct = prediction.lower() == true_label.lower()\n",
    "        correct += int(is_correct)\n",
    "        \n",
    "        print(f\"Input: {input_text}\")\n",
    "        print(f\"Predicted: {prediction}\")\n",
    "        print(f\"Actual: {true_label}\")\n",
    "        print(f\"Correct: {is_correct}\\n\")\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "test_cases = [\n",
    "    {\"input\": \"This product exceeded my expectations!\", \"label\": \"Positive\"},\n",
    "    {\"input\": \"I'm utterly disappointed with the service.\", \"label\": \"Negative\"},\n",
    "    {\"input\": \"The temperature today is 72 degrees.\", \"label\": \"Neutral\"}\n",
    "]\n",
    "\n",
    "accuracy = evaluate_model(few_shot_sentiment_classification, test_cases)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
