{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Conversational Agent with Context Awareness with PydanticAI\n",
    "\n",
    "**This tutorial is based off of the LangChain tutorial: `Building a Conversational Agent with Context Awareness`. It demonstrates the same concept using PydanticAI as the agent framework.**\n",
    "\n",
    "## PydanticAI\n",
    "\n",
    "[PydanticAI](https://ai.pydantic.dev/) is a new Python agent framework designed to make it less painful to build production grade applications with Generative AI. Developed by the team behind **Pydantic**, it brings the same robust validation and type-safety principles that have made Pydantic a cornerstone for many LLM libraries, including OpenAI SDK, Anthropic SDK, LangChain, LlamaIndex, and more.\n",
    "\n",
    "With PydanticAI, control flow and agent composition are handled using **vanilla Python**, allowing you to apply the same development best practices youâ€™d use in any other (non-AI) project.\n",
    "\n",
    "Key features include:\n",
    "\n",
    "- **[Validation](https://ai.pydantic.dev/results/#structured-result-validation)** and **[type safety](https://ai.pydantic.dev/agents/#static-type-checking)** powered by Pydantic.\n",
    "- A **[dependency injection system](https://ai.pydantic.dev/dependencies/)** for defining tools, with demonstrations in upcoming notebooks.\n",
    "- **[Logfire](https://ai.pydantic.dev/logfire/)**, a debugging and monitoring tool for enhanced observability.\n",
    "- And much more!\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial outlines the process of creating a conversational agent that maintains context across multiple interactions. We'll use a modern AI framework to build an agent capable of engaging in more natural and coherent conversations.\n",
    "\n",
    "## Motivation\n",
    "Many simple chatbots lack the ability to maintain context, leading to disjointed and frustrating user experiences. This tutorial aims to solve that problem by implementing a conversational agent that can remember and refer to previous parts of the conversation, enhancing the overall interaction quality.\n",
    "\n",
    "## Key Components\n",
    "1. **Language Model**: The core AI component that generates responses.\n",
    "2. **Prompt Template**: Defines the structure of our conversations.\n",
    "3. **History Manager**: Manages conversation history and context.\n",
    "4. **Message Store**: Stores the messages for each conversation session.\n",
    "\n",
    "## Method Details\n",
    "\n",
    "### Setting Up the Environment\n",
    "Begin by setting up the necessary AI framework and ensuring access to a suitable language model. This forms the foundation of our conversational agent.\n",
    "\n",
    "### Creating the Chat History Store\n",
    "Implement a system to manage multiple conversation sessions. Each session should be uniquely identifiable and associated with its own message history.\n",
    "\n",
    "### Defining the Conversation Structure\n",
    "Create a template that includes:\n",
    "- A system message defining the AI's role\n",
    "- A placeholder for conversation history\n",
    "- The user's input\n",
    "\n",
    "This structure guides the AI's responses and maintains consistency throughout the conversation.\n",
    "\n",
    "### Building the Conversational Agent\n",
    "Combine the prompt template with the language model to create a basic conversational agent. Wrap the agent with a history management component that automatically handles the insertion and retrieval of conversation history.\n",
    "\n",
    "### Interacting with the Agent\n",
    "To use the agent, invoke it with a user input and a session identifier. The history manager takes care of retrieving the appropriate conversation history, inserting it into the prompt, and storing new messages after each interaction.\n",
    "\n",
    "## Conclusion\n",
    "This approach to creating a conversational agent offers several advantages:\n",
    "- **Context Awareness**: The agent can refer to previous parts of the conversation, leading to more natural interactions.\n",
    "- **Simplicity**: The modular design keeps the implementation straightforward.\n",
    "- **Flexibility**: It's easy to modify the conversation structure or switch to a different language model.\n",
    "- **Scalability**: The session-based approach allows for managing multiple independent conversations.\n",
    "\n",
    "With this foundation, you can further enhance the agent by:\n",
    "- Implementing more sophisticated prompt engineering\n",
    "- Integrating it with external knowledge bases\n",
    "- Adding specialized capabilities for specific domains\n",
    "- Incorporating error handling and conversation repair strategies\n",
    "\n",
    "By focusing on context management, this conversational agent design significantly improves upon basic chatbot functionality, paving the way for more engaging and helpful AI assistants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Agent Tutorial\n",
    "\n",
    "This notebook demonstrates how to create a simple conversational agent using PydanticAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q pydantic-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from itertools import chain\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.messages import Message, MessagesTypeAdapter\n",
    "from pydantic_ai.result import RunResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed because we're running asyncio code inside a Jupyter notebook.\n",
    "# Otherwise, we'll get an error that we're trying to start a new event loop when\n",
    "# there's already an event loop running.\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables and initialize the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LOGFIRE_IGNORE_NO_CONFIG'] = '1'\n",
    "\n",
    "agent = Agent(\n",
    "    model='openai:gpt-4o-mini',\n",
    "    system_prompt='You are a helpful AI assistant.',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create a simple in-memory store for chat histories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dummy storage. In real applications, this will probably be a database.\n",
    "# Note that we convert the messages from Pydantic's `Message` type to `bytes`\n",
    "# before we store them. This is to simulate the way it'll be in a real-life\n",
    "# application.\n",
    "store: dict[str, list[bytes]] = {}\n",
    "\n",
    "def create_session_if_not_exists(session_id: str) -> None:\n",
    "    \"\"\"Makes sure that `session_id` exists in the chat storage.\"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id]: list[Message] = []\n",
    "    \n",
    "def get_chat_history(session_id: str) -> list[Message]:\n",
    "    \"\"\"Returns the existing chat history.\"\"\"\n",
    "    \n",
    "    create_session_if_not_exists(session_id)\n",
    "\n",
    "    # Convert from `bytes` to a list of `Message`s and return the history.\n",
    "    return list(chain.from_iterable(\n",
    "        MessagesTypeAdapter.validate_json(msg_group)\n",
    "        for msg_group in store[session_id]\n",
    "    ))\n",
    "\n",
    "def store_messages_in_history(session_id: str, run_result: RunResult) -> None:\n",
    "    \"\"\"Stores all new messages from the recent `run` with the model, into the local store.\n",
    "\n",
    "    Receives a session ID and the results that the model returned, fetches all the new \n",
    "    messages in `bytes` format and stores them in our local storage.\n",
    "    \"\"\"\n",
    "    create_session_if_not_exists(session_id)\n",
    "\n",
    "    store[session_id].append(run_result.new_messages_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap the ask with message history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_with_history(user_message: str, user_session_id: str) -> RunResult:\n",
    "    \"\"\"Asks the chatbot the user's question and stores the new messages in the chat history.\"\"\"\n",
    "\n",
    "    # Get existing history to send to model\n",
    "    chat_history = get_chat_history(user_session_id)\n",
    "\n",
    "    # Ask user's question and send chat history.\n",
    "    chat_response: RunResult = agent.run_sync(user_message, message_history=chat_history)\n",
    "\n",
    "    # Store new messages in chat history.\n",
    "    store_messages_in_history(user_session_id, chat_response)\n",
    "\n",
    "    return chat_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "AI: Your previous message was: \"Hello! How are you?\" How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "session_id = 'user_123'\n",
    "\n",
    "result1 = ask_with_history('Hello! How are you?', session_id)\n",
    "print('AI:', result1.new_messages()[-1].content)\n",
    "\n",
    "result2 = ask_with_history('What was my previous message?', session_id)\n",
    "print('AI:', result2.new_messages()[-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation History:\n",
      "user: Hello! How are you?\n",
      "model-text-response: Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "user: What was my previous message?\n",
      "model-text-response: Your previous message was: \"Hello! How are you?\" How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "print('\\nConversation History:')\n",
    "for message in get_chat_history(session_id):\n",
    "    print(f'{message.role}: {message.content}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
