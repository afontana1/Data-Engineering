{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0tCJAxWOYzveZDoalFGZl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlaFalaki/langchain-vectordbs-course/blob/main/Module%205/Lesson%2005-Build_a_Question_Answering_Chatbot_over_Documents_with_Sources.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15BW5LkgIv0T",
        "outputId": "1161b679-2ffb-41a9-83fa-c3bbb4803821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain==0.0.208 deeplake openai tiktoken python-dotenv newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "!echo \"OPENAI_API_KEY='<OPENAI_API_KEY>'\" > .env\n",
        "!echo \"ACTIVELOOP_TOKEN='<ACTIVELOOP_TOKEN>'\" >> .env\n",
        "\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSFtehNoLP8C",
        "outputId": "68bd354a-9484-487d-8bad-54c9033e9859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from newspaper import Article # https://github.com/codelucas/newspaper\n",
        "import time\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
        "}\n",
        "\n",
        "article_urls = [\n",
        "    \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\",\n",
        "    \"https://www.artificialintelligence-news.com/2023/05/15/jay-migliaccio-ibm-watson-on-leveraging-ai-to-improve-productivity/\",\n",
        "    \"https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/\",\n",
        "    \"https://www.artificialintelligence-news.com/2023/05/11/ai-and-big-data-expo-north-america-begins-in-less-than-one-week/\",\n",
        "    \"https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\",\n",
        "    \"https://www.artificialintelligence-news.com/2023/04/28/palantir-demos-how-ai-can-used-military/\"\n",
        "]\n",
        "\n",
        "session = requests.Session()\n",
        "pages_content = [] # where we save the scraped articles\n",
        "\n",
        "for url in article_urls:\n",
        "    try:\n",
        "        time.sleep(2) # sleep two seconds for gentle scraping\n",
        "        response = session.get(url, headers=headers, timeout=10)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            article = Article(url)\n",
        "            article.download() # download HTML of webpage\n",
        "            article.parse() # parse HTML to extract the article text\n",
        "            pages_content.append({ \"url\": url, \"text\": article.text })\n",
        "        else:\n",
        "            print(f\"Failed to fetch article at {url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while fetching article at {url}: {e}\")\n",
        "\n",
        "#If an error occurs while fetching an article, we catch the exception and print\n",
        "#an error message. This ensures that even if one article fails to download,\n",
        "#the rest of the articles can still be processed."
      ],
      "metadata": {
        "id": "11eE6zWCL0Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import DeepLake\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "my_activeloop_org_id = \"<Your_Organization_Id>\" # TODO: use your organization id here\n",
        "my_activeloop_dataset_name = \"langchain_course_qabot_with_source\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
        "\n",
        "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFEMWNhjMFIA",
        "outputId": "b2ed20e4-ca1b-499d-dad0-180bfcd56b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Deep Lake dataset has been successfully created!\n",
            "The dataset is private so make sure you are logged in!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "-"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/ala/langchain_course_qabot_with_source\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hub://ala/langchain_course_qabot_with_source loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We split the article texts into small chunks. While doing so, we keep track of each\n",
        "# chunk metadata (i.e. the URL where it comes from). Each metadata is a dictionary and\n",
        "# we need to use the \"source\" key for the document source so that we can then use the\n",
        "# RetrievalQAWithSourcesChain class which will automatically retrieve the \"source\" item\n",
        "# from the metadata dictionary.\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "all_texts, all_metadatas = [], []\n",
        "for d in pages_content:\n",
        "    chunks = text_splitter.split_text(d[\"text\"])\n",
        "    for chunk in chunks:\n",
        "        all_texts.append(chunk)\n",
        "        all_metadatas.append({ \"source\": d[\"url\"] })"
      ],
      "metadata": {
        "id": "mCHYtEdeNATo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we add all the chunks to the deep lake, along with their metadata\n",
        "db.add_texts(all_texts, all_metadatas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt7SGYYcNlsS",
        "outputId": "06762267-cca6-4489-c064-2abae4583330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ingest: 100%|██████████| 1/1 [00:21<00:00\n",
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://ala/langchain_course_qabot_with_source', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
            "\n",
            "  tensor     htype     shape      dtype  compression\n",
            "  -------   -------   -------    -------  ------- \n",
            " embedding  generic  (49, 1536)  float32   None   \n",
            "    ids      text     (49, 1)      str     None   \n",
            " metadata    json     (49, 1)      str     None   \n",
            "   text      text     (49, 1)      str     None   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a9ac1d0c-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac1ece-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac1faa-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2054-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac20f4-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2180-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2216-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac22a2-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2338-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac23ce-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac245a-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac24e6-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2572-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2608-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2694-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac272a-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac27c0-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac284c-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac28ce-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2964-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac29e6-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2a72-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2b08-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2b94-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2c20-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2cc0-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2d4c-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2dd8-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2e64-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2efa-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac2f86-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac301c-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac30ee-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac318e-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac3224-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac32b0-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac3346-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac344a-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac34f4-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac3580-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac3602-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac368e-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac371a-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac37a6-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac3832-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac38b4-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac3940-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac39cc-ffe6-11ed-8434-0242ac1c000c',\n",
              " 'a9ac3a4e-ffe6-11ed-8434-0242ac1c000c']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we create a RetrievalQAWithSourcesChain chain, which is very similar to a\n",
        "# standard retrieval QA chain but it also keeps track of the sources of the\n",
        "# retrieved documents\n",
        "\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
        "\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm,\n",
        "                                                    chain_type=\"stuff\",\n",
        "                                                    retriever=db.as_retriever())"
      ],
      "metadata": {
        "id": "JcVe2PI_No7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We generate a response to a query using the chain. The response object is a dictionary containing\n",
        "# an \"answer\" field with the textual answer to the query, and a \"sources\" field containing a string made\n",
        "# of the concatenation of the metadata[\"source\"] strings of the retrieved documents.\n",
        "d_response = chain({\"question\": \"What does Geoffrey Hinton think about recent trends in AI?\"})\n",
        "\n",
        "print(\"Response:\")\n",
        "print(d_response[\"answer\"])\n",
        "print(\"Sources:\")\n",
        "for source in d_response[\"sources\"].split(\", \"):\n",
        "    print(\"- \" + source)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_KGRTNkOT6I",
        "outputId": "96f3e90d-7f92-4aca-a6ee-9d68a655dd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            " Geoffrey Hinton has expressed concerns about the potential dangers of AI, such as false text, images, and videos created by AI, and the impact of AI on the job market. He believes that AI has the potential to replace humans as the dominant species on Earth.\n",
            "\n",
            "Sources:\n",
            "- https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\n",
            "- https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pEcsDsp6OkbE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}