{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlaFalaki/langchain-vectordbs-course/blob/main/Module%206/Lesson%2003-Supercharge_Your_Blog_Posts_Automatically_with_LangChain_and_Google_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.0.208 openai tiktoken newspaper3k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdSIAIj-iXZp",
        "outputId": "d3e62703-ea95-47e3-acdd-3c41ccf1086a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.3/939.3 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N1YVZcngzRY"
      },
      "outputs": [],
      "source": [
        "# let's setup the keys\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = \"<GOOGLE_CSE_ID>\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"<GOOGLE_API_KEY>\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<OPENAI_API_KEY>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0Ed6yWdgzRa"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\"\n",
        "\n",
        "title = \"OpenAI CEO: AI regulation ‘is essential’\"\n",
        "\n",
        "text_all = \"\"\"Altman highlighted the potential benefits of AI technologies like ChatGPT and Dall-E 2 to help address significant challenges such as climate change and cancer, but he also stressed the need to mitigate the risks associated with increasingly powerful AI models.\n",
        "\n",
        "Altman proposed that governments consider implementing licensing and testing requirements for AI models that surpass a certain threshold of capabilities. He highlighted OpenAI’s commitment to safety and extensive testing before releasing any new systems, emphasising the company’s belief that ensuring the safety of AI is crucial.\n",
        "\n",
        "Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n",
        "\n",
        "Blumenthal raised concerns about various risks associated with AI, including deepfakes, weaponised disinformation, discrimination, harassment, and impersonation fraud. He also emphasised the potential displacement of workers in the face of a new industrial revolution driven by AI.\"\"\"\n",
        "\n",
        "text_to_change = \"\"\"Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWwSTxxbgzRb",
        "outputId": "0981d02a-1cab-498c-fb6d-2f35ce6af596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"AI implications for elections\"', '\"AI job displacement\"', '\"AI security risks\"']\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "template = \"\"\"You are an exceptional copywriter and content creator.\n",
        "\n",
        "You're reading an article with the following title:\n",
        "----------------\n",
        "{title}\n",
        "----------------\n",
        "\n",
        "You've just read the following piece of text from that article.\n",
        "----------------\n",
        "{text_all}\n",
        "----------------\n",
        "\n",
        "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
        "----------------\n",
        "{text_to_change}\n",
        "----------------\n",
        "\n",
        "What are some simple and high-level Google queries that you'd do to search for more info to add to that paragraph?\n",
        "Write 3 queries as a bullet point list, prepending each line with -.\n",
        "\"\"\"\n",
        "\n",
        "human_message_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        template=template,\n",
        "        input_variables=[\"text_to_change\", \"text_all\", \"title\"],\n",
        "    )\n",
        ")\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
        "chat = ChatOpenAI(temperature=0.9)\n",
        "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
        "response = chain.run({\n",
        "    \"text_to_change\": text_to_change,\n",
        "    \"text_all\": text_all,\n",
        "    \"title\": title\n",
        "})\n",
        "queries = [line[2:] for line in response.split(\"\\n\")]\n",
        "print(queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2k2kaY_gzRd"
      },
      "outputs": [],
      "source": [
        "# first, we create a tool that allows us to use Google search.\n",
        "# we'll use it to retrieve the first 10 results\n",
        "\n",
        "from langchain.tools import Tool\n",
        "from langchain.utilities import GoogleSearchAPIWrapper\n",
        "\n",
        "search = GoogleSearchAPIWrapper()\n",
        "TOP_N_RESULTS = 5\n",
        "\n",
        "def top_n_results(query):\n",
        "    return search.results(query, TOP_N_RESULTS)\n",
        "\n",
        "tool = Tool(\n",
        "    name = \"Google Search\",\n",
        "    description=\"Search Google for recent results.\",\n",
        "    func=top_n_results\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4yhq11bgzRd",
        "outputId": "61785be7-5171-4742-90f5-730db48e7b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job Displacement - AI SUPERPOWERS new book by Kai-Fu Lee of ...\n",
            "https://www.aisuperpowers.com/job-displacement\n",
            "AI Job Displacement Index. How will your job be affected by AI? Within the next fifteen years, AI and automation will be able to do virtually all basic work ...\n",
            "--------------------------------------------------\n",
            "OWASP AI Security and Privacy Guide | OWASP Foundation\n",
            "https://owasp.org/www-project-ai-security-and-privacy-guide/\n",
            "Feb 15, 2023 ... Particular AI security risks · Data Security Risks: · AI model attacks, or adversarial machine learning attacks represent important security risks ...\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# this is how we can use the tool. For each result, we have:\n",
        "# 1. the result title\n",
        "# 2. its URL\n",
        "# 3. and the snippet that we would see if we were on the Google UI\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for query in queries:\n",
        "    results = tool.run(query)\n",
        "    all_results += results\n",
        "\n",
        "    if \"title\" in results[0]: # Sample\n",
        "        print(results[0][\"title\"])\n",
        "        print(results[0][\"link\"])\n",
        "        print(results[0][\"snippet\"])\n",
        "        print(\"-\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C0q-i52gzRe",
        "outputId": "b76c9d60-5f96-4ecc-a16c-08ef1ec5f2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pages:  10\n"
          ]
        }
      ],
      "source": [
        "# let's visit all the URLs from the results and use the newspaper library\n",
        "# to download their texts. The library won't work on some URLs, e.g.\n",
        "# if the content is a PDF file or if the website has some anti-bot mechanisms\n",
        "# adopted.\n",
        "\n",
        "import newspaper\n",
        "\n",
        "pages_content = []\n",
        "\n",
        "for result in all_results:\n",
        "    try:\n",
        "        article = newspaper.Article(result[\"link\"])\n",
        "        article.download()\n",
        "        article.parse()\n",
        "        if len(article.text) > 0:\n",
        "            pages_content.append({ \"url\": result[\"link\"], \"text\": article.text })\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(\"Number of pages: \", len(pages_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktObmDfxgzRe",
        "outputId": "9eec2389-6d12-49fc-e094-7313c4a975a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks:  26\n"
          ]
        }
      ],
      "source": [
        "# we split the article texts into small chunks. While doing so, we keep track of each\n",
        "# chunk metadata (i.e. the URL where it comes from). Each metadata is a dictionary and\n",
        "# we need to use the \"source\" key for the document source so that the chain\n",
        "# that we'll create later knows where to retrieve the source.\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
        "\n",
        "docs = []\n",
        "for d in pages_content:\n",
        "    chunks = text_splitter.split_text(d[\"text\"])\n",
        "    for chunk in chunks:\n",
        "        new_doc = Document(page_content=chunk, metadata={ \"source\": d[\"url\"] })\n",
        "        docs.append(new_doc)\n",
        "\n",
        "print(\"Number of chunks: \", len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtXDiBx2gzRf"
      },
      "outputs": [],
      "source": [
        "# then, we embed both the chunks and the query\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "docs_embeddings = embeddings.embed_documents([doc.page_content for doc in docs])\n",
        "query_embedding = embeddings.embed_query(text_to_change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVULhkU9gzRf"
      },
      "outputs": [],
      "source": [
        "# next, we compute the cosine similarities between the document vectors and\n",
        "# the query vectors using numpy and sklearn. We are interested only in the top 3\n",
        "# chunks for now because we'll later put them in a prompt and the prompt size is\n",
        "# limited.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_top_k_indices(list_of_doc_vectors, query_vector, top_k):\n",
        "    # convert the lists of vectors to numpy arrays\n",
        "    list_of_doc_vectors = np.array(list_of_doc_vectors)\n",
        "    query_vector = np.array(query_vector)\n",
        "\n",
        "    # compute cosine similarities\n",
        "    similarities = cosine_similarity(query_vector.reshape(1, -1), list_of_doc_vectors).flatten()\n",
        "\n",
        "    # sort the vectors based on cosine similarity\n",
        "    sorted_indices = np.argsort(similarities)[::-1]\n",
        "\n",
        "    # retrieve the top K indices from the sorted list\n",
        "    top_k_indices = sorted_indices[:top_k]\n",
        "\n",
        "    return top_k_indices\n",
        "\n",
        "top_k = 3\n",
        "best_indexes = get_top_k_indices(docs_embeddings, query_embedding, top_k)\n",
        "best_k_documents = [doc for i, doc in enumerate(docs) if i in best_indexes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywfXTKUagzRg",
        "outputId": "0c830a5f-f9c7-45ff-9b51-599324ed07c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='How to Prepare for AI Job Displacement Kai-Fu Lee · Follow · Oct 25, 2018 3 min read -- 1 Listen Share\\n\\nAs individuals, we should accept that routine jobs are going away. For young people in these routine jobs, start now by finding careers that fit your strengths and that are not easily replaced by AI. For older people, when early retirement is offered to you, consider accepting, with gig economy and volunteering to make some income and live a life you enjoy.\\n\\nWe should encourage more people to go into service careers, choosing jobs into which they can pour their hearts and souls, spreading their love and experiences.\\n\\nWe should embrace AI tools, especially for professionals, understanding that they will get better with more data and use. We should use these tools to do parts of our jobs, allowing them to do more of our routine tasks, freeing us to move into areas that are more suitable for humans.\\n\\nWe should encourage all kinds of creativity beyond the sciences: painting, architecture, music, poetry, acting, storytelling, PR, and marketing.\\n\\nLarge companies should establish and fund serious corporate social responsibility efforts and take steps to help society transition into the age of automation and the future of work.\\n\\nCorporations with a large workforce facing displacement should introduce employee training programs. These involve training employees for emotional quotient and soft skills, reimbursement for online training, and developing a culture of lifelong learning.\\n\\nService industries should develop clear career ladders for service professionals and share best practices and role models so that we attract more people to this large and more sustainable industry.\\n\\nInvestment companies should look at impact investment, not just investing in stocks or tech start-ups, but investing in companies with social impact. These companies, typically service companies, can have decent but not exponential growth and can provide lasting employment to large numbers of people. Such investments may not yield the highest returns but should be done as pro bono.\\n\\nEducational institutions should rethink their roles. Rote learning will only lead to graduates who are easily replaced by AI. Schools need to teach about emotional quotient including communication, teamwork, winning trust, and empathy. Students should be encouraged to pursue their passion, and teaching should become more personalized.\\n\\nSchools should embrace STEM education and find prodigies who will become the inventors of the next breakthroughs in AI, neurobiology, genomics, materials, energy, or basic sciences.\\n\\nWe as a society need to start shifting our culture and values. We have been conditioned to believe that our primary role in society (and even our identity) is found in wage-earning work.', metadata={'source': 'https://kaifulee.medium.com/how-to-prepare-for-ai-job-displacement-78d850e5c1ce'}),\n",
              " Document(page_content='“GPT-4 is a remarkable leap forward in natural language-based models, significantly expanding its potential use cases and building on the achievements of its previous iterations,” said Ferran, pointing to its expanded capability to write code in any language, he said.\\n\\nWilliams agreed, saying that AI is like any powerful tool: Organizations must do their own due diligence.\\n\\n“Are there risks that people can use it for nefarious purposes? Of course, but the benefits far outweigh the risks,” he said.', metadata={'source': 'https://venturebeat.com/security/security-risks-evolve-with-release-of-gpt-4/'}),\n",
              " Document(page_content='Across the globe, organizations are waking up to the power of artificial intelligence (AI). Even before ChatGPT, the technology was starting to move from being an early adopter buzzword to something capable of affecting business transformation for the corporate masses. The market for AI software, hardware and services is expected to hit yet another milestone – $500bn in value – by 2024, thanks to impressive double-digit growth. Yet however they’re deployed to drive business success, AI services are only as strong as the data that powers them.\\n\\nThat means organizations wanting to extract maximum value from AI must also build security into projects from the start to help mitigate AI security risks and threats. A best practice layered approach must begin with securing the data itself - data-centric AI security\\n\\nThe power of AI\\n\\nWe should all be aware by now of the value AI tools can provide to organizations – in both a customer-facing and back office context. One obvious advantage of chatbots like ChatGPT is in enhancing customer service with a realistic human-like interface to field queries and complaints. In doing so, it will free up staff to focus on higher-value tasks. AI-based automation could also reduce the manual, repetitive tasks some team members still have to undertake in industries like banking and retail – such as on- and offboarding customers and approving mortgages. This would also minimize human error and improve overall efficiency.\\n\\nA third output from AI tools – and perhaps the one business leaders are most excited about – revolves around decision-making. By applying the right algorithms to large datasets, companies can generate insight with which to make more successful decisions. For example, they can forecast multiple market scenarios to help predict stock levels, customer sentiment and pricing sensitivity – and adjust strategy accordingly. This will be an increasingly critical driver of agility – especially in times of tremendous business uncertainty and macro-economic volatility.\\n\\nRisk is everywhere: data security risks facing AI & machine learning applications\\n\\nYet where there is data, there are inevitably risks over how it is used and who has access to it. Top AI data security risks include:\\n\\nModel poisoning Model poisoning is a type of attack where threat actors deliberately inject malicious data into an AI or machine learning (ML) model, with the goal of compromising its performance. In most cases, the malicious data will either be significantly different from the distribution of the AI/ML’s training data or heavily biased leading the AI/ML system to misclassify the data and make unreliable decisions.\\n\\n\\n\\nData manipulation/tampering Data manipulation or tampering could occur before data is even fed into algorithms. It is a tactic used by threat actors to deceive an AI/machine learning model, sabotage results or influence other outcomes that the threat actor wants.', metadata={'source': 'https://insights.comforte.com/ai-means-business-so-start-with-data-centric-security'})]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "best_k_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hVQWtS_gzRg",
        "outputId": "878e954d-a1b7-4acf-a497-13efd09b5aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text to Change:  Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n",
            "Expanded Variation: Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal even showcased the potential of AI technology by playing an audio introduction using an AI voice cloning software trained on his speeches. However, as pointed out by Kai-Fu Lee, individuals and organizations must be prepared for AI job displacement and actively seek out careers that cannot easily be replaced by AI. This can include service careers that require emotional intelligence and creativity beyond the sciences. Investment companies can also look into impact investment in service companies that provide lasting employment to large numbers of people, even if they may not yield the highest returns. Additionally, organizations using AI must ensure the security of the data that powers them, including guarding against risks such as model poisoning and data manipulation/tampering. Despite these potential risks, OpenAI CEO Greg Brockman emphasized the need for AI regulation and safety measures to mitigate any negative impacts.\n"
          ]
        }
      ],
      "source": [
        "template = \"\"\"You are an exceptional copywriter and content creator.\n",
        "\n",
        "You're reading an article with the following title:\n",
        "----------------\n",
        "{title}\n",
        "----------------\n",
        "\n",
        "You've just read the following piece of text from that article.\n",
        "----------------\n",
        "{text_all}\n",
        "----------------\n",
        "\n",
        "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
        "----------------\n",
        "{text_to_change}\n",
        "----------------\n",
        "\n",
        "Searching around the web, you've found this ADDITIONAL INFORMATION from distinct articles.\n",
        "----------------\n",
        "{doc_1}\n",
        "----------------\n",
        "{doc_2}\n",
        "----------------\n",
        "{doc_3}\n",
        "----------------\n",
        "\n",
        "Modify the previous TEXT TO CONSIDER by enriching it with information from the previous ADDITIONAL INFORMATION.\n",
        "\"\"\"\n",
        "\n",
        "human_message_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        template=template,\n",
        "        input_variables=[\"text_to_change\", \"text_all\", \"title\", \"doc_1\", \"doc_2\", \"doc_3\"],\n",
        "    )\n",
        ")\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
        "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
        "\n",
        "response = chain.run({\n",
        "    \"text_to_change\": text_to_change,\n",
        "    \"text_all\": text_all,\n",
        "    \"title\": title,\n",
        "    \"doc_1\": best_k_documents[0].page_content,\n",
        "    \"doc_2\": best_k_documents[1].page_content,\n",
        "    \"doc_3\": best_k_documents[2].page_content\n",
        "})\n",
        "\n",
        "print(\"Text to Change: \", text_to_change)\n",
        "print(\"Expanded Variation:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCIbgKPxgzRh",
        "outputId": "15a8f887-7165-463a-efae-8a456a331306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n"
          ]
        }
      ],
      "source": [
        "print(text_to_change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IphEI-ChgzRh",
        "outputId": "7f9b9937-8a87-4e95-bcf7-29fb5011ac63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications\n",
            "for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating\n",
            "the potential of the technology.\n",
            "\n",
            "Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications\n",
            "for elections, jobs, and security. Blumenthal even showcased the potential of AI technology by playing an audio introduction using an AI voice cloning\n",
            "software trained on his speeches. However, as pointed out by Kai-Fu Lee, individuals and organizations must be prepared for AI job displacement and\n",
            "actively seek out careers that cannot easily be replaced by AI. This can include service careers that require emotional intelligence and creativity\n",
            "beyond the sciences. Investment companies can also look into impact investment in service companies that provide lasting employment to large numbers\n",
            "of people, even if they may not yield the highest returns. Additionally, organizations using AI must ensure the security of the data that powers them,\n",
            "including guarding against risks such as model poisoning and data manipulation/tampering. Despite these potential risks, OpenAI CEO Greg Brockman\n",
            "emphasized the need for AI regulation and safety measures to mitigate any negative impacts.\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "\n",
        "print(textwrap.fill(text_to_change, width=150))\n",
        "print()\n",
        "print(textwrap.fill(response, width=150))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1O2bdf5gzRi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myvenv",
      "language": "python",
      "name": "myvenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}