{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the breakthroughs of neural networks in Natural Language Processing is the usage of word embeddings. Rather than using the words themselves as features, neural network methods typically take as input dense, relatively low-dimensional vectors that model the meaning and usage of a word. Word embeddings were first popularized through the [Word2Vec](https://arxiv.org/abs/1301.3781) model, developed by Thomas Mikolov and colleagues at Google. Since then, scores of alternative approaches have been developed, such as [GloVe](https://nlp.stanford.edu/projects/glove/) and [FastText](https://fasttext.cc/) embeddings. In this notebook, we'll explore word embeddings with the original Word2Vec approach, as implemented in the [Gensim](https://radimrehurek.com/gensim/) library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training word embeddings with Gensim couldn't be easier. The only thing we need is a corpus of sentences in the language under investigation. Wikipedia is a good choice for training generic embeddings. For our experiments, we're going to use 5,000,000 sentences from Dutch Wikipedia, which we've trained and lowercased in advance. This means we can feed lists of sentence tokens to Word2Vec by reading the lines in our Wikipedia file and splitting them on spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class SentenceCorpus(object):\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def __iter__(self):\n",
    "        with open(self.filename, \"r\") as i:\n",
    "            for line in i:\n",
    "                tokens = line.strip().split()\n",
    "                yield tokens\n",
    "                \n",
    "                \n",
    "WIKI_FILE = os.path.join(os.path.expanduser(\"~\"), \"Corpora/NL/Wikipedia\", \"nlwiki_20170620_tok_small.txt\")\n",
    "sentences = SentenceCorpus(WIKI_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we train our word embeddings, gensim allows us to set a number of parameters. The most important of these are `min_count`, `window`, `size` and `sg`:\n",
    "\n",
    "- `min_count` is the minimum frequency of the words in our corpus. For infrequent words, we just don't have enough information to train reliable word embeddings. It therefore makes sense to set this minimum frequency to at least 10. In these experiments, we'll set it to 100 to limit the size of our model even more.\n",
    "- `window` is number of words to the left and to the right that make up the context that word2vec will take into account.\n",
    "- `size` is the dimensionality of the word vectors. This is generally between 100 and 1000. You often have to make a trade-off: embeddings with a higher dimensionality are able to model more information, but also need more data to train.\n",
    "- `sg`: there are two algorithms to train word2vec: skip-gram and CBOW. Skip-gram tries to predict the context on the basis of the target word; CBOW tries to find the target on the basis of the context. By default, Gensim uses CBOW (`sg=0`).\n",
    "\n",
    "We'll investigate the impact of some of these parameters later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences, min_count=100, window=5, size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the model. The word embeddings are on its `wv` attribute, and we can access them by the using the token as key. For example, here is the embedding for Dutch *koning* (king), with the requested 100 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.7436782 , -2.5546741 , -2.4181092 ,  0.53079987, -0.6392997 ,\n",
       "        2.7601945 , -2.836296  ,  1.1442246 ,  2.261504  , -1.8250332 ,\n",
       "        1.8353037 ,  0.8417728 , -4.150364  ,  0.389364  , -3.0675495 ,\n",
       "        1.7651662 ,  1.3213423 , -1.8265532 , -1.5197517 , -0.55600065,\n",
       "        1.3073932 ,  0.15334386,  0.02926308, -0.14631374,  2.5769231 ,\n",
       "       -0.53777665, -1.6289988 , -1.441241  , -0.93412006,  0.44386926,\n",
       "       -3.227865  ,  0.16452734,  2.0498326 ,  1.1050102 , -3.7508855 ,\n",
       "       -0.71464   , -1.6540393 ,  1.1486468 ,  0.602774  , -1.5581201 ,\n",
       "       -0.6466161 ,  4.055801  ,  1.3687848 , -1.9568108 ,  1.2429739 ,\n",
       "       -1.4464447 ,  4.8698716 , -0.35930628, -0.18051736, -4.080876  ,\n",
       "       -1.8546008 , -0.63234687,  4.99867   , -1.4174942 , -1.1202643 ,\n",
       "       -0.47730613,  1.6716621 , -1.9697584 ,  0.81117696,  3.4258103 ,\n",
       "        1.1309042 ,  1.2451673 , -1.2035362 , -1.78328   ,  2.8833058 ,\n",
       "        2.025087  , -2.2452092 ,  0.4089499 ,  1.9777402 ,  0.44628003,\n",
       "       -0.8269358 ,  0.82931596,  2.00037   ,  3.2863615 ,  2.591826  ,\n",
       "        1.5034645 , -0.7193872 ,  2.602686  , -0.81810385,  2.491064  ,\n",
       "        0.29169732, -0.8717945 ,  2.0420494 ,  2.4769654 ,  0.01286373,\n",
       "        0.54074115, -0.6844914 ,  0.991695  , -1.4319983 ,  0.9153959 ,\n",
       "        0.7817343 ,  0.12193728,  0.5783813 ,  1.7583479 ,  1.5870973 ,\n",
       "       -0.5969859 , -1.5437273 ,  1.0563058 , -1.6641833 ,  0.13443224],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"koning\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily find the similarity between two words. Similarity is measured as the cosine between the two word embeddings, and ranges between -1 and +1. The higher the cosine, the more similar two words are. As expected, the figures below show that *koning* (king) is closer to *koningin* (queen) than to *koffie* (coffee)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73005563\n",
      "0.0014626831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yvespeirsman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/yvespeirsman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(model.similarity(\"koning\", \"koningin\"))\n",
    "print(model.similarity(\"koning\", \"koffie\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar vein, we can find the words that are most similar to a target word. The words with the most similar embedding to *koning* are all similar titles (such as *keizer* (emperor) and *hertog* (duke)) or are semantically related to royalty (such as *troon* (throne))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yvespeirsman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('keizer', 0.8240664601325989),\n",
       " ('kroonprins', 0.8125288486480713),\n",
       " ('vorst', 0.7871984243392944),\n",
       " ('troonpretendent', 0.7620712518692017),\n",
       " ('stadhouder', 0.7611129879951477),\n",
       " ('troonopvolger', 0.7572510242462158),\n",
       " ('hofmeier', 0.755607545375824),\n",
       " ('hertog', 0.7424051761627197),\n",
       " ('vorstin', 0.7386618852615356),\n",
       " ('prins', 0.7371718883514404)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_word(\"koning\", topn=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we can look for words that are similar to a set of words and dissimilar to another set of words at the same time. This allows us to look for analogies of the type *king (koning) is to man (man) like ... is to woman (vrouw)*. Although the most similar word is not the correct answer (which would be queen), notice how female titles, such as *echtgenote* (wife), *keizerin* (empress) and *koningin* (queen) are now present in the top 10 most similar words. This wasn't the case above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yvespeirsman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('kroonprins', 0.7548491358757019),\n",
       " ('troonopvolger', 0.701501727104187),\n",
       " ('echtgenote', 0.7009282112121582),\n",
       " ('keizerin', 0.7000778317451477),\n",
       " ('gemalin', 0.6954908967018127),\n",
       " ('koningin', 0.6939809322357178),\n",
       " ('groothertog', 0.6857107877731323),\n",
       " ('troonpretendent', 0.674928605556488),\n",
       " ('onderkoning', 0.6680958271026611),\n",
       " ('isabella', 0.6667591333389282)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['vrouw', 'koning'], negative=[\"man\"], topn=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can also zoom in on one of the meanings of ambiguous words. For example, like in English, *muis* (mouse) in Dutch can refer to two things: an animal and a computer mouse. If we look at the 10 nearest neighbours to *muis*, most of them are animals: *papegaai* (parrot), *kat* (cat), *ezel* (donkey), etc. This suggests the animal meaning is much more frequent on Wikipedia than the other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yvespeirsman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('papegaai', 0.745761513710022),\n",
       " ('kat', 0.7276036739349365),\n",
       " ('ezel', 0.7258143424987793),\n",
       " ('slang', 0.7252289056777954),\n",
       " ('geit', 0.721189022064209),\n",
       " ('hond', 0.7077101469039917),\n",
       " ('aap', 0.7041506767272949),\n",
       " ('schotel', 0.7023760080337524),\n",
       " ('verrekijker', 0.6976540088653564),\n",
       " ('zeester', 0.6953004598617554)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"muis\"], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we specify we're looking for words that are similar to *muis* (mouse), but dissimilar to *dier* (animal), suddenly the computer meaning takes over. We now find similar devices in the top ten nearest neighbours: *afstandsbediening* (remote control), *controller*, *switch* and *stick*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yvespeirsman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('afstandsbediening', 0.5098882913589478),\n",
       " ('bel', 0.45299047231674194),\n",
       " ('dealer', 0.4435589015483856),\n",
       " ('controller', 0.44276514649391174),\n",
       " ('belt', 0.44036799669265747),\n",
       " ('switch', 0.43773093819618225),\n",
       " ('stick', 0.43422454595565796),\n",
       " ('driver', 0.42898130416870117),\n",
       " ('thin', 0.4241107106208801),\n",
       " ('r8', 0.4202088713645935)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"muis\"], negative=[\"dier\"], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can present the word2vec model with a list of words and ask it to identify the odd one out. It then uses the word embeddings to identify the word that is least similar to the other ones. For example, in the list *auto fiets bus koffie* (car, bike, bus, coffee), it correctly identifies *koffie* as the odd one out. In the list *koffie auto thee melk* (coffee, car, tea, milk), it correctly singles out *auto*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "koffie\n",
      "auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yvespeirsman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/yvespeirsman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match(\"auto fiets bus koffie\".split()))\n",
    "print(model.doesnt_match(\"koffie auto thee melk\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.nl import pluralize, parse\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fe40422de84873ba2d0de6ad9299db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11522), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[('architect', 'architecten'), ('minister', 'ministers'), ('hitler', 'hitlers'), ('gold', 'golden'), ('rijk', 'rijken'), ('jaar', 'jaren'), ('gezin', 'gezinnen'), ('vader', 'vaders'), ('zomer', 'zomers'), ('studie', 'studies'), ('hogeschool', 'hogescholen'), ('school', 'scholen'), ('stijl', 'stijlen'), ('behaald', 'behaalden'), ('toespraak', 'toespraken'), ('maand', 'maanden'), ('woord', 'woorden'), ('partij', 'partijen'), ('vorm', 'vormen'), ('idee', 'ideeën'), ('veld', 'velden'), ('recht', 'rechten'), ('licht', 'lichten'), ('afdeling', 'afdelingen'), ('aanleg', 'aanleggen'), ('hand', 'handen'), ('plek', 'plekken'), ('kroon', 'kronen'), ('traditie', 'tradities'), ('stad', 'steden'), ('volk', 'volken'), ('bouw', 'bouwen'), ('vergroot', 'vergroten'), ('bron', 'bronnen'), ('grond', 'gronden'), ('prijs', 'prijzen'), ('rand', 'randen'), ('cilinder', 'cilinders'), ('begin', 'beginnen'), ('bouwwerk', 'bouwwerken'), ('plaats', 'plaatsen'), ('m', 'men'), ('maal', 'malen'), ('meter', 'meters'), ('straat', 'straten'), ('gereed', 'gereden'), ('vliegveld', 'vliegvelden'), ('aantal', 'aantallen'), ('opdracht', 'opdrachten'), ('locatie', 'locaties'), ('gebied', 'gebieden'), ('dierentuin', 'dierentuinen'), ('concentratiekamp', 'concentratiekampen'), ('ontwerp', 'ontwerpen'), ('beeld', 'beelden'), ('oog', 'ogen'), ('opvolger', 'opvolgers'), ('productie', 'producties'), ('geval', 'gevallen'), ('missie', 'missies'), ('soort', 'soorten'), ('uitvoering', 'uitvoeringen'), ('voorbeeld', 'voorbeelden'), ('verovering', 'veroveringen'), ('proces', 'processen'), ('feit', 'feiten'), ('werk', 'werken'), ('schuld', 'schulden'), ('mogelijkheid', 'mogelijkheden'), ('steun', 'steunen'), ('streep', 'strepen'), ('naam', 'namen'), ('tijd', 'tijden'), ('verkoop', 'verkopen'), ('dood', 'doden'), ('leven', 'levens'), ('hoeveelheid', 'hoeveelheden'), ('titel', 'titels'), ('rol', 'rollen'), ('boek', 'boeken'), ('bezoek', 'bezoeken'), ('onderzoek', 'onderzoeken'), ('document', 'documenten'), ('materiaal', 'materialen'), ('val', 'vallen'), ('collectie', 'collecties'), ('bezit', 'bezitten'), ('opbrengst', 'opbrengsten'), ('mark', 'marken'), ('stuk', 'stukken'), ('oever', 'oevers'), ('man', 'mannen'), ('medewerker', 'medewerkers'), ('verraad', 'verraden'), ('gebouw', 'gebouwen'), ('eeuw', 'eeuwen'), ('deel', 'deels'), ('karakter', 'karakters'), ('stand', 'standen'), ('herinnering', 'herinneringen'), ('terrein', 'terreinen'), ('zoon', 'zonen'), ('speler', 'spelers'), ('sport', 'sporten'), ('lijst', 'lijsten'), ('graf', 'graven'), ('genoot', 'genoten'), ('opleiding', 'opleidingen'), ('bijnaam', 'bijnamen'), ('organisatie', 'organisaties'), ('gras', 'grassen'), ('wedstrijd', 'wedstrijden'), ('vrouw', 'vrouwen'), ('overwinning', 'overwinningen'), ('amerikaan', 'amerikanen'), ('ontwikkeling', 'ontwikkelingen'), ('kwaliteit', 'kwaliteiten'), ('draad', 'draden'), ('periode', 'periodes'), ('rust', 'rusten'), ('kamp', 'kampen'), ('project', 'projecten'), ('vernieuwing', 'vernieuwingen'), ('campagne', 'campagnes'), ('inzet', 'inzetten'), ('bal', 'ballen'), ('nederlaag', 'nederlagen'), ('versterking', 'versterkingen'), ('verkiezing', 'verkiezingen'), ('kamer', 'kamers'), ('fractie', 'fracties'), ('vertegenwoordiger', 'vertegenwoordigers'), ('akkoord', 'akkoorden'), ('niveau', 'niveaus'), ('bestuur', 'besturen'), ('eed', 'eden'), ('kiezer', 'kiezers'), ('familie', 'families'), ('zus', 'zussen'), ('band', 'banden'), ('uitvinding', 'uitvindingen'), ('spin', 'spinnen'), ('markt', 'markten'), ('vertrok', 'vertrokken'), ('buurt', 'buurten'), ('bedrijf', 'bedrijven'), ('vliegtuig', 'vliegtuigen'), ('techniek', 'technieken'), ('dag', 'dagen'), ('leger', 'legers'), ('nederland', 'nederlanden'), ('ruimte', 'ruimtes'), ('fabriek', 'fabrieken'), ('positie', 'posities'), ('loop', 'lopen'), ('vereniging', 'verenigingen'), ('huwelijk', 'huwelijken'), ('raam', 'ramen'), ('gevolg', 'gevolgen'), ('operatie', 'operaties'), ('as', 'assen'), ('dochter', 'dochters'), ('tentoonstelling', 'tentoonstellingen'), ('gelegenheid', 'gelegenheden'), ('evenement', 'evenementen'), ('gebruik', 'gebruiken'), ('maatschappij', 'maatschappijen'), ('vak', 'vakken'), ('piloot', 'piloten'), ('kind', 'kinderen'), ('broer', 'broers'), ('wetenschap', 'wetenschappen'), ('invloed', 'invloeden'), ('koninkrijk', 'koninkrijken'), ('geest', 'geesten'), ('vraag', 'vragen'), ('universiteit', 'universiteiten'), ('antwoord', 'antwoorden'), ('conclusie', 'conclusies'), ('machine', 'machines'), ('code', 'codes'), ('park', 'parken'), ('dienst', 'diensten'), ('vijand', 'vijanden'), ('stap', 'stappen'), ('tijdschrift', 'tijdschriften'), ('orde', 'ordes'), ('onderscheiding', 'onderscheidingen'), ('groot', 'groten'), ('ongeluk', 'ongelukken'), ('schrijver', 'schrijvers'), ('moeder', 'moeders'), ('regering', 'regeringen'), ('vriend', 'vrienden'), ('berekening', 'berekeningen'), ('computer', 'computers'), ('toneelstuk', 'toneelstukken'), ('versie', 'versies'), ('hoofdrol', 'hoofdrollen'), ('willem', 'willems'), ('figuur', 'figuren'), ('game', 'games'), ('resultaat', 'resultaten'), ('taak', 'taken'), ('verschil', 'verschillen'), ('inspanning', 'inspanningen'), ('instructie', 'instructies'), ('functie', 'functies'), ('toestand', 'toestanden'), ('apparaat', 'apparaten'), ('beschrijving', 'beschrijvingen'), ('oplossing', 'oplossingen'), ('programmeertaal', 'programmeertalen'), ('type', 'types'), ('b', 'ben'), ('definitie', 'definities'), ('demonstratie', 'demonstraties'), ('methode', 'methodes'), ('uitspraak', 'uitspraken'), ('stelling', 'stellingen'), ('praktijk', 'praktijken'), ('belang', 'belangen'), ('stam', 'stammen'), ('golf', 'golven'), ('boog', 'bogen'), ('top', 'toppen'), ('jong', 'jongen'), ('oceaan', 'oceanen'), ('betrekking', 'betrekkingen'), ('punt', 'punten'), ('berg', 'bergen'), ('grens', 'grenzen'), ('lijn', 'lijnen'), ('noord', 'noorden'), ('zuid', 'zuiden'), ('meting', 'metingen'), ('hoogtepunt', 'hoogtepunten'), ('reis', 'reizen'), ('verandering', 'veranderingen'), ('opbouw', 'opbouwen'), ('dal', 'dalen'), ('helling', 'hellingen'), ('richting', 'richtingen'), ('beweging', 'bewegingen'), ('druk', 'drukken'), ('temperatuur', 'temperaturen'), ('laag', 'lagen'), ('west', 'westen'), ('oost', 'oosten'), ('droog', 'drogen'), ('afstand', 'afstanden'), ('winter', 'winters'), ('snelheid', 'snelheden'), ('gang', 'gangen'), ('uur', 'uren'), ('aspect', 'aspecten'), ('muur', 'muren'), ('beïnvloed', 'beïnvloeden'), ('duur', 'duren'), ('bodem', 'bodems'), ('kleur', 'kleuren'), ('effect', 'effecten'), ('eiland', 'eilanden'), ('mens', 'mensen'), ('hout', 'houten'), ('kracht', 'krachten'), ('wijn', 'wijnen'), ('betekenis', 'betekenissen'), ('goud', 'gouden'), ('verklaring', 'verklaringen'), ('kerk', 'kerken'), ('dorp', 'dorpen'), ('trek', 'trekken'), ('buurland', 'buurlanden'), ('dorpje', 'dorpjes'), ('verlaat', 'verlaten'), ('sector', 'sectoren'), ('land', 'landen'), ('orkest', 'orkesten'), ('gebeurtenis', 'gebeurtenissen'), ('week', 'weken'), ('hoofd', 'hoofden'), ('commissie', 'commissies'), ('provincie', 'provincies'), ('gemeente', 'gemeentes'), ('haven', 'havens'), ('zetel', 'zetels'), ('bisdom', 'bisdommen'), ('nederzetting', 'nederzettingen'), ('schipper', 'schippers'), ('vondst', 'vondsten'), ('verwijzing', 'verwijzingen'), ('vorst', 'vorsten'), ('keizer', 'keizers'), ('karel', 'karels'), ('vlucht', 'vluchten'), ('aanhanger', 'aanhangers'), ('opstand', 'opstanden'), ('ontwikkeld', 'ontwikkelden'), ('district', 'districten'), ('belg', 'belgen'), ('groep', 'groepen'), ('taal', 'talen'), ('dialect', 'dialecten'), ('cultuur', 'culturen'), ('eilandje', 'eilandjes'), ('nummer', 'nummers'), ('will', 'willen'), ('antwerp', 'antwerpen'), ('lied', 'liederen'), ('bell', 'bellen'), ('ed', 'eden'), ('oproep', 'oproepen'), ('staal', 'stalen'), ('netwerk', 'netwerken'), ('ring', 'ringen'), ('brussel', 'brussels'), ('kust', 'kusten'), ('verbetering', 'verbeteringen'), ('tunnel', 'tunnels'), ('buslijn', 'buslijnen'), ('bus', 'bussen'), ('gebruiker', 'gebruikers'), ('luchthaven', 'luchthavens'), ('gemeenschap', 'gemeenschappen'), ('centrum', 'centra'), ('tiental', 'tientallen'), ('overheid', 'overheden'), ('parochie', 'parochies'), ('tempel', 'tempels'), ('verbond', 'verbonden'), ('uitzondering', 'uitzonderingen'), ('burgemeester', 'burgemeesters'), ('college', 'colleges'), ('faculteit', 'faculteiten'), ('ploeg', 'ploegen'), ('huis', 'huizen'), ('kampioenschap', 'kampioenschappen'), ('samenstelling', 'samenstellingen'), ('wet', 'wetten'), ('tak', 'takken'), ('komeet', 'kometen'), ('begrip', 'begrippen'), ('structuur', 'structuren'), ('maan', 'manen'), ('verband', 'verbanden'), ('inzicht', 'inzichten'), ('oorzaak', 'oorzaken'), ('variëteit', 'variëteiten'), ('baan', 'banen'), ('paar', 'paren'), ('concentratie', 'concentraties'), ('vakgebied', 'vakgebieden'), ('planeet', 'planeten'), ('middel', 'middels'), ('analyse', 'analyses'), ('instrument', 'instrumenten'), ('eenheid', 'eenheden'), ('g', 'gen'), ('h', 'hen'), ('p', 'pen'), ('t', 'ten'), ('continent', 'continenten'), ('post', 'posten'), ('vlag', 'vlaggen'), ('monument', 'monumenten'), ('stroom', 'stromen'), ('kaart', 'kaarten'), ('lading', 'ladingen'), ('koning', 'koningen'), ('ontdekking', 'ontdekkingen'), ('dam', 'dammen'), ('fiets', 'fietsen'), ('citaat', 'citaten'), ('personage', 'personages'), ('verhaal', 'verhalen'), ('ervaring', 'ervaringen'), ('politicus', 'politici'), ('raad', 'raden'), ('state', 'states'), ('voorstander', 'voorstanders'), ('opzet', 'opzetten'), ('tegenstander', 'tegenstanders'), ('moord', 'moorden'), ('vertrek', 'vertrekken'), ('race', 'races'), ('kwestie', 'kwesties'), ('president', 'presidenten'), ('kritiek', 'kritieken'), ('persoon', 'personen'), ('leider', 'leiders'), ('geld', 'gelden'), ('reactie', 'reacties'), ('zaak', 'zaken'), ('duitser', 'duitsers'), ('kandidaat', 'kandidaten'), ('onderneming', 'ondernemingen'), ('overeenkomst', 'overeenkomsten'), ('onderhoud', 'onderhouden'), ('benaming', 'benamingen'), ('besluit', 'besluiten'), ('combinatie', 'combinaties'), ('revolutionair', 'revolutionairen'), ('kanaal', 'kanalen'), ('polder', 'polders'), ('brug', 'bruggen'), ('bestemming', 'bestemmingen'), ('verloop', 'verlopen'), ('gehucht', 'gehuchten'), ('verbinding', 'verbindingen'), ('waterschap', 'waterschappen'), ('theater', 'theaters'), ('european', 'europeanen'), ('moment', 'momenten'), ('start', 'starten'), ('opname', 'opnames'), ('principe', 'principes'), ('verhouding', 'verhoudingen'), ('getal', 'getallen'), ('wijziging', 'wijzigingen'), ('factor', 'factoren'), ('tegenstelling', 'tegenstellingen'), ('verdieping', 'verdiepingen'), ('rest', 'resten'), ('hoofdstuk', 'hoofdstukken'), ('actie', 'acties'), ('vrijheid', 'vrijheden'), ('mening', 'meningen'), ('binding', 'bindingen'), ('standaard', 'standaarden'), ('situatie', 'situaties'), ('master', 'masters'), ('voorspelling', 'voorspellingen'), ('wetenschapper', 'wetenschappers'), ('stroming', 'stromingen'), ('arts', 'artsen'), ('leerling', 'leerlingen'), ('meester', 'meesters'), ('trouw', 'trouwen'), ('publicatie', 'publicaties'), ('toepassing', 'toepassingen'), ('vertaling', 'vertalingen'), ('tekst', 'teksten'), ('lichaam', 'lichamen'), ('term', 'termen'), ('daad', 'daden'), ('vuur', 'vuren'), ('onderwerp', 'onderwerpen'), ('voorstelling', 'voorstellingen'), ('motief', 'motieven'), ('groepering', 'groeperingen'), ('bin', 'binnen'), ('zin', 'zinnen'), ('schatting', 'schattingen'), ('minderheid', 'minderheden'), ('godsdienst', 'godsdiensten'), ('ziekte', 'ziektes'), ('ministerie', 'ministeries'), ('verbrand', 'verbranden'), ('strijd', 'strijden'), ('arm', 'armen'), ('activiteit', 'activiteiten'), ('verzet', 'verzetten'), ('plan', 'plannen'), ('spoorlijn', 'spoorlijnen'), ('natie', 'naties'), ('religie', 'religies'), ('eigenschap', 'eigenschappen'), ('standpunt', 'standpunten'), ('profeet', 'profeten'), ('attractie', 'attracties'), ('beschaving', 'beschavingen'), ('krant', 'kranten'), ('pers', 'perzen'), ('doek', 'doeken'), ('schaal', 'schalen'), ('kunst', 'kunsten'), ('kant', 'kanten'), ('beroep', 'beroepen'), ('tekening', 'tekeningen'), ('register', 'registers'), ('woning', 'woningen'), ('indeling', 'indelingen'), ('constructie', 'constructies'), ('contact', 'contacten'), ('zorg', 'zorgen'), ('behoud', 'behouden'), ('discipline', 'disciplines'), ('voorloper', 'voorlopers'), ('jager', 'jagers'), ('onderzoeker', 'onderzoekers'), ('plicht', 'plichten'), ('eigenaar', 'eigenaren'), ('bevoegdheid', 'bevoegdheden'), ('metaal', 'metalen'), ('klok', 'klokken'), ('hoek', 'hoeken'), ('satelliet', 'satellieten'), ('waarnemer', 'waarnemers'), ('pool', 'polen'), ('kilometer', 'kilometers'), ('bol', 'bollen'), ('vermoed', 'vermoeden'), ('grootheid', 'grootheden'), ('kern', 'kernen'), ('plaat', 'platen'), ('zuur', 'zuren'), ('zout', 'zouten'), ('el', 'els'), ('gas', 'gassen'), ('stukje', 'stukjes'), ('wolk', 'wolken'), ('vergelijking', 'vergelijkingen'), ('woestijn', 'woestijnen'), ('verspreid', 'verspreiden'), ('wild', 'wilden'), ('conflict', 'conflicten'), ('schijf', 'schijven'), ('voorouder', 'voorouders'), ('weefsel', 'weefsels'), ('spraak', 'spraken'), ('symbool', 'symbolen'), ('interpretatie', 'interpretaties'), ('verzameling', 'verzamelingen'), ('klinker', 'klinkers'), ('letter', 'letters'), ('discussie', 'discussies'), ('bibliotheek', 'bibliotheken'), ('vis', 'vissen'), ('illustratie', 'illustraties'), ('klank', 'klanken'), ('spreker', 'sprekers'), ('heerser', 'heersers'), ('afstammeling', 'afstammelingen'), ('bisschop', 'bisschoppen'), ('graafschap', 'graafschappen'), ('frank', 'franken'), ('gevaar', 'gevaren'), ('orgaan', 'organen'), ('les', 'lessen'), ('voorganger', 'voorgangers'), ('katholiek', 'katholieken'), ('munt', 'munten'), ('konijn', 'konijnen'), ('zender', 'zenders'), ('omroep', 'omroepen'), ('nederlander', 'nederlanders'), ('kolonie', 'kolonies'), ('aardbeving', 'aardbevingen'), ('tracht', 'trachten'), ('oprichter', 'oprichters'), ('genre', 'genres'), ('serie', 'series'), ('gitaar', 'gitaren'), ('geluid', 'geluiden'), ('generatie', 'generaties'), ('succes', 'successen'), ('zanger', 'zangers'), ('boom', 'bomen'), ('verblijf', 'verblijven'), ('landschap', 'landschappen'), ('uitgever', 'uitgevers'), ('product', 'producten'), ('gerecht', 'gerechten'), ('zink', 'zinken'), ('werkgever', 'werkgevers'), ('producent', 'producenten'), ('patroon', 'patronen'), ('plant', 'planten'), ('ras', 'rassen'), ('bereid', 'bereiden'), ('tuin', 'tuinen'), ('zaad', 'zaden'), ('consument', 'consumenten'), ('vermogen', 'vermogens'), ('feest', 'feesten'), ('borst', 'borsten'), ('heuvel', 'heuvels'), ('rechtbank', 'rechtbanken'), ('gewond', 'gewonden'), ('klacht', 'klachten'), ('held', 'helden'), ('vat', 'vaten'), ('zuster', 'zusters'), ('wagen', 'wagens'), ('paard', 'paarden'), ('brand', 'branden'), ('soldaat', 'soldaten'), ('prestatie', 'prestaties'), ('kring', 'kringen'), ('verkreeg', 'verkregen'), ('bewijs', 'bewijzen'), ('historicus', 'historici'), ('deur', 'deuren'), ('editie', 'edities'), ('kardinaal', 'kardinalen'), ('paus', 'pausen'), ('exemplaar', 'exemplaren'), ('portret', 'portretten'), ('inscriptie', 'inscripties'), ('element', 'elementen'), ('verval', 'vervallen'), ('advocaat', 'advocaten'), ('grondlegger', 'grondleggers'), ('test', 'testen'), ('voorwerp', 'voorwerpen'), ('instantie', 'instanties'), ('virus', 'virussen'), ('ramp', 'rampen'), ('behandeling', 'behandelingen'), ('deeltje', 'deeltjes'), ('eiwit', 'eiwitten'), ('ziek', 'zieken'), ('aandoening', 'aandoeningen'), ('infectie', 'infecties'), ('aanwijzing', 'aanwijzingen'), ('voorraad', 'voorraden'), ('proef', 'proeven'), ('partner', 'partners'), ('hof', 'hoven'), ('lezing', 'lezingen'), ('website', 'websites'), ('geslacht', 'geslachten'), ('instituut', 'instituten'), ('behield', 'behielden'), ('fabrikant', 'fabrikanten'), ('klas', 'klassen'), ('leraar', 'leraren'), ('relatie', 'relaties'), ('dimensie', 'dimensies'), ('brief', 'brieven'), ('beslissing', 'beslissingen'), ('burger', 'burgers'), ('slaap', 'slapen'), ('ziekenhuis', 'ziekenhuizen'), ('waard', 'waarden'), ('zwart', 'zwarten'), ('waarneming', 'waarnemingen'), ('molecuul', 'moleculen'), ('george', 'georges'), ('uitbreiding', 'uitbreidingen'), ('bezwaar', 'bezwaren'), ('hemellichaam', 'hemellichamen'), ('bijeenkomst', 'bijeenkomsten'), ('student', 'studenten'), ('ideaal', 'idealen'), ('bericht', 'berichten'), ('gezicht', 'gezichten'), ('inval', 'invallen'), ('militair', 'militairen'), ('voorbereiding', 'voorbereidingen'), ('science', 'sciences'), ('protest', 'protesten'), ('opvatting', 'opvattingen'), ('time', 'times'), ('bedreiging', 'bedreigingen'), ('deelstaat', 'deelstaten'), ('statuut', 'statuten'), ('basisschool', 'basisscholen'), ('verzoek', 'verzoeken'), ('tramlijn', 'tramlijnen'), ('rat', 'ratten'), ('kikker', 'kikkers'), ('slang', 'slangen'), ('kabinet', 'kabinetten'), ('initiatief', 'initiatieven'), ('hervorming', 'hervormingen'), ('priester', 'priesters'), ('et', 'eten'), ('zak', 'zakken'), ('uitdrukking', 'uitdrukkingen'), ('domein', 'domeinen'), ('poging', 'pogingen'), ('opzicht', 'opzichten'), ('compositie', 'composities'), ('wapen', 'wapens'), ('verwant', 'verwanten'), ('winkel', 'winkels'), ('ambt', 'ambten'), ('or', 'oren'), ('insect', 'insecten'), ('haag', 'hagen'), ('stadsmuur', 'stadsmuren'), ('vestiging', 'vestigingen'), ('sluis', 'sluizen'), ('wijk', 'wijken'), ('koop', 'kopen'), ('talent', 'talenten'), ('voet', 'voeten'), ('leeuw', 'leeuwen'), ('suiker', 'suikers'), ('bevrijd', 'bevrijden'), ('route', 'routes'), ('bezoeker', 'bezoekers'), ('been', 'beenderen'), ('wereldkampioenschap', 'wereldkampioenschappen'), ('paleis', 'paleizen'), ('pand', 'panden'), ('divisie', 'divisies'), ('inwoner', 'inwoners'), ('schilder', 'schilders'), ('traject', 'trajecten'), ('variant', 'varianten'), ('kenmerk', 'kenmerken'), ('rang', 'rangen'), ('vocht', 'vochten'), ('verplichting', 'verplichtingen'), ('aanval', 'aanvallen'), ('schoot', 'schoten'), ('journalist', 'journalisten'), ('jood', 'joden'), ('café', 'cafés'), ('slachtoffer', 'slachtoffers'), ('jongen', 'jongens'), ('pad', 'paden'), ('meisje', 'meisjes'), ('kunstschilder', 'kunstschilders'), ('schilderij', 'schilderijen'), ('radicaal', 'radicalen'), ('koe', 'koeien'), ('vergadering', 'vergaderingen'), ('afbeelding', 'afbeeldingen'), ('zaal', 'zalen'), ('staking', 'stakingen'), ('ambtenaar', 'ambtenaren'), ('monster', 'monsters'), ('verwachting', 'verwachtingen'), ('conservatief', 'conservatieven'), ('alternatief', 'alternatieven'), ('autoriteit', 'autoriteiten'), ('signaal', 'signalen'), ('bombardement', 'bombardementen'), ('experiment', 'experimenten'), ('afspraak', 'afspraken'), ('bom', 'bommen'), ('trein', 'treinen'), ('bondgenoot', 'bondgenoten'), ('poot', 'poten'), ('steek', 'steken'), ('kaak', 'kaken'), ('vinger', 'vingers'), ('predikant', 'predikanten'), ('liedje', 'liedjes'), ('televisieserie', 'televisieseries'), ('vogel', 'vogels'), ('ridder', 'ridders'), ('kat', 'katten'), ('componist', 'componisten'), ('aanpassing', 'aanpassingen'), ('agent', 'agenten'), ('concurrent', 'concurrenten'), ('vakbond', 'vakbonden'), ('vleugel', 'vleugels'), ('zuil', 'zuilen'), ('roep', 'roepen'), ('werknemer', 'werknemers'), ('muzikant', 'muzikanten'), ('paal', 'palen'), ('gewest', 'gewesten'), ('plaatje', 'plaatjes'), ('gesprek', 'gesprekken'), ('variatie', 'variaties'), ('regel', 'regels'), ('vrouwtje', 'vrouwtjes'), ('vlek', 'vlekken'), ('blad', 'bladeren'), ('mannetje', 'mannetjes'), ('opening', 'openingen'), ('rij', 'rijen'), ('ei', 'eieren'), ('nest', 'nesten'), ('skelet', 'skeletten'), ('buit', 'buiten'), ('strand', 'stranden'), ('gedicht', 'gedichten'), ('straal', 'stralen'), ('moeras', 'moerassen'), ('bewerking', 'bewerkingen'), ('beek', 'beken'), ('gracht', 'grachten'), ('restant', 'restanten'), ('atoom', 'atomen'), ('isotoop', 'isotopen'), ('patiënt', 'patiënten'), ('ion', 'ionen'), ('kruistocht', 'kruistochten'), ('belasting', 'belastingen'), ('klooster', 'kloosters'), ('archief', 'archieven'), ('blijk', 'blijken'), ('maat', 'maten'), ('object', 'objecten'), ('wortel', 'wortels'), ('investering', 'investeringen'), ('component', 'componenten'), ('blok', 'blokken'), ('hond', 'honden'), ('commissaris', 'commissarissen'), ('instelling', 'instellingen'), ('plaatsnaam', 'plaatsnamen'), ('kunstwerk', 'kunstwerken'), ('boerderij', 'boerderijen'), ('beton', 'betonnen'), ('graad', 'graden'), ('fundament', 'fundamenten'), ('engel', 'engels'), ('doelstelling', 'doelstellingen'), ('voertuig', 'voertuigen'), ('uitzending', 'uitzendingen'), ('rechtszaak', 'rechtszaken'), ('bepaling', 'bepalingen'), ('wethouder', 'wethouders'), ('richtlijn', 'richtlijnen'), ('aansluit', 'aansluiten'), ('verbood', 'verboden'), ('tand', 'tanden'), ('dijk', 'dijken'), ('departement', 'departementen'), ('rit', 'ritten'), ('all', 'allen'), ('blue', 'blues'), ('good', 'goden'), ('hotel', 'hotels'), ('storm', 'stormen'), ('installatie', 'installaties'), ('aanvraag', 'aanvragen'), ('poort', 'poorten'), ('werkwoord', 'werkwoorden'), ('put', 'putten'), ('wand', 'wanden'), ('toon', 'tonen'), ('bereik', 'bereiken'), ('senator', 'senatoren'), ('handeling', 'handelingen'), ('beperking', 'beperkingen'), ('misdrijf', 'misdrijven'), ('concessie', 'concessies'), ('rechter', 'rechters'), ('fout', 'fouten'), ('scherm', 'schermen'), ('cijfer', 'cijfers'), ('afwijking', 'afwijkingen'), ('norm', 'normen'), ('album', 'albums'), ('misdaad', 'misdaden'), ('geschrift', 'geschriften'), ('mineraal', 'mineralen'), ('aanspraak', 'aanspraken'), ('erfgenaam', 'erfgenamen'), ('verwoesting', 'verwoestingen'), ('theoloog', 'theologen'), ('buis', 'buizen'), ('pijl', 'pijlen'), ('lening', 'leningen'), ('spanning', 'spanningen'), ('long', 'longen'), ('doelpunt', 'doelpunten'), ('competitie', 'competities'), ('ondernemer', 'ondernemers'), ('rots', 'rotsen'), ('muis', 'muizen'), ('vulkaan', 'vulkanen'), ('olifant', 'olifanten'), ('natuurgebied', 'natuurgebieden'), ('woonwijk', 'woonwijken'), ('minuut', 'minuten'), ('server', 'servers'), ('lezer', 'lezers'), ('passage', 'passages'), ('motor', 'motoren'), ('optie', 'opties'), ('dame', 'dames'), ('breuk', 'breuken'), ('argument', 'argumenten'), ('bestand', 'bestanden'), ('bank', 'banken'), ('kristal', 'kristallen'), ('liberaal', 'liberalen'), ('bot', 'botten'), ('geschil', 'geschillen'), ('aflevering', 'afleveringen'), ('duin', 'duinen'), ('frequentie', 'frequenties'), ('incident', 'incidenten'), ('vervolg', 'vervolgen'), ('halte', 'haltes'), ('handschrift', 'handschriften'), ('musicus', 'musici'), ('boot', 'boten'), ('visser', 'vissers'), ('artiest', 'artiesten'), ('ondersoort', 'ondersoorten'), ('bevolkingsgroep', 'bevolkingsgroepen'), ('kip', 'kippen'), ('dank', 'danken'), ('scène', 'scènes'), ('stoel', 'stoelen'), ('noot', 'noten'), ('avontuur', 'avonturen'), ('vector', 'vectoren'), ('schildpad', 'schildpadden'), ('genoom', 'genomen'), ('bek', 'bekken'), ('populatie', 'populaties'), ('klant', 'klanten'), ('gevecht', 'gevechten'), ('trap', 'trappen'), ('antenne', 'antennes'), ('naamwoord', 'naamwoorden'), ('gezond', 'gezonden'), ('vers', 'verzen'), ('knoop', 'knopen'), ('huishouden', 'huishoudens'), ('grot', 'grotten'), ('droom', 'dromen'), ('beschuldiging', 'beschuldigingen'), ('helikopter', 'helikopters'), ('vrucht', 'vruchten'), ('pigment', 'pigmenten'), ('chromosoom', 'chromosomen'), ('enzym', 'enzymen'), ('subsidie', 'subsidies'), ('gerucht', 'geruchten'), ('sv', 'sven'), ('kanon', 'kanonnen'), ('tarief', 'tarieven'), ('concert', 'concerten'), ('dwerg', 'dwergen'), ('trilling', 'trillingen'), ('fles', 'flessen'), ('omzet', 'omzetten'), ('buurtschap', 'buurtschappen'), ('streed', 'streden'), ('batterij', 'batterijen'), ('kever', 'kevers'), ('vlinder', 'vlinders'), ('vlam', 'vlammen'), ('sleutel', 'sleutels'), ('snaar', 'snaren'), ('schimmel', 'schimmels'), ('stoornis', 'stoornissen'), ('schaak', 'schaken'), ('locomotief', 'locomotieven'), ('bes', 'bessen'), ('rook', 'roken'), ('grafheuvel', 'grafheuvels'), ('priemgetal', 'priemgetallen'), ('schelp', 'schelpen')]\n"
     ]
    }
   ],
   "source": [
    "test_pairs = []\n",
    "for word in tqdm(model.wv.vocab):\n",
    "    ling = parse(word)\n",
    "    if ling.split(\"/\")[1] == \"NN\":\n",
    "        plural = pluralize(word)\n",
    "        if plural in model.wv.vocab:\n",
    "            test_pairs.append((word, plural))\n",
    "            \n",
    "print(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72028fac87504f7fb0b806748c2cabf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=948), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate(test_pairs, model):\n",
    "    reciprocal_ranks = []\n",
    "    for sing, plur in tqdm(test_pairs):\n",
    "        rank = model.wv.rank(sing, plur)\n",
    "        reciprocal_ranks.append(1/rank)\n",
    "    return np.mean(reciprocal_ranks)\n",
    "        \n",
    "mrp = evaluate(test_pairs, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09843961931034355"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53436e29892425a8f69946cb240e0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=948), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9397119351d4db1a138b91f50a468fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=948), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec52dd63e0684998ac32b949a6df7e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=948), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5a81b39507413a970d1f120bd3111a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=948), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0b74e83057fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mmrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 end_alpha=self.min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    552\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    487\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    488\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sizes = [100, 200, 300]\n",
    "windows = [2,5,10]\n",
    "\n",
    "df = pd.DataFrame(index=windows, columns=sizes)\n",
    "\n",
    "for size in sizes:\n",
    "    for window in windows:\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=100, window=window, size=size)\n",
    "        mrp = evaluate(test_pairs, model)\n",
    "        df[size][window] = mrp\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x1a1bda2438>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "vocab = list(model.wv.vocab)\n",
    "vectors = [model.wv[w] for w in vocab]\n",
    "vectors_norm = normalize(vectors)\n",
    "\n",
    "clusterer = AgglomerativeClustering(n_clusters=500)\n",
    "clusters = clusterer.fit_predict(vectors_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dictionary = {}\n",
    "for cluster, word in zip(clusters, vocab): \n",
    "    if cluster not in cluster_dictionary:\n",
    "        cluster_dictionary[cluster] = []\n",
    "    cluster_dictionary[cluster].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duitsland', 'frankrijk', 'oostenrijk', 'italië', 'zwitserland', 'slovenië', 'liechtenstein', 'monaco', 'joegoslavië', 'spanje', 'polen', 'turkije', 'luxemburg', 'macedonië', 'sovjet-unie', 'andorra', 'vaticaanstad', 'rusland', 'ussr', 'griekenland', 'portugal', 'tsjecho-slowakije', 'tsjechië', 'hongarije', 'tsjechoslowakije', 'roemenië', 'bulgarije', 'denemarken', 'noorwegen', 'zweden', 'finland', 'oekraïne', 'oost-duitsland', 'bondsrepubliek', 'servië', 'west-duitsland', 'armenië', 'bosnië', 'cyprus', 'wit-rusland', 'litouwen', 'letland', 'albanië', 'slowakije', 'ddr', 'georgië', 'malta', 'oost-berlijn', 'west-berlijn', 'estland', 'montenegro', 'kroatië', 'herzegovina', 'azerbeidzjan']\n"
     ]
    }
   ],
   "source": [
    "for x in cluster_dictionary:\n",
    "    if \"italië\" in cluster_dictionary[x]:\n",
    "        print(cluster_dictionary[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/clusters_nl.tsv\", \"w\") as o:\n",
    "    for c in cluster_dictionary:\n",
    "        for w in cluster_dictionary[c]:\n",
    "            o.write(f\"{w}\\t{c}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
