{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFGLog = {\n",
    "    \"data\": {\n",
    "        \"path\": \"../data/yelp.csv\",\n",
    "        \"x\": \"text\",\n",
    "        \"y\": \"stars\",\n",
    "        \"test_size\": 0.2,\n",
    "        \"random_state\": 2022,\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"min_df\": 10\n",
    "\n",
    "    },\n",
    "    \"train\": {\n",
    "            \"solver\": \"liblinear\",\n",
    "            \"max_iter\": 1000,\n",
    "            \"random_state\": 2022,\n",
    "            \"C\": 0.01,\n",
    "            \"penalty\": \"l2\",\n",
    "    },\n",
    "    \"output\": {\n",
    "        \"output_path\": r\"../data/exported_models\",\n",
    "    }\n",
    "}\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Config class which contains data, train and model hyperparameters\"\"\"\n",
    "\n",
    "    def __init__(self, data, train, output):\n",
    "        self.data = data\n",
    "        # self.datapath = os.path.\n",
    "        self.train = train\n",
    "        self.output = output\n",
    "\n",
    "    @classmethod # using config to define constructor of the class\n",
    "    def from_json(cls, cfg):\n",
    "        \"\"\"Creates config from json\"\"\"\n",
    "        params = json.loads(json.dumps(cfg), object_hook=HelperDict)\n",
    "        # init all class instance with data and train attributes\n",
    "        return cls(params.data, params.train, params.output) \n",
    "\n",
    "\n",
    "class HelperDict(object):\n",
    "    \"\"\"Helper class to convert json into Python object\"\"\"\n",
    "    def __init__(self, dict_):\n",
    "        self.__dict__.update(dict_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    \"\"\"Abstract Model class that is inherited to all models\"\"\"\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        self.config = Config.from_json(cfg)\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_data(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def build(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self):\n",
    "        pass\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Data Loader class\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data(data_config):\n",
    "        \"\"\"Loads dataset from path\"\"\"\n",
    "        df = pd.read_csv(data_config.path) # data_config will have .path attribute\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_data(data_config, dataset = None): #dataset -> df\n",
    "        \"\"\" Preprocess and splits into training and test\"\"\"\n",
    "        x = dataset[data_config.x]\n",
    "        y = dataset[data_config.y]\n",
    "        test_size = data_config.test_size\n",
    "        random_state = data_config.random_state\n",
    "        # splitting\n",
    "        x_train, x_test, y_train, y_test = \\\n",
    "            model_selection.train_test_split(x, y, \n",
    "                                             test_size=test_size, \n",
    "                                             random_state=random_state)\n",
    "        # vectorizing\n",
    "        vectorizer = CountVectorizer(ngram_range = data_config.ngram_range, \n",
    "                                     min_df = data_config.min_df)\n",
    "        # fit_transform on training texts: from text to sparse frequency fector embeddings\n",
    "        # transform on test texts: using vector dimension from training set\n",
    "        # Extract token counts out of raw text documents using the vocabulary\n",
    "        # fitted with fit or the one provided to the constructor.\n",
    "        # vectorizer.vocabulary_: A mapping of terms to feature indices.\n",
    "        X_train = vectorizer.fit_transform(x_train)\n",
    "        X_test = vectorizer.transform(x_test)\n",
    "        Y_train = np.array(y_train)\n",
    "        Y_test = np.array(y_test)\n",
    "\n",
    "        return x, y, x_train, x_test, y_train, y_test, X_train, X_test, Y_train, Y_test, vectorizer\n",
    "\n",
    "\n",
    "class LogisticRegressionTrainer():\n",
    "    def __init__(self, model, X_train, Y_train):\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "    def train(self):\n",
    "        self.model.fit(self.X_train, self.Y_train)\n",
    "\n",
    "\n",
    "class YelpLogisticRegression(BaseModel):\n",
    "    \"\"\"Logistic regression model\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Loads and preprocess data to inputs accepted by the model\"\"\"\n",
    "        self.dataset = DataLoader().load_data(self.config.data)\n",
    "        self.x, self.y, \\\n",
    "            self.x_train, self.x_test, self.y_train, self.y_test,\\\n",
    "            self.X_train, self.X_test, self.Y_train, self.Y_test, self.vectorizer =  \\\n",
    "            DataLoader().preprocess_data(data_config = self.config.data, \n",
    "                                           dataset = self.dataset)\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\"Builds the model\"\"\"\n",
    "        # as the model architecture is vanilla logistic regression, there is no customization here\n",
    "        # this is useful when you want to customize layers in a deep learning model \n",
    "        self.model = linear_model.LogisticRegression()\n",
    "        print('Logistic Regression model built')\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Compiles and trains the model with configured training hyper-parameters\"\"\"\n",
    "        print('Set training hyper parameters')\n",
    "        self.model = linear_model.LogisticRegression(\n",
    "            solver = self.config.train.solver, \n",
    "            max_iter = self.config.train.max_iter, \n",
    "            random_state = self.config.train.random_state, \n",
    "            C = self.config.train.C,\n",
    "            penalty = self.config.train.penalty)\n",
    "        print('Training is started')\n",
    "        start_time = datetime.now()\n",
    "        trainer = LogisticRegressionTrainer(\n",
    "            model = self.model, \n",
    "            X_train=self.X_train, \n",
    "            Y_train=self.Y_train)\n",
    "        trainer.train()\n",
    "        end_time = datetime.now()\n",
    "        training_time = (end_time - start_time).total_seconds()\n",
    "        print(f'Training is completed in {\"{:.2f}\".format(training_time)} seconds')\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"Predicts resuts for the test dataset\"\"\"\n",
    "        self.Y_test_pred = self.model.predict(self.X_test)\n",
    "        self.Y_test_pred_proba = self.model.predict_proba(self.X_test)\n",
    "        print('Model evaluation on test set completed, check model attributes for results')\n",
    "\n",
    "    def evaluate_document(self, document: str):\n",
    "        \"\"\"Predicts the rating for an input string given a trained model\"\"\"\n",
    "        document_embedding = self.vectorizer.transform([document]) # vectorizer expects a list of strings\n",
    "        return self.model.predict_proba(document_embedding), self.model.predict(document_embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model built\n",
      "Set training hyper parameters\n",
      "Training is started\n",
      "Training is completed in 1.51 seconds\n"
     ]
    }
   ],
   "source": [
    "model = YelpLogisticRegression(CFGLog)\n",
    "model.load_data()\n",
    "model.build()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.1733107 , 0.34590901, 0.18530299, 0.1227306 , 0.1727467 ]]),\n",
       " array([2], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = r\"Was it worth the for a salad and small pizza Absolutely not Bad service. Maybe the guys grandma died I don't know. I want to tell you what really made me mad about the experience. We order the small pizza and salad and the guys could have cared less and took our $ and we sat down. We were looking around and hmm, there's a sign saying x large pizza and large salad only 23. Wow that would have been nice if the guy told us that. I left hungry, mad and unsatisfied. To the owner: teach your employees the value of upselling and telling the specials. Something so small can affect a customers experience negatively. And your salads are severely overpriced Won't go back unless I'm desperate.\"\n",
    "model.evaluate_document(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "class ModelSaving(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_current_timestamp():\n",
    "        now = datetime.datetime.now()\n",
    "        return now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # @staticmethod\n",
    "    # def save_model_with_timestamp(model, output_config):\n",
    "    #     filename = ModelSaving.get_current_timestamp() + '_LogReg' + '.pickle'\n",
    "    #     filepath = os.path.join(output_config, filename)\n",
    "    #     pickle.dump(model, open(filepath, 'wb'))\n",
    "    #     return print('Saved model to: ', filepath)\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model_with_timestamp(vectorizer, model, output_config):\n",
    "        filename = ModelSaving.get_current_timestamp() + '_LogReg' + '.pickle'\n",
    "        filepath = os.path.join(output_config, filename)\n",
    "        with open(filepath, 'wb') as fout:\n",
    "            pickle.dump((vectorizer, model), fout)\n",
    "        return print('Saved model to: ', filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/exported_models\n",
      "Saved model to:  ../data/exported_models\\20230217_142422_LogReg.pickle\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
     ]
    }
   ],
   "source": [
    "config = Config.from_json(CFGLog)\n",
    "output_config = config.output.output_path\n",
    "print(output_config)\n",
    "# need to pickle the object of <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
    "ModelSaving().save_model_with_timestamp(model.vectorizer, model.model, output_config) \n",
    "print(type(model.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "with open('../data/exported_models/20230217_142422_LogReg.pickle', 'rb') as f:\n",
    "    vectorizer, model = pickle.load(f)\n",
    "document = r\"Was it worth the for a salad and small pizza Absolutely not Bad service. Maybe the guys grandma died I don't know. I want to tell you what really made me mad about the experience. We order the small pizza and salad and the guys could have cared less and took our $ and we sat down. We were looking around and hmm, there's a sign saying x large pizza and large salad only 23. Wow that would have been nice if the guy told us that. I left hungry, mad and unsatisfied. To the owner: teach your employees the value of upselling and telling the specials. Something so small can affect a customers experience negatively. And your salads are severely overpriced Won't go back unless I'm desperate.\"\n",
    "document_embedding = vectorizer.transform([document])\n",
    "print(model.predict(document_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20230217_143059_LogReg.pickle']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config.from_json(CFGLog)\n",
    "output_config = config.output.output_path\n",
    "os.listdir(output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29999692 0.32410897 0.11531732 0.12218435 0.13839243]\n",
      " [0.00330758 0.00528659 0.11448401 0.64093983 0.23598199]\n",
      " [0.29684838 0.28430779 0.18279811 0.19443509 0.04161063]\n",
      " ...\n",
      " [0.10461121 0.31665087 0.34181183 0.20045846 0.03646764]\n",
      " [0.00259873 0.00360898 0.02670638 0.47526981 0.49181609]\n",
      " [0.00458105 0.02761443 0.36196598 0.60364872 0.00218984]]\n",
      "[2 4 1 ... 3 5 4]\n",
      "[2 4 2 ... 2 5 2]\n"
     ]
    }
   ],
   "source": [
    "x_test = model.x_test\n",
    "X_test = model.X_test\n",
    "Y_test = model.Y_test\n",
    "Y_test_pred_proba = model.model.predict_proba(X_test)\n",
    "Y_test_pred = model.model.predict(X_test)\n",
    "print(Y_test_pred_proba)\n",
    "print(Y_test_pred)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6487    I have ordered here before (General's chicken)...\n",
       "8785    I just went here for lunch.  I really have not...\n",
       "7390    Went here for dinner, there were only about 6 ...\n",
       "7078    Fuego Bistro is one of my new favorites! A cou...\n",
       "1230    Good Starbucks in the Happy Valley Shopping Ce...\n",
       "                              ...                        \n",
       "3963    I walked here in the heat and was immediately ...\n",
       "5047    What a great property. Only had been to the ba...\n",
       "6539    I feel bad giving this 2 stars but I'm basing ...\n",
       "6433    I really adore this place. They've got some of...\n",
       "3372    I want to give the Cornish Pasty Company anoth...\n",
       "Name: text, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2, ..., 2, 5, 2], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I just went here for lunch.  I really have nothing to add to the other reviews on here because they pretty much all sum it up.  It gets crowded, the ordering process is a clusterfuk, they place looks sketchy and dirty, the staff is very friendly and helpful, yada yada.  The place isn't worth all the hype but definitely is worth a visit if you are in the mood for something unique.  Its not the healthiest or highest quality cuisine, but it is a pretty solid place and worth a shot.\\n\\n* Jerk Chicken = very good\\n* Pollo Diablo = spicy and awesome and my stomach is going to hate me later\\n* Jade Red Chicken = excellent\\n* Pork Fried Rice = very good\\n* Red Salsa Stuff = excellent\\n* Refried Beans = standard\\n* Snickerdoodle Cookie = awesome\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[8785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5516    I think this place is hyped up a little more t...\n",
       "1255    I went here Saturday night with a party of 4. ...\n",
       "4319    Good place to have a beer, duck fart, or whate...\n",
       "9372    Given the high ratio of staff to customers, it...\n",
       "1723    Great customer service, perfect dining area! T...\n",
       "                              ...                        \n",
       "6384    As an Irish lass thru and thru, the promise of...\n",
       "4720    The drive to the top is really fun, and the vi...\n",
       "173     Ok, so I'm catching up on past-due reviews.  F...\n",
       "1244    The Good: We absolutely love their wings and i...\n",
       "4989    Pretty good coffee. Nothing special but better...\n",
       "Name: text, Length: 8000, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YelpLogisticRegression(CFGLog)\n",
    "model.load_data()\n",
    "model.x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I think this place is hyped up a little more than it should be. I've tired their bruschetta, pizzas and salads. They were decent and I have no complaints but nothing to rave about. A decent place to pop in to for lunch since they have counter service that you order at.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample review document\n",
    "model.x_train[5516]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document vector\n",
    "model.X_train.toarray()[5516]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10642\n",
      "['pizzas']\n",
      "pizzas\n"
     ]
    }
   ],
   "source": [
    "# vocabulary from training data X_train\n",
    "# key: value = term: index\n",
    "vocab_dict = model.vectorizer.vocabulary_\n",
    "# obtain the vocab index of a word in the sample document\n",
    "print(vocab_dict['pizzas'])\n",
    "# finding the word (key) in the document with this vocab index (value)\n",
    "keys = [k for k, v in vocab_dict.items() if v == 10642]\n",
    "print(keys)\n",
    "# alternatively\n",
    "print(list(vocab_dict.keys())[list(vocab_dict.values()).index(10642)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indices of words appearing at least once:\n",
    "non_zeros = list(np.nonzero(model.X_train.toarray()[5516])[0])\n",
    "len(non_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model built\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=1000, random_state=2022, solver='liblinear')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build()\n",
    "print(type(model.model))\n",
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Config'>\n",
      "<class '__main__.HelperDict'>\n",
      "../data/yelp.csv\n",
      "text\n",
      "stars\n"
     ]
    }
   ],
   "source": [
    "config = Config.from_json(CFGLog) # initiate Config class with class method\n",
    "print(type(config))\n",
    "data_config = config.data # define data_config from Config class, containing data config info\n",
    "print(type(data_config))\n",
    "DataLoader().load_data(data_config).head(2) # using data config info to load actual data\n",
    "data_config_path = data_config.path\n",
    "print(data_config_path)\n",
    "data_config_x = data_config.x\n",
    "print(data_config_x)\n",
    "data_config_y = data_config.y\n",
    "print(data_config_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def method(self):\n",
    "        return 'instance method called', self \n",
    "        # 'self' is replaced and returns the object in memory\n",
    "\n",
    "    @classmethod\n",
    "    def classmethod(cls):\n",
    "        return 'class method called', cls\n",
    "\n",
    "    @staticmethod\n",
    "    def staticmethod():\n",
    "        return 'static method called'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('instance method called', <__main__.MyClass at 0x1de4dada1f0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = MyClass()\n",
    "# an instance can call instance method:\n",
    "obj.method()\n",
    "\n",
    "# calling instance method without initiating an instance \n",
    "# TypeError, 'self' is missing, as there is no instance\n",
    "# MyClass.method()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('class method called', __main__.MyClass)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an instance can call its class method:\n",
    "obj.classmethod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'static method called'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an instance can call the class's static method:\n",
    "obj.staticmethod()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to look at this use of class methods is that they allow you to define alternative constructors for your classes. <br>\n",
    "\n",
    "Python only allows one `__init__` method per class. Using class methods it’s possible to add as many alternative constructors as necessary. This can make the interface for your classes self-documenting (to a certain degree) and simplify their usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pizza:\n",
    "    def __init__(self, ingredients):\n",
    "        self.ingredients = ingredients\n",
    "\n",
    "    # def pizza(self):\n",
    "    #     return self(self.ingredients)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Your Pizza({self.ingredients})!'\n",
    "\n",
    "    @classmethod\n",
    "    def margherita(cls):\n",
    "        return cls(['mozzarella', 'tomatoes'])\n",
    "\n",
    "    @classmethod\n",
    "    def prosciutto(cls):\n",
    "        return cls(['mozzarella', 'tomatoes', 'ham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Pizza(['mozzarella', 'tomatoes', 'ham'])!\n"
     ]
    }
   ],
   "source": [
    "Pizza.margherita()\n",
    "print(Pizza.prosciutto())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56c60349980dbc812633e0178218017b9281b8abb7530174d97057b1d59c6a06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
